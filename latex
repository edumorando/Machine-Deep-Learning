CÓDIGOS ATUAIS:
ANALISE PERFIL{
import re
import pandas as pd
import numpy as np
from pyspark.sql import SparkSession
from pyspark.sql.types import DecimalType, DoubleType
from openai import OpenAI
import time
import json
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
import concurrent.futures
import threading
from queue import Queue
import logging
import sys
import mlflow
mlflow.openai.autolog()

# Configuração de logging mais detalhada
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger("AnalisadorPerfil")

class SparkSessionManager:
    """Classe para gerenciar a sessão Spark de forma robusta"""
    
    _instance = None
    
    @classmethod
    def get_or_create(cls):
        if cls._instance is None:
            logger.info("Inicializando nova SparkSession")
            try:
                # Configuração otimizada para o SparkSession
                spark = (SparkSession.builder
                    .appName("AnalisadorPerfilAssociado")
                    .config("spark.sql.execution.arrow.pyspark.enabled", "true")
                    .config("spark.sql.execution.arrow.maxRecordsPerBatch", "10000")
                    .config("spark.databricks.io.cache.enabled", "true")
                    .config("spark.databricks.delta.preview.enabled", "true")
                    .getOrCreate())
                
                # Definir configurações de log do Spark para reduzir ruído
                spark.sparkContext.setLogLevel("WARN")
                
                cls._instance = spark
                logger.info("SparkSession inicializada com sucesso")
            except Exception as e:
                logger.error(f"Erro ao inicializar SparkSession: {str(e)}")
                raise
        return cls._instance
    
    @classmethod
    def reset(cls):
        """Reinicia a sessão Spark em caso de problemas"""
        if cls._instance:
            try:
                logger.info("Reiniciando SparkSession")
                cls._instance.stop()
            except:
                pass
            cls._instance = None
        return cls.get_or_create()

class AnalisadorPerfilAssociado:
    """
    Classe principal para análise de perfil de associados Sicredi.
    Implementa funcionalidades avançadas de análise holística, incluindo
    cônjuges, sócios e grupos econômicos.
    """
    
    def __init__(self):
        """Inicializa o analisador com configurações padrão."""
        self.timeout_analise_secundaria = 120  # timeout em segundos para análises secundárias
        self.max_retries = 3  # número máximo de tentativas para chamadas ao modelo
        self.cache_associados = {}  # cache para evitar consultas repetidas
        self.spark = None  # será inicializado sob demanda
    
    def _get_spark(self):
        """Obtém uma sessão Spark válida, com tratamento de reconexão"""
        if self.spark is None:
            self.spark = SparkSessionManager.get_or_create()
        return self.spark
    
    def analisar_perfil_associado(self, cpf_cnpj: str) -> Dict[str, Any]:
        """
        Analisa o perfil completo de um associado do Sicredi, incluindo suas relações
        (cônjuge, sócios ou grupo econômico).
        
        Args:
            cpf_cnpj: CPF ou CNPJ do associado (com ou sem formatação)
            
        Returns:
            Dicionário contendo análise principal, análises relacionadas e análise consolidada
        """
        start_time = time.time()
        
        try:
            # Limpar o CPF/CNPJ (remover caracteres não numéricos)
            cpf_cnpj_limpo = re.sub(r'[^0-9]', '', cpf_cnpj)
            
            # Validar o CPF/CNPJ
            if not cpf_cnpj_limpo:
                return {
                    "status": "error",
                    "message": f"CPF/CNPJ inválido: {cpf_cnpj}"
                }
            
            if len(cpf_cnpj_limpo) != 11 and len(cpf_cnpj_limpo) != 14:
                return {
                    "status": "error",
                    "message": f"CPF/CNPJ com formato inválido: {cpf_cnpj}. Deve ter 11 dígitos (CPF) ou 14 dígitos (CNPJ)."
                }
            
            # Obter sessão Spark válida
            try:
                spark = self._get_spark()
                # Limpar cache do Spark para evitar problemas de memória
                spark.catalog.clearCache()
            except Exception as e:
                logger.error(f"Erro ao inicializar Spark: {str(e)}")
                # Tentar reiniciar a sessão
                SparkSessionManager.reset()
                spark = self._get_spark()
            
            # Consultar os dados do associado principal
            try:
                dados_associado = self.extrair_dados_associado(cpf_cnpj_limpo)
            except Exception as e:
                logger.error(f"Erro ao extrair dados: {str(e)}")
                # Tentar novamente com sessão reiniciada
                SparkSessionManager.reset()
                self.spark = SparkSessionManager.get_or_create()
                dados_associado = self.extrair_dados_associado(cpf_cnpj_limpo)
            
            # Verificar se foram encontrados dados
            if dados_associado.empty:
                return {
                    "status": "error",
                    "message": f"Não foram encontrados dados para o CPF/CNPJ {cpf_cnpj_limpo}"
                }
            
            # Converter os dados para um formato adequado para o modelo
            dados_formatados = self.formatar_dados_para_analise(dados_associado)
            
            # Determinar se é PF ou PJ
            tipo_pessoa = dados_formatados.get("tipo_pessoa", "").upper()
            is_pf = "FISICA" in tipo_pessoa or "FÍSICA" in tipo_pessoa
            is_pj = "JURIDICA" in tipo_pessoa or "JURÍDICA" in tipo_pessoa
            
            # Armazenar no cache para evitar consultas repetidas
            self.cache_associados[cpf_cnpj_limpo] = {
                "dados_formatados": dados_formatados,
                "is_pf": is_pf,
                "is_pj": is_pj
            }
            
            # Preparar estrutura para análises relacionadas
            analises_relacionadas = {
                "conjuge": None,
                "socios": [],
                "grupo_economico": None
            }
            
            # Obter o glossário da tabela
            glossario = self.obter_glossario_tabela()
            
            # Gerar a análise principal usando o modelo
            analise_principal = self.gerar_analise_com_modelo(
                dados_formatados, 
                glossario, 
                cpf_cnpj_limpo, 
                is_pf, 
                is_pj
            )
            
            # Iniciar análises secundárias em paralelo com tratamento de erros aprimorado
            futures = {}
            with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                
                # 1. Análise de cônjuge para PF
                if is_pf and dados_formatados.get("nome_pessoa_conjuge") and dados_formatados.get("cpf_conjuge"):
                    cpf_conjuge = re.sub(r'[^0-9]', '', str(dados_formatados.get("cpf_conjuge", "")))
                    if cpf_conjuge and len(cpf_conjuge) == 11:
                        logger.info(f"Iniciando análise do cônjuge: {cpf_conjuge}")
                        futures["conjuge"] = executor.submit(
                            self.analisar_conjuge, 
                            cpf_conjuge, 
                            dados_formatados.get("nome_pessoa_conjuge")
                        )
                
                # 2. Análise de sócios para PJ
                if is_pj and dados_formatados.get("cpfs_socios"):
                    cpfs_socios = dados_formatados.get("cpfs_socios", "").split(';')
                    nomes_socios = dados_formatados.get("nomes_socios", "").split(';')
                    percentuais = dados_formatados.get("percentuais_capital", "").split(';')
                    
                    # Limitar a no máximo 3 sócios para evitar sobrecarga
                    for i in range(min(len(cpfs_socios), len(nomes_socios), 3)):
                        cpf_socio = re.sub(r'[^0-9]', '', cpfs_socios[i])
                        if cpf_socio and len(cpf_socio) == 11:
                            percentual = percentuais[i] if i < len(percentuais) else "0"
                            logger.info(f"Iniciando análise do sócio: {cpf_socio}")
                            futures[f"socio_{i}"] = executor.submit(
                                self.analisar_socio,
                                cpf_socio,
                                nomes_socios[i].strip(),
                                percentual.strip()
                            )
                
                # 3. Análise de grupo econômico
                if dados_formatados.get("nome_grupo_economico") and dados_formatados.get("Codigo_conglomerado_economico"):
                    codigo_grupo = dados_formatados.get("Codigo_conglomerado_economico")
                    nome_grupo = dados_formatados.get("nome_grupo_economico")
                    if codigo_grupo:
                        logger.info(f"Iniciando análise do grupo econômico: {nome_grupo} (Código: {codigo_grupo})")
                        futures["grupo_economico"] = executor.submit(
                            self.analisar_grupo_economico,
                            codigo_grupo,
                            nome_grupo
                        )
                
                # Coletar resultados das análises secundárias com melhor tratamento de erros
                for key, future in futures.items():
                    try:
                        resultado = future.result(timeout=self.timeout_analise_secundaria)
                        if key == "conjuge":
                            analises_relacionadas["conjuge"] = resultado
                        elif key == "grupo_economico":
                            analises_relacionadas["grupo_economico"] = resultado
                        elif key.startswith("socio_"):
                            analises_relacionadas["socios"].append(resultado)
                    except concurrent.futures.TimeoutError:
                        logger.warning(f"Timeout na análise secundária: {key}")
                    except Exception as e:
                        logger.error(f"Erro na análise secundária {key}: {str(e)}")
            
            # Consolidar todas as análises
            analise_consolidada = self.consolidar_analises(
                cpf_cnpj_limpo,
                dados_formatados,
                analise_principal,
                analises_relacionadas,
                is_pf,
                is_pj
            )
            
            # Calcular tempo total de processamento
            tempo_processamento = time.time() - start_time
            
            # Garantir que a renda mensal esteja disponível na resposta
            renda_mensal = dados_formatados.get("renda_mensal", "Não informado")
            
            return {
                "status": "success",
                "cpf_cnpj": cpf_cnpj_limpo,
                "tipo_pessoa": "PF" if is_pf else "PJ" if is_pj else "Não identificado",
                "analise_principal": analise_principal,
                "relacoes": analises_relacionadas,
                "analise_consolidada": analise_consolidada,
                "dados": dados_formatados,
                "renda_mensal": renda_mensal,  # Garantindo que a renda esteja explícita no resultado
                "tempo_processamento": f"{tempo_processamento:.2f} segundos",
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            
        except Exception as e:
            import traceback
            stack_trace = traceback.format_exc()
            logger.error(f"Erro na análise principal: {str(e)}\n{stack_trace}")
            return {
                "status": "error",
                "message": f"Erro ao analisar perfil: {str(e)}",
                "details": stack_trace,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
    
    def extrair_dados_associado(self, cpf_cnpj: str) -> pd.DataFrame:
        """
        Extrai os dados do associado da tabela perfil_associado.
        
        Args:
            cpf_cnpj: CPF/CNPJ limpo do associado
            
        Returns:
            DataFrame pandas com os dados do associado
        """
        # Verificar se os dados já estão em cache
        if cpf_cnpj in self.cache_associados and "dados_brutos" in self.cache_associados[cpf_cnpj]:
            logger.info(f"Usando dados em cache para {cpf_cnpj}")
            return self.cache_associados[cpf_cnpj]["dados_brutos"]
        
        # Definir tabela principal
        tabela_principal = "sicredi_coop_0914.bases_bi.perfil_associado"
        
        # SQL para obter todos os dados do associado
        sql_query = f"""
        SELECT *
        FROM {tabela_principal}
        WHERE num_cpf_cnpj = '{cpf_cnpj}'
        """
        
        # Obter sessão Spark válida
        spark = self._get_spark()
        
        try:
            # Executar a consulta com tratamento de erros
            df_spark = spark.sql(sql_query)
            
            # Converter tipos de dados problemáticos antes da conversão para pandas
            for field in df_spark.schema.fields:
                if isinstance(field.dataType, DecimalType):
                    df_spark = df_spark.withColumn(field.name, df_spark[field.name].cast(DoubleType()))
            
            # Converter para pandas DataFrame - usar método mais eficiente
            df_pandas = df_spark.toPandas()
            
            # Armazenar dados brutos no cache
            if cpf_cnpj in self.cache_associados:
                self.cache_associados[cpf_cnpj]["dados_brutos"] = df_pandas
            else:
                self.cache_associados[cpf_cnpj] = {"dados_brutos": df_pandas}
            
            return df_pandas
            
        except Exception as e:
            logger.error(f"Erro ao extrair dados do associado: {str(e)}")
            # Tentar reiniciar a sessão Spark
            SparkSessionManager.reset()
            self.spark = SparkSessionManager.get_or_create()
            
            # Tentar novamente a consulta
            df_spark = self.spark.sql(sql_query)
            
            # Converter tipos de dados
            for field in df_spark.schema.fields:
                if isinstance(field.dataType, DecimalType):
                    df_spark = df_spark.withColumn(field.name, df_spark[field.name].cast(DoubleType()))
            
            # Converter para pandas
            return df_spark.toPandas()
    
    def extrair_dados_grupo_economico(self, codigo_grupo: str) -> pd.DataFrame:
        """
        Extrai os dados de todos os associados pertencentes ao mesmo grupo econômico.
        
        Args:
            codigo_grupo: Código do grupo econômico
            
        Returns:
            DataFrame pandas com os dados dos associados do grupo
        """
        # Definir tabela principal
        tabela_principal = "sicredi_coop_0914.bases_bi.perfil_associado"
        
        # SQL para obter dados resumidos de todos os associados do grupo
        sql_query = f"""
        SELECT 
            num_cpf_cnpj, nome_associado, tipo_pessoa, 
            saldo_total_sicredi_conceito_amplo, capital_social_saldo,
            endividamento_total_conceito_amplo, patrimonio_total,
            faixa_risco_padrao, pd_padrao, flg_inad,
            renda_mensal  -- Garantindo que a renda mensal seja incluída
        FROM {tabela_principal}
        WHERE Codigo_conglomerado_economico = '{codigo_grupo}'
        """
        
        # Executar a consulta
        df_spark = self.spark.sql(sql_query)
        
        # Converter tipos de dados problemáticos antes da conversão para pandas
        for field in df_spark.schema.fields:
            if isinstance(field.dataType, DecimalType):
                df_spark = df_spark.withColumn(field.name, df_spark[field.name].cast(DoubleType()))
        
        # Converter para pandas DataFrame
        return df_spark.toPandas()
    
    def formatar_dados_para_analise(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        Formata os dados do associado para análise, tratando valores especiais.
        
        Args:
            df: DataFrame pandas com os dados do associado
            
        Returns:
            Dicionário com os dados formatados
        """
        if df.empty:
            return {}
        
        # Obter o primeiro (e único) registro
        registro = df.iloc[0]
        
        # Função auxiliar para formatar valores
        def formatar_valor(coluna, valor):
            if pd.isna(valor) or pd.isnull(valor):
                return None
            
            # Formatar valores monetários
            if isinstance(valor, (float, int)) and any(termo in coluna.lower() for termo in ['saldo', 'valor', 'limite', 'renda', 'patrimonio', 'capital', 'comprometimento', 'endividamento', 'vlr_']):
                return f"R$ {valor:,.2f}".replace(',', 'X').replace('.', ',').replace('X', '.')
            
            # Formatar percentuais
            if isinstance(valor, (float, int)) and any(perc in coluna.lower() for perc in ['percentual', 'pd_', 'pp_']):
                return f"{valor:.2f}%".replace('.', ',')
            
            # Tratar datas
            if 'data_' in coluna.lower() and isinstance(valor, str):
                try:
                    # Tentar converter para formato de data mais legível
                    data = pd.to_datetime(valor)
                    return data.strftime('%d/%m/%Y')
                except:
                    return valor
            
            # Tratar flags SIM/NÃO
            if isinstance(valor, str) and valor.upper() in ['SIM', 'NAO', 'NÃO', 'S', 'N']:
                return 'Sim' if valor.upper() in ['SIM', 'S'] else 'Não'
            
            # Retornar o valor como está para outros casos
            return valor
        
        # Criar dicionário com todos os campos formatados
        dados_formatados = {}
        
        for coluna in registro.index:
            valor = registro[coluna]
            dados_formatados[coluna] = formatar_valor(coluna, valor)
        
        # Processar dados específicos para PJ (se aplicável)
        if dados_formatados.get("tipo_pessoa", "").upper() in ["PESSOA JURIDICA", "PESSOA JURÍDICA"]:
            # Processar lista de sócios
            if dados_formatados.get("nomes_socios"):
                nomes = dados_formatados.get("nomes_socios", "").split(';')
                cpfs = dados_formatados.get("cpfs_socios", "").split(';')
                percentuais = dados_formatados.get("percentuais_capital", "").split(';')
                
                # Criar lista estruturada de sócios
                socios = []
                for i in range(min(len(nomes), len(cpfs))):
                    percentual = percentuais[i] if i < len(percentuais) else 'Não informado'
                    socios.append({
                        "nome": nomes[i].strip(),
                        "cpf": cpfs[i].strip(),
                        "percentual": percentual.strip()
                    })
                
                dados_formatados["socios_estruturados"] = socios
        
        # Calcular métricas adicionais
        dados_formatados = self.calcular_metricas_adicionais(dados_formatados)
        
        return dados_formatados
    
    def calcular_metricas_adicionais(self, dados: Dict[str, Any]) -> Dict[str, Any]:
        """
        Calcula métricas adicionais para enriquecer a análise.
        
        Args:
            dados: Dicionário com os dados formatados do associado
            
        Returns:
            Dicionário com dados enriquecidos com métricas adicionais
        """
        # Função para converter valores para float
        def converter_para_float(valor):
            if valor is None:
                return 0.0
            if isinstance(valor, (int, float)):
                return float(valor)
            if isinstance(valor, str):
                # Remover R$ e substituir , por . em valores monetários
                valor_limpo = valor.replace('R$', '').replace('.', '').replace(',', '.').strip()
                try:
                    return float(valor_limpo)
                except ValueError:
                    # Tentar converter percentuais
                    try:
                        return float(valor.replace('%', '').replace(',', '.'))
                    except ValueError:
                        return 0.0
            return 0.0
        
        # Adicionar seção para métricas calculadas
        dados["metricas_calculadas"] = {}
        
        # 1. Calcular percentual de utilização de limites
        limite_cheque = converter_para_float(dados.get("limite_cheque_especial", 0))
        usado_cheque = converter_para_float(dados.get("limite_utilizado_cheque_especial", 0))
        
        if limite_cheque > 0:
            percentual_uso_cheque = (usado_cheque / limite_cheque) * 100
            dados["metricas_calculadas"]["percentual_uso_cheque_especial"] = f"{percentual_uso_cheque:.2f}%".replace('.', ',')
        
        limite_cartao = converter_para_float(dados.get("limite_cartao_credito", 0))
        usado_cartao = converter_para_float(dados.get("limite_utilizado_cartao_credito", 0))
        
        if limite_cartao > 0:
            percentual_uso_cartao = (usado_cartao / limite_cartao) * 100
            dados["metricas_calculadas"]["percentual_uso_cartao_credito"] = f"{percentual_uso_cartao:.2f}%".replace('.', ',')
        
        # 2. Calcular relação patrimônio/renda
        patrimonio = converter_para_float(dados.get("patrimonio_total", 0))
        renda = converter_para_float(dados.get("renda_mensal", 0))
        
        if renda > 0:
            relacao_patrimonio_renda = patrimonio / renda
            dados["metricas_calculadas"]["relacao_patrimonio_renda"] = f"{relacao_patrimonio_renda:.2f}".replace('.', ',')
            
            if relacao_patrimonio_renda > 60:
                dados["metricas_calculadas"]["classificacao_patrimonio_renda"] = "Alta"
            elif relacao_patrimonio_renda > 24:
                dados["metricas_calculadas"]["classificacao_patrimonio_renda"] = "Média"
            else:
                dados["metricas_calculadas"]["classificacao_patrimonio_renda"] = "Em desenvolvimento"
        
        # 3. Classificar tempo de relacionamento
        anos_associacao = converter_para_float(dados.get("anos_de_associacao", 0))
        
        if anos_associacao < 1:
            dados["metricas_calculadas"]["classificacao_tempo_relacionamento"] = "Iniciante"
        elif anos_associacao < 3:
            dados["metricas_calculadas"]["classificacao_tempo_relacionamento"] = "Em desenvolvimento"
        elif anos_associacao < 7:
            dados["metricas_calculadas"]["classificacao_tempo_relacionamento"] = "Estabelecido"
        else:
            dados["metricas_calculadas"]["classificacao_tempo_relacionamento"] = "Longevo"
        
        # 4. Classificar nível de atualização cadastral
        dias_atualizacao = converter_para_float(dados.get("dias_desde_ultima_atualizacao_conta", 0))
        
        if dias_atualizacao <= 180:
            dados["metricas_calculadas"]["status_atualizacao_cadastral"] = "Recente"
        elif dias_atualizacao <= 365:
            dados["metricas_calculadas"]["status_atualizacao_cadastral"] = "Moderada"
        else:
            dados["metricas_calculadas"]["status_atualizacao_cadastral"] = "Desatualizada"
        
        # 5. Classificar saúde financeira
        comprometimento_renda = converter_para_float(dados.get("percentual_comprometido_renda", 0))
        valor_restritivos = converter_para_float(dados.get("valor_total_restritivos", 0))
        
        if comprometimento_renda <= 30 and valor_restritivos == 0:
            dados["metricas_calculadas"]["classificacao_saude_financeira"] = "Excelente"
        elif comprometimento_renda <= 50 and valor_restritivos == 0:
            dados["metricas_calculadas"]["classificacao_saude_financeira"] = "Boa"
        elif comprometimento_renda <= 70 and valor_restritivos < 1000:
            dados["metricas_calculadas"]["classificacao_saude_financeira"] = "Regular"
        else:
            dados["metricas_calculadas"]["classificacao_saude_financeira"] = "Atenção"
        
        # 6. Calcular potencial de crescimento (nova métrica)
        saldo_total = converter_para_float(dados.get("saldo_total_sicredi_conceito_amplo", 0))
        patrimonio_total = converter_para_float(dados.get("patrimonio_total", 0))
        
        if patrimonio_total > 0:
            penetracao_patrimonio = (saldo_total / patrimonio_total) * 100
            dados["metricas_calculadas"]["penetracao_patrimonio"] = f"{penetracao_patrimonio:.2f}%".replace('.', ',')
            
            if penetracao_patrimonio < 15:
                dados["metricas_calculadas"]["potencial_crescimento"] = "Alto"
            elif penetracao_patrimonio < 40:
                dados["metricas_calculadas"]["potencial_crescimento"] = "Médio"
            else:
                dados["metricas_calculadas"]["potencial_crescimento"] = "Baixo"
        
        # 7. Adicionar informações explícitas sobre conceitos restritos e amplos
        if "saldo_total_sicredi_conceito_amplo" in dados and "scr_total_conceito_restrito" in dados:
            dados["metricas_calculadas"]["diferenca_conceitos"] = {
                "saldo_total_conceito_amplo": dados.get("saldo_total_sicredi_conceito_amplo", "Não informado"),
                "scr_total_conceito_restrito": dados.get("scr_total_conceito_restrito", "Não informado"),
                "explicacao": "O conceito amplo inclui todas as operações no sistema financeiro, enquanto o conceito restrito considera apenas operações diretas com a instituição."
            }
        
        return dados
    
    def obter_glossario_tabela(self) -> str:
        """
        Retorna o glossário completo da tabela perfil_associado.
        
        Returns:
            String com o glossário formatado
        """
        return """
        Glossário e Guia de Uso da Tabela Perfil_Associado
        
        Visão Geral
        A tabela perfil_associado é um repositório centralizado e abrangente de informações sobre os associados do Sicredi, reunindo dados de diversas fontes em um único local. Esta tabela foi projetada para fornecer uma visão 360° de cada associado, incluindo informações demográficas, financeiras, comportamentais, de risco e relacionamento, permitindo análises profundas e tomadas de decisão baseadas em dados.
        
        Glossário de Campos
        
        Identificação e Organização
        Campo | Descrição | Uso
        num_cpf_cnpj | Número do CPF (pessoa física) ou CNPJ (pessoa jurídica) do associado, formatado como string para preservar zeros à esquerda | Identificador único do associado, utilizado como chave primária para relacionamentos com outras tabelas
        cod_carteira | Código da carteira à qual o associado está vinculado | Identifica o tipo de relacionamento comercial do associado
        flg_correntista | Indica se o associado possui conta corrente ('SIM' ou 'NÃO') | Permite filtrar associados que possuem conta corrente ativa
        flg_carteira_ativa | Indica se a carteira do associado está ativa ('SIM' ou 'NÃO') | Permite identificar associados com relacionamento ativo
        nom_carteira | Nome descritivo da carteira do associado | Facilita a compreensão do tipo de relacionamento comercial
        num_conta | Número da conta principal do associado | Identificador da conta para operações bancárias
        cod_agencia | Código da agência onde a conta está registrada | Permite análises geográficas e por unidade de atendimento
        des_status_conta | Status atual da conta (Ativo, Inativo, etc.) | Indica se a conta está operacional
        des_marca | Marca associada (Sicredi, etc.) | Identifica a marca institucional relacionada
        nom_gestor_carteira | Nome do gerente ou gestor responsável pela carteira | Permite análises de desempenho por gestor
        nome_grupo_economico | Nome do grupo econômico ao qual o associado pertence, se aplicável | Identifica relações entre empresas do mesmo grupo
        Codigo_conglomerado_economico | Código numérico do conglomerado econômico | Facilita agrupamentos por conglomerado
        Regional | Regional administrativa à qual o associado está vinculado | Permite análises regionais
        nome_agencia | Nome fantasia da agência onde a conta está registrada | Facilita identificação da unidade de atendimento
        
        Associação e Demografia
        Campo | Descrição | Uso
        data_inicio_associacao | Data em que o cliente se tornou associado | Permite análises de tempo de relacionamento e fidelidade
        anos_de_associacao | Tempo em anos desde que se tornou associado, calculado com precisão decimal | Métrica importante para segmentação e análise de fidelidade
        tipo_pessoa | Classificação como Pessoa Física (PF) ou Pessoa Jurídica (PJ) | Permite segmentação básica do tipo de cliente
        des_estado_civil | Estado civil do associado (para PF) | Informação demográfica relevante para ofertas personalizadas
        idade | Idade atual do associado (para PF) | Permite segmentação etária e análises de ciclo de vida
        flg_sexo | Gênero do associado (para PF) | Permite segmentação demográfica
        
        Segmentação e Profissional
        Campo | Descrição | Uso
        nome_associado | Nome completo do associado | Identificação nominal do cliente
        des_segmento | Segmento de mercado do associado | Permite estratégias específicas por segmento
        des_subsegmento | Subsegmento mais específico | Refinamento da segmentação de mercado
        des_publico_estrategico | Classificação estratégica do público | Identifica grupos de interesse especial para a cooperativa
        cod_cbo | Código da Classificação Brasileira de Ocupações | Identifica a profissão do associado PF
        des_cbo | Descrição da ocupação profissional | Permite análises por grupo profissional
        cod_cnae | Código da Classificação Nacional de Atividades Econômicas | Identifica o setor de atuação do associado PJ
        des_cnae | Descrição da atividade econômica | Permite análises setoriais
        trabalha_no_sicredi | Indica se o associado é funcionário do Sicredi | Identifica colaboradores que são associados
        des_cargo_sicredi | Cargo ocupado no Sicredi, se aplicável | Detalha a função do associado na instituição
        
        Atualizações Cadastrais
        Campo | Descrição | Uso
        data_ultima_atualizacao_cadastral | Data da última atualização cadastral completa | Monitora a atualização dos dados cadastrais
        dias_desde_ultima_atualizacao_conta | Dias transcorridos desde a última atualização cadastral | Identifica cadastros que precisam ser atualizados
        data_ultima_atualizacao_renda | Data da última atualização de informações de renda | Monitora a atualização de dados financeiros
        dias_desde_ultima_atualizacao_renda | Dias transcorridos desde a última atualização de renda | Identifica necessidade de atualização de dados financeiros
        
        Capital e Patrimônio
        Campo | Descrição | Uso
        capital_social_saldo | Valor total investido pelo associado em cotas de capital social da cooperativa | Indica o nível de participação societária na cooperativa
        patrimonio_total | Valor total do patrimônio declarado pelo associado | Permite análises de capacidade financeira e potencial de investimento
        
        Carteira e Limites Financeiros
        Campo | Descrição | Uso
        saldo_total_sicredi_conceito_amplo | Soma de todos os valores em produtos financeiros no Sicredi, incluindo operações em todo o sistema financeiro | Visão consolidada do relacionamento financeiro em conceito amplo
        saldo_conta_corrente | Saldo atual disponível na conta corrente | Indica liquidez imediata do associado
        limite_cheque_especial | Valor do limite de cheque especial aprovado | Indica o crédito pré-aprovado para emergências
        limite_utilizado_cheque_especial | Valor do limite de cheque especial que está sendo utilizado | Indica o nível de dependência de crédito emergencial
        valor_adiantamento | Valor de adiantamentos concedidos ao associado | Indica uso de crédito antecipado
        limite_cartao_credito | Valor do limite total aprovado em cartões de crédito | Indica capacidade de crédito rotativo
        limite_utilizado_cartao_credito | Valor do limite de cartão de crédito que está sendo utilizado | Indica nível de utilização do crédito rotativo
        sld_fundos | Saldo total investido em fundos de investimento | Indica perfil investidor e reservas financeiras
        qt_fundos | Quantidade de fundos de investimento que o associado possui | Indica diversificação de investimentos
        pix_trans_30d | Quantidade de transações PIX nos últimos 30 dias | Indica engajamento com serviços digitais
        isa | Índice Sicredi de Atividade - métrica proprietária que mede o nível de atividade do associado | Indica o quão ativo é o relacionamento com a cooperativa
        principalidade | Faixa de principalidade do associado (Alta, Média, Baixa) | Indica se o Sicredi é o principal banco do associado
        score_principalidade | Pontuação numérica que determina o nível de principalidade | Métrica quantitativa de relacionamento bancário principal
        
        Renda e Comprometimento de Crédito
        Campo | Descrição | Uso
        renda_mensal | Média mensal de renda do associado | Base para análise de capacidade de pagamento
        comprometimento_mensal | Valor mensal comprometido com pagamento de dívidas | Indica o montante de obrigações financeiras mensais
        percentual_comprometido_renda | Percentual da renda comprometido com dívidas | Indicador crucial de saúde financeira e capacidade de endividamento
        flg_cheque_especial | Indica se o associado possui cheque especial | Identifica disponibilidade deste produto
        uso_cheque_especial_ultimos_3meses | Frequência de uso do cheque especial nos últimos 3 meses | Indica dependência de crédito emergencial
        uso_credito_rotativo_ultimos_3meses | Frequência de uso de crédito rotativo nos últimos 3 meses | Indica comportamento de uso de crédito de curto prazo
        uso_credito_facil_ultimos_3meses | Frequência de uso de crédito fácil nos últimos 3 meses | Indica comportamento de uso de linhas de crédito específicas
        uso_rotativo_cartao_ultimos_6meses | Frequência de uso do rotativo do cartão nos últimos 6 meses | Indica comportamento de pagamento parcial de faturas
        cheques_devolvidos_ultimos_6meses | Quantidade de cheques devolvidos nos últimos 6 meses | Indica problemas de fluxo de caixa ou organização financeira
        
        Endividamento e SCR
        Campo | Descrição | Uso
        scr_total_conceito_restrito | Valor total das operações registradas no Sistema de Informações de Crédito do Banco Central, considerando apenas operações diretas com a instituição | Indica endividamento no sistema financeiro em conceito restrito
        valor_cpr_b3 | Valor total de operações registradas na Central de Registro de Títulos e Ativos da B3 | Indica compromissos financeiros registrados na B3
        endividamento_total_conceito_amplo | Soma de todas as dívidas do associado, incluindo operações em todo o sistema financeiro | Visão consolidada do endividamento total em conceito amplo
        percentual_comprometimento_patrimonio | Percentual do patrimônio comprometido com dívidas | Indica o nível de alavancagem patrimonial
        
        Restritivos
        Campo | Descrição | Uso
        qtd_restritivos_serasa | Quantidade de apontamentos restritivos no Serasa | Indica problemas de crédito reportados pelo Serasa
        vlr_restritivos_serasa | Valor total dos apontamentos restritivos no Serasa | Dimensiona o tamanho dos problemas de crédito no Serasa
        restricao_serasa | Indica se há restrição ativa no Serasa | Flag rápido de verificação de problemas no Serasa
        restricao_spc | Indica se há restrição ativa no SPC | Flag rápido de verificação de problemas no SPC
        restricao_scr | Indica se há restrição no Sistema de Informações de Crédito | Flag rápido de verificação de problemas no SCR
        qtd_restritivos_spc | Quantidade de apontamentos restritivos no SPC | Indica problemas de crédito reportados pelo SPC
        vlr_restritivos_spc | Valor total dos apontamentos restritivos no SPC | Dimensiona o tamanho dos problemas de crédito no SPC
        valor_total_restritivos | Soma de todos os valores restritivos | Visão consolidada dos problemas de crédito
        qtd_pefin | Quantidade de pendências financeiras | Indica problemas específicos de pendências financeiras
        vlr_pefin | Valor total das pendências financeiras | Dimensiona o tamanho das pendências financeiras
        qtd_refin | Quantidade de operações refinanciadas | Indica histórico de renegociações
        vlr_refin | Valor total das operações refinanciadas | Dimensiona o volume de renegociações
        qtd_dividas | Quantidade total de dívidas registradas | Indica o número de compromissos financeiros
        vlr_dividas | Valor total das dívidas registradas | Dimensiona o volume total de compromissos
        qtd_ch_serasa | Quantidade de cheques com restrição no Serasa | Indica problemas específicos com cheques
        vlr_ch_serasa | Valor total dos cheques com restrição no Serasa | Dimensiona os problemas com cheques
        qtd_protesto | Quantidade de protestos em cartório | Indica problemas legais de crédito
        vlr_protesto | Valor total dos protestos em cartório | Dimensiona os problemas legais de crédito
        qtd_acao_judicial | Quantidade de ações judiciais | Indica litígios financeiros em andamento
        vlr_acao_judicial | Valor total das ações judiciais | Dimensiona o volume de litígios financeiros
        
        Inadimplência
        Campo | Descrição | Uso
        flg_inad | Indica se o associado está inadimplente ('SIM' ou 'NÃO') | Flag rápido para identificar inadimplência atual
        
        Cônjuge
        Campo | Descrição | Uso
        tempo_uniao | Tempo em anos da união matrimonial ou estável | Indica estabilidade familiar
        nome_regime_bem | Regime de bens do casamento ou união | Relevante para análise de garantias e patrimônio
        uniao_estavel | Indica se o associado possui união estável | Identifica tipo de vínculo conjugal
        nome_pessoa_conjuge | Nome do cônjuge | Identifica o parceiro para análises familiares
        cpf_conjuge | CPF do cônjuge | Permite análise integrada do casal
        
        Modelagem de Risco IFRS 9
        Campo | Descrição | Uso
        descr_modelo | Descrição do modelo de classificação de risco utilizado | Identifica o tipo de avaliação aplicada
        faixa_risco_padrao | Classificação padronizada de risco | Indica o nível de risco do associado
        pd_padrao | Probability of Default - probabilidade de inadimplência | Métrica estatística de risco de crédito
        pp_padrao | Perda Potencial - estimativa de perda em caso de default | Métrica de impacto financeiro em caso de inadimplência
        
        Pessoa Jurídica
        Campo | Descrição | Uso
        des_natureza_juridica | Descrição da natureza jurídica da empresa | Identifica o tipo de organização empresarial
        qt_socios | Quantidade de sócios da empresa | Indica a estrutura societária
        nomes_socios | Lista de nomes dos sócios, separados por ponto e vírgula | Identifica os responsáveis pela empresa
        cpfs_socios | Lista de CPFs dos sócios, separados por ponto e vírgula | Permite cruzamento com dados individuais dos sócios
        percentuais_capital | Lista dos percentuais de participação de cada sócio | Indica a distribuição do controle societário
        """
    
    def analisar_conjuge(self, cpf_conjuge: str, nome_conjuge: str) -> Dict[str, Any]:
        """
        Realiza uma análise específica para o cônjuge de um associado PF.
        
        Args:
            cpf_conjuge: CPF do cônjuge
            nome_conjuge: Nome do cônjuge
            
        Returns:
            Dicionário com os dados e análise do cônjuge
        """
        logger.info(f"Analisando cônjuge: {nome_conjuge} (CPF: {cpf_conjuge})")
        
        try:
            # Extrair dados do cônjuge
            dados_conjuge = self.extrair_dados_associado(cpf_conjuge)
            
            # Verificar se o cônjuge é associado
            is_associado = not dados_conjuge.empty
            
            if is_associado:
                # Formatar dados do cônjuge
                dados_formatados = self.formatar_dados_para_analise(dados_conjuge)
                
                # Determinar tipo de pessoa
                tipo_pessoa = dados_formatados.get("tipo_pessoa", "").upper()
                is_pf = "FISICA" in tipo_pessoa or "FÍSICA" in tipo_pessoa
                
                # Gerar uma análise enxuta do cônjuge
                analise = self.gerar_analise_conjuge(dados_formatados, cpf_conjuge, is_pf)
                
                # Garantir que a renda mensal esteja disponível na resposta
                renda_mensal = dados_formatados.get("renda_mensal", "Não informado")
                
                return {
                    "cpf": cpf_conjuge,
                    "nome": nome_conjuge,
                    "is_associado": True,
                    "dados": dados_formatados,
                    "renda_mensal": renda_mensal,  # Garantindo que a renda esteja explícita
                    "analise": analise
                }
            else:
                # Cônjuge não é associado
                return {
                    "cpf": cpf_conjuge,
                    "nome": nome_conjuge,
                    "is_associado": False,
                    "dados": None,
                    "analise": "O cônjuge não é associado do Sicredi. Há uma oportunidade de prospecção."
                }
                
        except Exception as e:
            logger.error(f"Erro ao analisar cônjuge: {str(e)}")
            return {
                "cpf": cpf_conjuge,
                "nome": nome_conjuge,
                "is_associado": None,
                "erro": str(e),
                "analise": "Não foi possível analisar o cônjuge devido a um erro."
            }
    
    def analisar_socio(self, cpf_socio: str, nome_socio: str, percentual: str) -> Dict[str, Any]:
        """
        Realiza uma análise específica para um sócio de um associado PJ.
        
        Args:
            cpf_socio: CPF do sócio
            nome_socio: Nome do sócio
            percentual: Percentual de participação na empresa
            
        Returns:
            Dicionário com os dados e análise do sócio
        """
        logger.info(f"Analisando sócio: {nome_socio} (CPF: {cpf_socio}, Participação: {percentual})")
        
        try:
            # Extrair dados do sócio
            dados_socio = self.extrair_dados_associado(cpf_socio)
            
            # Verificar se o sócio é associado
            is_associado = not dados_socio.empty
            
            if is_associado:
                # Formatar dados do sócio
                dados_formatados = self.formatar_dados_para_analise(dados_socio)
                
                # Determinar tipo de pessoa
                tipo_pessoa = dados_formatados.get("tipo_pessoa", "").upper()
                is_pf = "FISICA" in tipo_pessoa or "FÍSICA" in tipo_pessoa
                
                # Gerar uma análise enxuta do sócio
                analise = self.gerar_analise_socio(dados_formatados, cpf_socio, is_pf, percentual)
                
                # Garantir que a renda mensal esteja disponível na resposta
                renda_mensal = dados_formatados.get("renda_mensal", "Não informado")
                
                return {
                    "cpf": cpf_socio,
                    "nome": nome_socio,
                    "percentual": percentual,
                    "is_associado": True,
                    "dados": dados_formatados,
                    "renda_mensal": renda_mensal,  # Garantindo que a renda esteja explícita
                    "analise": analise
                }
            else:
                # Sócio não é associado
                return {
                    "cpf": cpf_socio,
                    "nome": nome_socio,
                    "percentual": percentual,
                    "is_associado": False,
                    "dados": None,
                    "analise": f"O sócio não é associado do Sicredi. Com {percentual} de participação na empresa, representa uma oportunidade de prospecção."
                }
                
        except Exception as e:
            logger.error(f"Erro ao analisar sócio: {str(e)}")
            return {
                "cpf": cpf_socio,
                "nome": nome_socio,
                "percentual": percentual,
                "is_associado": None,
                "erro": str(e),
                "analise": "Não foi possível analisar o sócio devido a um erro."
            }
    
    def analisar_grupo_economico(self, codigo_grupo: str, nome_grupo: str) -> Dict[str, Any]:
        """
        Realiza uma análise consolidada de um grupo econômico.
        
        Args:
            codigo_grupo: Código do grupo econômico
            nome_grupo: Nome do grupo econômico
            
        Returns:
            Dicionário com os dados e análise do grupo econômico
        """
        logger.info(f"Analisando grupo econômico: {nome_grupo} (Código: {codigo_grupo})")
        
        try:
            # Extrair dados de todos os associados do grupo
            dados_grupo = self.extrair_dados_grupo_economico(codigo_grupo)
            
            # Verificar se foram encontrados dados
            if dados_grupo.empty:
                return {
                    "codigo": codigo_grupo,
                    "nome": nome_grupo,
                    "qtd_associados": 0,
                    "dados": None,
                    "analise": "Não foram encontrados outros associados pertencentes a este grupo econômico."
                }
            
            # Calcular métricas consolidadas do grupo
            metricas_grupo = self.calcular_metricas_grupo_economico(dados_grupo)
            
            # Gerar análise do grupo econômico
            analise = self.gerar_analise_grupo_economico(metricas_grupo, nome_grupo, dados_grupo)
            
            return {
                "codigo": codigo_grupo,
                "nome": nome_grupo,
                "qtd_associados": len(dados_grupo),
                "metricas": metricas_grupo,
                "associados": dados_grupo.to_dict(orient='records'),
                "analise": analise
            }
                
        except Exception as e:
            logger.error(f"Erro ao analisar grupo econômico: {str(e)}")
            return {
                "codigo": codigo_grupo,
                "nome": nome_grupo,
                "erro": str(e),
                "analise": "Não foi possível analisar o grupo econômico devido a um erro."
            }
    
    def calcular_metricas_grupo_economico(self, dados_grupo: pd.DataFrame) -> Dict[str, Any]:
        """
        Calcula métricas consolidadas para um grupo econômico.
        
        Args:
            dados_grupo: DataFrame com dados de todos os associados do grupo
            
        Returns:
            Dicionário com métricas consolidadas do grupo
        """
        metricas = {}
        
        # Converter colunas numéricas para float
        colunas_numericas = [
            'saldo_total_sicredi_conceito_amplo', 
            'capital_social_saldo',
            'endividamento_total_conceito_amplo', 
            'patrimonio_total',
            'renda_mensal'  # Incluindo renda mensal nas métricas
        ]
        
        for col in colunas_numericas:
            if col in dados_grupo.columns:
                dados_grupo[col] = dados_grupo[col].apply(
                    lambda x: float(str(x).replace('R$', '').replace('.', '').replace(',', '.').strip()) 
                    if isinstance(x, str) else float(x if pd.notna(x) else 0)
                )
        
        # Calcular métricas básicas
        metricas['qtd_associados'] = len(dados_grupo)
        metricas['qtd_pf'] = len(dados_grupo[dados_grupo['tipo_pessoa'].str.contains('FISICA|FÍSICA', case=False, na=False)])
        metricas['qtd_pj'] = len(dados_grupo[dados_grupo['tipo_pessoa'].str.contains('JURIDICA|JURÍDICA', case=False, na=False)])
        
        # Calcular somas
        for col in colunas_numericas:
            if col in dados_grupo.columns:
                metricas[f'total_{col}'] = dados_grupo[col].sum()
                metricas[f'media_{col}'] = dados_grupo[col].mean()
        
        # Calcular métricas de risco
        if 'pd_padrao' in dados_grupo.columns:
            dados_grupo['pd_padrao_num'] = dados_grupo['pd_padrao'].apply(
                lambda x: float(str(x).replace('%', '').replace(',', '.').strip()) 
                if isinstance(x, str) else float(x if pd.notna(x) else 0)
            )
            metricas['pd_media'] = dados_grupo['pd_padrao_num'].mean()
        
        # Contar inadimplentes
        if 'flg_inad' in dados_grupo.columns:
            metricas['qtd_inadimplentes'] = len(dados_grupo[dados_grupo['flg_inad'].str.upper().isin(['SIM', 'S'])])
        
        # Formatar valores monetários
        for chave, valor in metricas.items():
            if any(termo in chave for termo in ['total_', 'media_']):
                metricas[chave] = f"R$ {valor:,.2f}".replace(',', 'X').replace('.', ',').replace('X', '.')
        
        # Formatar percentuais
        if 'pd_media' in metricas:
            metricas['pd_media'] = f"{metricas['pd_media']:.2f}%".replace('.', ',')
        
        # Adicionar explicação sobre conceitos amplos e restritos
        metricas['explicacao_conceitos'] = """
        Conceito Amplo: Inclui todas as operações do associado no sistema financeiro.
        Conceito Restrito: Considera apenas operações diretas com o Sicredi.
        """
        
        return metricas
    
    def consolidar_analises(self, cpf_cnpj: str, dados_principal: Dict[str, Any], 
                           analise_principal: str, analises_relacionadas: Dict[str, Any],
                           is_pf: bool, is_pj: bool) -> str:
        """
        Consolida todas as análises em uma visão integrada do associado e seu ecossistema.
        
        Args:
            cpf_cnpj: CPF/CNPJ do associado principal
            dados_principal: Dados formatados do associado principal
            analise_principal: Análise do associado principal
            analises_relacionadas: Dicionário com análises de cônjuge, sócios e grupo econômico
            is_pf: Booleano indicando se é pessoa física
            is_pj: Booleano indicando se é pessoa jurídica
            
        Returns:
            String com a análise consolidada
        """
        # Construir prompt para o modelo
        prompt = self.construir_prompt_analise_consolidada(
            cpf_cnpj, 
            dados_principal, 
            analise_principal, 
            analises_relacionadas, 
            is_pf, 
            is_pj
        )
        
        # Configurar cliente OpenAI para Databricks
        client = OpenAI(
            api_key='dapie6330b0d1f7ccef0e70f3bdd28b1e2a2',
            base_url="https://sicredi-coop-0914.cloud.databricks.com/serving-endpoints",
            timeout=180.0  # 3 minutos
        )
        
        try:
            # Chamar o modelo
            response = client.chat.completions.create(
                model="databricks-claude-3-7-sonnet",
                messages=[
                    {"role": "system", "content": self.get_system_prompt_consolidado(is_pf, is_pj)},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=8000
            )
            
            # Extrair e retornar a análise
            analise_consolidada = response.choices[0].message.content
            
            # Garantir que a renda mensal esteja mencionada na análise consolidada
            renda_mensal = dados_principal.get("renda_mensal", "Não informado")
            if "renda mensal" not in analise_consolidada.lower():
                # Adicionar informação sobre a renda no início da análise
                analise_consolidada = f"O associado possui renda mensal de {renda_mensal}. " + analise_consolidada
            
            return analise_consolidada
            
        except Exception as e:
            logger.error(f"Erro ao gerar análise consolidada: {str(e)}")
            # Criar uma análise consolidada básica em caso de falha
            renda_mensal = dados_principal.get("renda_mensal", "Não informado")
            nome_associado = dados_principal.get("nome_associado", "Associado")
            
            return f"""
            # Análise Consolidada do Associado {nome_associado}
            
            O associado possui renda mensal de {renda_mensal}.
            
            Não foi possível gerar uma análise consolidada completa devido a um erro técnico: {str(e)}
            
            Recomenda-se analisar os dados individuais disponíveis para uma avaliação completa.
            """
    
    def gerar_analise_com_modelo(self, dados: Dict[str, Any], glossario: str, cpf_cnpj: str, is_pf: bool, is_pj: bool) -> str:
        """
        Gera uma análise do perfil do associado usando um modelo LLM, adaptada ao tipo de pessoa (PF ou PJ).
        
        Args:
            dados: Dicionário com os dados formatados do associado
            glossario: String com o glossário da tabela
            cpf_cnpj: CPF/CNPJ do associado
            is_pf: Booleano indicando se é pessoa física
            is_pj: Booleano indicando se é pessoa jurídica
            
        Returns:
            String com a análise gerada pelo modelo
        """
        # Configurar cliente OpenAI para Databricks
        client = OpenAI(
            api_key='dapie6330b0d1f7ccef0e70f3bdd28b1e2a2',
            base_url="https://sicredi-coop-0914.cloud.databricks.com/serving-endpoints",
            timeout=180.0  # 3 minutos
        )
        
        # Construir o prompt para o modelo, adaptado ao tipo de pessoa
        prompt = self.construir_prompt_para_modelo(dados, glossario, cpf_cnpj, is_pf, is_pj)
        
        # Implementar mecanismo de retry com backoff exponencial
        max_retries = self.max_retries
        retry_delay = 15  # segundos
        
        for attempt in range(max_retries):
            try:
                # Chamar o modelo
                response = client.chat.completions.create(
                    model="databricks-claude-3-7-sonnet",
                    messages=[
                        {"role": "system", "content": self.get_system_prompt(is_pf, is_pj)},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.1,
                    max_tokens=8000
                )
                
                # Extrair a análise
                analise = response.choices[0].message.content
                
                # Garantir que a renda mensal esteja mencionada na análise
                renda_mensal = dados.get("renda_mensal", "Não informado")
                if "renda mensal" not in analise.lower():
                    # Adicionar informação sobre a renda no início da análise
                    analise = f"O associado possui renda mensal de {renda_mensal}. " + analise
                
                # Garantir que os conceitos amplo e restrito sejam explicados se presentes
                if ("conceito amplo" in analise.lower() or "conceito restrito" in analise.lower()):
                    if "diferença entre conceito amplo e restrito" not in analise.lower():
                        explicacao = """
                        
                        Nota sobre conceitos:
                        - Conceito Amplo: Inclui todas as operações do associado no sistema financeiro.
                        - Conceito Restrito: Considera apenas operações diretas com o Sicredi.
                        """
                        analise += explicacao
                
                return analise
                
            except Exception as e:
                logger.warning(f"Tentativa {attempt+1} falhou: {str(e)}")
                
                if "timeout" in str(e).lower() and attempt < max_retries - 1:
                    # Se for timeout e não for a última tentativa, esperar e tentar novamente
                    logger.info(f"Timeout detectado. Tentando novamente em {retry_delay} segundos...")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # Backoff exponencial
                else:
                    # Se for outro erro ou a última tentativa, tentar com modelo de fallback
                    try:
                        logger.info("Tentando com modelo de fallback")
                        # Criar uma versão reduzida do prompt para o modelo de fallback
                        prompt_reduzido = self.construir_prompt_reduzido(dados, cpf_cnpj, is_pf, is_pj)
                        
                        response = client.chat.completions.create(
                            model="databricks-claude-3-7-sonnet",
                            messages=[
                                {"role": "system", "content": self.get_system_prompt_reduzido(is_pf, is_pj)},
                                {"role": "user", "content": prompt_reduzido}
                            ],
                            temperature=0.2,
                            max_tokens=8000
                        )
                        
                        analise = response.choices[0].message.content
                        
                        # Garantir que a renda mensal esteja mencionada na análise
                        renda_mensal = dados.get("renda_mensal", "Não informado")
                        if "renda mensal" not in analise.lower():
                            # Adicionar informação sobre a renda no início da análise
                            analise = f"O associado possui renda mensal de {renda_mensal}. " + analise
                        
                        return analise
                        
                    except Exception as e2:
                        logger.error(f"Erro no modelo de fallback: {str(e2)}")
                        # Em caso de falha total, retornar uma análise básica com os dados principais
                        renda_mensal = dados.get("renda_mensal", "Não informado")
                        nome_associado = dados.get("nome_associado", "Associado")
                        
                        return f"""
                        # Análise Básica do Associado {nome_associado}
                        
                        O associado possui renda mensal de {renda_mensal}.
                        
                        Não foi possível gerar uma análise completa devido a um erro técnico.
                        
                        ## Dados Principais:
                        - CPF/CNPJ: {cpf_cnpj}
                        - Tipo: {"Pessoa Física" if is_pf else "Pessoa Jurídica" if is_pj else "Não identificado"}
                        - Renda Mensal: {renda_mensal}
                        - Patrimônio Total: {dados.get("patrimonio_total", "Não informado")}
                        - Endividamento Total (conceito amplo): {dados.get("endividamento_total_conceito_amplo", "Não informado")}
                        - Saldo Total Sicredi (conceito amplo): {dados.get("saldo_total_sicredi_conceito_amplo", "Não informado")}
                        - Faixa de Risco: {dados.get("faixa_risco_padrao", "Não informado")}
                        """
        
        # Se todas as tentativas falharem
        renda_mensal = dados.get("renda_mensal", "Não informado")
        return f"Erro ao gerar análise. O associado possui renda mensal de {renda_mensal}. Todas as tentativas falharam."
    
    def gerar_analise_conjuge(self, dados: Dict[str, Any], cpf_conjuge: str, is_pf: bool) -> str:
        """
        Gera uma análise específica para o cônjuge de um associado PF.
        
        Args:
            dados: Dicionário com os dados formatados do cônjuge
            cpf_conjuge: CPF do cônjuge
            is_pf: Booleano indicando se é pessoa física
            
        Returns:
            String com a análise do cônjuge
        """
        # Configurar cliente OpenAI para Databricks
        client = OpenAI(
            api_key='dapie6330b0d1f7ccef0e70f3bdd28b1e2a2',
            base_url="https://sicredi-coop-0914.cloud.databricks.com/serving-endpoints",
            timeout=120.0  # 2 minutos
        )
        
        # Construir prompt específico para análise de cônjuge
        prompt = self.construir_prompt_analise_conjuge(dados, cpf_conjuge)
        
        try:
            # Chamar o modelo
            response = client.chat.completions.create(
                model="databricks-claude-3-7-sonnet",
                messages=[
                    {"role": "system", "content": "Você é um analista financeiro especializado em análise de cônjuges de associados. Forneça uma análise concisa mas completa do cônjuge, focando em aspectos que impactam a unidade familiar e o relacionamento com a cooperativa."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=8000
            )
            
            # Extrair a análise
            analise = response.choices[0].message.content
            
            # Garantir que a renda mensal esteja mencionada na análise
            renda_mensal = dados.get("renda_mensal", "Não informado")
            if "renda mensal" not in analise.lower():
                # Adicionar informação sobre a renda no início da análise
                analise = f"O cônjuge possui renda mensal de {renda_mensal}. " + analise
            
            return analise
            
        except Exception as e:
            logger.error(f"Erro ao gerar análise do cônjuge: {str(e)}")
            # Em caso de erro, retornar uma análise básica
            renda_mensal = dados.get("renda_mensal", "Não informado")
            nome_associado = dados.get("nome_associado", "Cônjuge")
            
            return f"""
            # Análise Básica do Cônjuge {nome_associado}
            
            O cônjuge possui renda mensal de {renda_mensal}.
            
            Não foi possível gerar uma análise completa devido a um erro técnico: {str(e)}
            
            ## Dados Principais:
            - CPF: {cpf_conjuge}
            - Renda Mensal: {renda_mensal}
            - Patrimônio Total: {dados.get("patrimonio_total", "Não informado")}
            - Endividamento Total (conceito amplo): {dados.get("endividamento_total_conceito_amplo", "Não informado")}
            - Saldo Total Sicredi (conceito amplo): {dados.get("saldo_total_sicredi_conceito_amplo", "Não informado")}
            """
    
    def gerar_analise_socio(self, dados: Dict[str, Any], cpf_socio: str, is_pf: bool, percentual: str) -> str:
        """
        Gera uma análise específica para um sócio de um associado PJ.
        
        Args:
            dados: Dicionário com os dados formatados do sócio
            cpf_socio: CPF do sócio
            is_pf: Booleano indicando se é pessoa física
            percentual: Percentual de participação na empresa
            
        Returns:
            String com a análise do sócio
        """
        # Configurar cliente OpenAI para Databricks
        client = OpenAI(
            api_key='dapie6330b0d1f7ccef0e70f3bdd28b1e2a2',
            base_url="https://sicredi-coop-0914.cloud.databricks.com/serving-endpoints",
            timeout=120.0  # 2 minutos
        )
        
        # Construir prompt específico para análise de sócio
        prompt = self.construir_prompt_analise_socio(dados, cpf_socio, percentual)
        
        try:
            # Chamar o modelo
            response = client.chat.completions.create(
                model="databricks-claude-3-7-sonnet",
                messages=[
                    {"role": "system", "content": "Você é um analista financeiro especializado em análise de sócios de empresas. Forneça uma análise concisa mas completa do sócio, focando em aspectos que impactam a empresa e o relacionamento com a cooperativa."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=8000
            )
            
            # Extrair a análise
            analise = response.choices[0].message.content
            
            # Garantir que a renda mensal esteja mencionada na análise
            renda_mensal = dados.get("renda_mensal", "Não informado")
            if "renda mensal" not in analise.lower():
                # Adicionar informação sobre a renda no início da análise
                analise = f"O sócio possui renda mensal de {renda_mensal}. " + analise
            
            return analise
            
        except Exception as e:
            logger.error(f"Erro ao gerar análise do sócio: {str(e)}")
            # Em caso de erro, retornar uma análise básica
            renda_mensal = dados.get("renda_mensal", "Não informado")
            nome_associado = dados.get("nome_associado", "Sócio")
            
            return f"""
            # Análise Básica do Sócio {nome_associado}
            
            O sócio possui renda mensal de {renda_mensal} e participação de {percentual} na empresa.
            
            Não foi possível gerar uma análise completa devido a um erro técnico: {str(e)}
            
            ## Dados Principais:
            - CPF: {cpf_socio}
            - Percentual de Participação: {percentual}
            - Renda Mensal: {renda_mensal}
            - Patrimônio Total: {dados.get("patrimonio_total", "Não informado")}
            - Endividamento Total (conceito amplo): {dados.get("endividamento_total_conceito_amplo", "Não informado")}
            - Saldo Total Sicredi (conceito amplo): {dados.get("saldo_total_sicredi_conceito_amplo", "Não informado")}
            """
    
    def gerar_analise_grupo_economico(self, metricas: Dict[str, Any], nome_grupo: str, dados_grupo: pd.DataFrame) -> str:
        """
        Gera uma análise consolidada de um grupo econômico.
        
        Args:
            metricas: Métricas calculadas do grupo econômico
            nome_grupo: Nome do grupo econômico
            dados_grupo: DataFrame com dados de todos os associados do grupo
            
        Returns:
            String com a análise do grupo econômico
        """
        # Configurar cliente OpenAI para Databricks
        client = OpenAI(
            api_key='dapie6330b0d1f7ccef0e70f3bdd28b1e2a2',
            base_url="https://sicredi-coop-0914.cloud.databricks.com/serving-endpoints",
            timeout=120.0  # 2 minutos
        )
        
        # Converter DataFrame para formato de texto para o prompt
        associados_texto = ""
        for i, row in dados_grupo.head(10).iterrows():  # Limitar a 10 associados para não sobrecarregar o prompt
            associados_texto += f"- {row.get('nome_associado', 'Nome não informado')} ({row.get('tipo_pessoa', 'Tipo não informado')}): "
            associados_texto += f"Saldo Total: {row.get('saldo_total_sicredi_conceito_amplo', 'N/A')}, "
            associados_texto += f"Endividamento: {row.get('endividamento_total_conceito_amplo', 'N/A')}, "
            associados_texto += f"Renda Mensal: {row.get('renda_mensal', 'N/A')}\n"  # Incluindo renda mensal
        
        if len(dados_grupo) > 10:
            associados_texto += f"... e mais {len(dados_grupo) - 10} associados não listados."
        
        # Construir prompt para análise do grupo econômico
        prompt = f"""
        # ANÁLISE DE GRUPO ECONÔMICO
        
        ## Nome do Grupo: {nome_grupo}
        
        ## Métricas Consolidadas:
        - Quantidade de Associados: {metricas.get('qtd_associados', 'N/A')}
        - Pessoas Físicas: {metricas.get('qtd_pf', 'N/A')}
        - Pessoas Jurídicas: {metricas.get('qtd_pj', 'N/A')}
        - Saldo Total Sicredi (conceito amplo): {metricas.get('total_saldo_total_sicredi_conceito_amplo', 'N/A')}
        - Capital Social Total: {metricas.get('total_capital_social_saldo', 'N/A')}
        - Endividamento Total (conceito amplo): {metricas.get('total_endividamento_total_conceito_amplo', 'N/A')}
        - Patrimônio Total: {metricas.get('total_patrimonio_total', 'N/A')}
        - Renda Mensal Total: {metricas.get('total_renda_mensal', 'N/A')}
        - Renda Mensal Média: {metricas.get('media_renda_mensal', 'N/A')}
        - PD Média: {metricas.get('pd_media', 'N/A')}
        - Quantidade de Inadimplentes: {metricas.get('qtd_inadimplentes', 'N/A')}
        
        {metricas.get('explicacao_conceitos', '')}
        
        ## Principais Associados do Grupo:
        {associados_texto}
        
        # SOLICITAÇÃO DE ANÁLISE
        
        Com base nos dados acima, forneça uma análise consolidada do grupo econômico, abordando:
        
        1. Relevância do grupo para a cooperativa (tamanho, volume financeiro)
        2. Perfil de risco consolidado do grupo
        3. Exposição total de crédito e investimentos
        4. Principais entidades do grupo e suas relações
        5. Riscos sistêmicos que podem afetar todo o grupo
        6. Oportunidades de negócio considerando o grupo como um todo
        
        Seja conciso mas abrangente, focando nos aspectos mais relevantes para a tomada de decisão estratégica.
        Certifique-se de mencionar explicitamente a renda mensal total e média do grupo em sua análise.
        """
        
        try:
            # Chamar o modelo
            response = client.chat.completions.create(
                model="databricks-claude-3-7-sonnet",
                messages=[
                    {"role": "system", "content": "Você é um analista financeiro especializado em análise de grupos econômicos. Forneça uma análise consolidada e estratégica do grupo, focando em aspectos que impactam o relacionamento com a cooperativa."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=8000
            )
            
            # Extrair a análise
            analise = response.choices[0].message.content
            
            # Garantir que a renda mensal esteja mencionada na análise
            renda_total = metricas.get('total_renda_mensal', 'Não informado')
            if "renda mensal" not in analise.lower():
                # Adicionar informação sobre a renda no início da análise
                analise = f"O grupo econômico possui renda mensal total de {renda_total}. " + analise
            
            return analise
            
        except Exception as e:
            logger.error(f"Erro ao gerar análise do grupo econômico: {str(e)}")
            # Em caso de erro, retornar uma análise básica
            renda_total = metricas.get('total_renda_mensal', 'Não informado')
            
            return f"""
            # Análise Básica do Grupo Econômico {nome_grupo}
            
            O grupo econômico possui renda mensal total de {renda_total}.
            
            Não foi possível gerar uma análise completa devido a um erro técnico: {str(e)}
            
            ## Dados Principais:
            - Quantidade de Associados: {metricas.get('qtd_associados', 'N/A')}
            - Pessoas Físicas: {metricas.get('qtd_pf', 'N/A')}
            - Pessoas Jurídicas: {metricas.get('qtd_pj', 'N/A')}
            - Saldo Total Sicredi (conceito amplo): {metricas.get('total_saldo_total_sicredi_conceito_amplo', 'N/A')}
            - Endividamento Total (conceito amplo): {metricas.get('total_endividamento_total_conceito_amplo', 'N/A')}
            - Renda Mensal Total: {renda_total}
            """
    
    def get_system_prompt(self, is_pf: bool, is_pj: bool) -> str:
        """
        Retorna o prompt de sistema para o modelo LLM, adaptado ao tipo de pessoa.
        
        Args:
            is_pf: Booleano indicando se é pessoa física
            is_pj: Booleano indicando se é pessoa jurídica
            
        Returns:
            String com o prompt de sistema
        """
        base_prompt = """
        Você é um analista financeiro especializado do Sicredi, com vasta experiência em análise de perfil de associados de cooperativas de crédito. 
        
        Sua função é fornecer análises técnicas detalhadas e estratégicas que ajudem os gestores a compreender profundamente o perfil dos associados, 
        identificar oportunidades de negócio e mitigar riscos. Suas análises devem ser:
        
        1. Extremamente detalhadas e abrangentes
        2. Tecnicamente precisas e fundamentadas em dados
        3. Estratégicas e orientadas a ações concretas
        4. Estruturadas de forma clara e lógica
        5. Focadas em insights que gerem valor para a cooperativa e para o associado
        
        Utilize uma linguagem técnica apropriada para profissionais do setor financeiro, mas mantenha a clareza.
        
        IMPORTANTE: Sempre mencione explicitamente o valor da renda mensal do associado em sua análise.
        Também explique claramente a diferença entre valores em "conceito amplo" (todo o sistema financeiro) e 
        "conceito restrito" (apenas operações com o Sicredi) quando estes termos aparecerem.
        """
        
        if is_pf:
            return base_prompt + """
            
            O associado em análise é uma PESSOA FÍSICA. Considere aspectos relevantes como:
            - Ciclo de vida e momento financeiro do indivíduo
            - Perfil profissional e estabilidade da renda
            - Comportamento financeiro pessoal
            - Necessidades financeiras típicas de pessoa física (crédito pessoal, financiamentos, investimentos para objetivos pessoais)
            - Relação familiar e impacto na situação financeira
            - Potencial de relacionamento de longo prazo com a cooperativa
            """
        
        elif is_pj:
            return base_prompt + """
            
            O associado em análise é uma PESSOA JURÍDICA. Considere aspectos relevantes como:
            - Natureza jurídica e setor de atuação da empresa
            - Estrutura societária e perfil dos sócios
            - Necessidades financeiras típicas de empresas (capital de giro, investimentos, financiamentos para expansão)
            - Saúde financeira do negócio
            - Potencial de relacionamento comercial ampliado (folha de pagamento, serviços financeiros para funcionários)
            - Oportunidades de cross-selling com produtos específicos para PJ
            """
        
        else:
            return base_prompt
    
    def get_system_prompt_reduzido(self, is_pf: bool, is_pj: bool) -> str:
        """
        Retorna o prompt de sistema reduzido para o modelo de fallback, adaptado ao tipo de pessoa.
        
        Args:
            is_pf: Booleano indicando se é pessoa física
            is_pj: Booleano indicando se é pessoa jurídica
            
        Returns:
            String com o prompt de sistema reduzido
        """
        base_prompt = """
        Você é um analista financeiro especializado do Sicredi. Forneça uma análise técnica e estratégica do perfil do associado,
        identificando oportunidades de negócio e riscos. Seja detalhado, preciso e objetivo.
        
        IMPORTANTE: Sempre mencione explicitamente o valor da renda mensal do associado em sua análise.
        Também explique claramente a diferença entre valores em "conceito amplo" (todo o sistema financeiro) e 
        "conceito restrito" (apenas operações com o Sicredi) quando estes termos aparecerem.
        """
        
        if is_pf:
            return base_prompt + " O associado é uma PESSOA FÍSICA."
        elif is_pj:
            return base_prompt + " O associado é uma PESSOA JURÍDICA."
        else:
            return base_prompt
    
    def get_system_prompt_consolidado(self, is_pf: bool, is_pj: bool) -> str:
        """
        Retorna o prompt de sistema para a análise consolidada.
        
        Args:
            is_pf: Booleano indicando se é pessoa física
            is_pj: Booleano indicando se é pessoa jurídica
            
        Returns:
            String com o prompt de sistema para análise consolidada
        """
        base_prompt = """
        Você é um analista financeiro sênior do Sicredi, especializado em análises holísticas e sistêmicas. 
        Sua função é integrar múltiplas análises individuais em uma visão consolidada e estratégica que capture 
        as interrelações, padrões emergentes e dinâmicas de grupo que não seriam evidentes em análises isoladas.
        
        Sua análise consolidada deve:
        1. Identificar padrões e conexões entre os diferentes associados analisados
        2. Avaliar riscos sistêmicos e oportunidades sinérgicas
        3. Fornecer uma visão estratégica do ecossistema financeiro do associado principal
        4. Destacar insights que só emergem da análise integrada
        
        IMPORTANTE: Sempre mencione explicitamente o valor da renda mensal do associado principal em sua análise.
        Também explique claramente a diferença entre valores em "conceito amplo" (todo o sistema financeiro) e 
        "conceito restrito" (apenas operações com o Sicredi) quando estes termos aparecerem.
        """
        
        if is_pf:
            return base_prompt + """
            
            O associado principal é uma PESSOA FÍSICA. Considere especialmente:
            - A dinâmica financeira familiar, incluindo o cônjuge
            - O impacto das relações familiares na saúde financeira global
            - Estratégias que considerem o casal como unidade financeira
            - Ciclos de vida e momentos financeiros compartilhados
            """
        
        elif is_pj:
            return base_prompt + """
            
            O associado principal é uma PESSOA JURÍDICA. Considere especialmente:
            - A relação entre a empresa e seus sócios
            - Fluxos financeiros entre pessoas jurídicas e físicas relacionadas
            - Riscos de contágio financeiro entre entidades do mesmo grupo
            - Oportunidades de negócio que abranjam tanto a empresa quanto seus sócios
            - Estratégias para o ecossistema empresarial como um todo
            """
        
        else:
            return base_prompt
    
    def construir_prompt_para_modelo(self, dados: Dict[str, Any], glossario: str, cpf_cnpj: str, is_pf: bool, is_pj: bool) -> str:
        """
        Constrói o prompt detalhado para o modelo LLM, adaptado ao tipo de pessoa.
        
        Args:
            dados: Dicionário com os dados formatados do associado
            glossario: String com o glossário da tabela
            cpf_cnpj: CPF/CNPJ do associado
            is_pf: Booleano indicando se é pessoa física
            is_pj: Booleano indicando se é pessoa jurídica
            
        Returns:
            String contendo o prompt completo
        """
        # Criar uma versão resumida do glossário para o prompt
        glossario_resumido = """
        GLOSSÁRIO RESUMIDO DOS CAMPOS MAIS IMPORTANTES:
        
        - num_cpf_cnpj: Identificador único do associado (CPF ou CNPJ)
        - nome_associado: Nome completo do associado
        - tipo_pessoa: Classificação como Pessoa Física ou Pessoa Jurídica
        - data_inicio_associacao: Data em que se tornou associado
        - anos_de_associacao: Tempo em anos desde que se tornou associado
        - des_segmento/des_subsegmento: Segmentação de mercado do associado
        - renda_mensal: Média mensal de renda do associado
        - patrimonio_total: Valor total do patrimônio declarado
        - capital_social_saldo: Valor investido em cotas de capital social da cooperativa
        - saldo_total_sicredi_conceito_amplo: Soma de todos os valores em produtos financeiros no Sicredi, incluindo operações em todo o sistema financeiro
        - scr_total_conceito_restrito: Valor total das operações registradas no SCR do Banco Central, considerando apenas operações diretas com a instituição
        - principalidade: Indica se o Sicredi é o principal banco do associado
        - isa: Índice Sicredi de Atividade - mede o nível de atividade do relacionamento
        - percentual_comprometido_renda: Percentual da renda comprometido com dívidas
        - endividamento_total_conceito_amplo: Soma de todas as dívidas do associado, incluindo operações em todo o sistema financeiro
        - flg_inad: Indica se o associado está inadimplente
        - faixa_risco_padrao: Classificação padronizada de risco
        - pd_padrao: Probability of Default - probabilidade de inadimplência
        """
        
        # Adicionar explicação sobre conceitos amplo e restrito
        conceitos_explicacao = """
        EXPLICAÇÃO SOBRE CONCEITOS AMPLO E RESTRITO:
        
        - Conceito Amplo: Inclui todas as operações do associado no sistema financeiro.
        - Conceito Restrito: Considera apenas operações diretas com o Sicredi.
        """
        
        # Iniciar o prompt com informações básicas
        prompt = f"""
        # ANÁLISE DE PERFIL DO ASSOCIADO SICREDI
        
        ## CPF/CNPJ: {cpf_cnpj}
        ## Tipo: {"PESSOA FÍSICA" if is_pf else "PESSOA JURÍDICA" if is_pj else "NÃO IDENTIFICADO"}
        
        {glossario_resumido}
        
        {conceitos_explicacao}
        
        Abaixo estão os dados do associado organizados por categorias:
        """
        
        # Adicionar dados de identificação básica
        prompt += "\n\n## 1. IDENTIFICAÇÃO BÁSICA\n"
        for campo in ["num_cpf_cnpj", "nome_associado", "tipo_pessoa", "des_segmento", "des_subsegmento", "des_publico_estrategico"]:
            if campo in dados and dados[campo] is not None:
                prompt += f"- {campo}: {dados[campo]}\n"
        
        # Adicionar dados específicos para pessoa física
        if is_pf:
            prompt += "\n\n## 2. DADOS DEMOGRÁFICOS (PESSOA FÍSICA)\n"
            for campo in ["idade", "flg_sexo", "des_estado_civil", "des_cbo", "trabalha_no_sicredi", "des_cargo_sicredi"]:
                if campo in dados and dados[campo] is not None:
                    prompt += f"- {campo}: {dados[campo]}\n"
            
            # Adicionar dados do cônjuge se disponíveis
            if "nome_pessoa_conjuge" in dados and dados["nome_pessoa_conjuge"] is not None:
                prompt += "\n### Dados do Cônjuge\n"
                for campo in ["nome_pessoa_conjuge", "cpf_conjuge", "tempo_uniao", "nome_regime_bem", "uniao_estavel"]:
                    if campo in dados and dados[campo] is not None:
                        prompt += f"- {campo}: {dados[campo]}\n"
        
        # Adicionar dados específicos para pessoa jurídica
        if is_pj:
            prompt += "\n\n## 2. DADOS EMPRESARIAIS (PESSOA JURÍDICA)\n"
            for campo in ["des_natureza_juridica", "des_cnae", "cod_cnae", "qt_socios"]:
                if campo in dados and dados[campo] is not None:
                    prompt += f"- {campo}: {dados[campo]}\n"
            
            # Adicionar dados dos sócios se disponíveis
            if "socios_estruturados" in dados and dados["socios_estruturados"]:
                prompt += "\n### Quadro Societário\n"
                for i, socio in enumerate(dados["socios_estruturados"]):
                    prompt += f"- Sócio {i+1}: {socio['nome']} (CPF: {socio['cpf']}) - Participação: {socio['percentual']}\n"
        
        # Adicionar dados de relacionamento com a cooperativa
        prompt += "\n\n## 3. RELACIONAMENTO COM A COOPERATIVA\n"
        for campo in ["data_inicio_associacao", "anos_de_associacao", "flg_correntista", "flg_carteira_ativa", 
                     "nom_carteira", "num_conta", "cod_agencia", "nome_agencia", "des_status_conta", 
                     "nom_gestor_carteira", "isa", "principalidade", "score_principalidade"]:
            if campo in dados and dados[campo] is not None:
                prompt += f"- {campo}: {dados[campo]}\n"
        
        # Adicionar dados de grupo econômico se disponíveis
        if dados.get("nome_grupo_economico") or dados.get("Codigo_conglomerado_economico"):
            prompt += "\n### Grupo Econômico\n"
            for campo in ["nome_grupo_economico", "Codigo_conglomerado_economico"]:
                if campo in dados and dados[campo] is not None:
                    prompt += f"- {campo}: {dados[campo]}\n"
        
        # Adicionar métricas calculadas de relacionamento
        if "metricas_calculadas" in dados and "classificacao_tempo_relacionamento" in dados["metricas_calculadas"]:
            prompt += f"- classificacao_tempo_relacionamento: {dados['metricas_calculadas']['classificacao_tempo_relacionamento']}\n"
        
        # Adicionar dados de atualização cadastral
        prompt += "\n### Atualização Cadastral\n"
        for campo in ["data_ultima_atualizacao_cadastral", "dias_desde_ultima_atualizacao_conta",
                     "data_ultima_atualizacao_renda", "dias_desde_ultima_atualizacao_renda"]:
            if campo in dados and dados[campo] is not None:
                prompt += f"- {campo}: {dados[campo]}\n"
        
        if "metricas_calculadas" in dados and "status_atualizacao_cadastral" in dados["metricas_calculadas"]:
            prompt += f"- status_atualizacao_cadastral: {dados['metricas_calculadas']['status_atualizacao_cadastral']}\n"
        
        # Adicionar dados financeiros
        prompt += "\n\n## 4. SITUAÇÃO FINANCEIRA\n"
        
        # Destacar a renda mensal como informação crucial
        if "renda_mensal" in dados and dados["renda_mensal"] is not None:
            prompt += f"- renda_mensal: {dados['renda_mensal']} (INFORMAÇÃO CRUCIAL)\n"
        else:
            prompt += f"- renda_mensal: Não informado (INFORMAÇÃO CRUCIAL)\n"
        
        for campo in ["patrimonio_total", "capital_social_saldo", 
                     "saldo_total_sicredi_conceito_amplo", "saldo_conta_corrente", "sld_fundos", "qt_fundos"]:
            if campo in dados and dados[campo] is not None:
                # Adicionar explicação para campos com conceito amplo/restrito
                if "conceito_amplo" in campo:
                    prompt += f"- {campo}: {dados[campo]} (inclui operações em todo o sistema financeiro)\n"
                elif "conceito_restrito" in campo:
                    prompt += f"- {campo}: {dados[campo]} (considera apenas operações diretas com o Sicredi)\n"
                else:
                    prompt += f"- {campo}: {dados[campo]}\n"
        
        # Adicionar relação patrimônio/renda se calculada
        if "metricas_calculadas" in dados and "relacao_patrimonio_renda" in dados["metricas_calculadas"]:
            prompt += f"- relacao_patrimonio_renda: {dados['metricas_calculadas']['relacao_patrimonio_renda']} meses de renda\n"
            if "classificacao_patrimonio_renda" in dados["metricas_calculadas"]:
                prompt += f"- classificacao_patrimonio_renda: {dados['metricas_calculadas']['classificacao_patrimonio_renda']}\n"
        
        # Adicionar dados de crédito e limites
        prompt += "\n\n## 5. CRÉDITO E LIMITES\n"
        for campo in ["limite_cheque_especial", "limite_utilizado_cheque_especial", 
                     "limite_cartao_credito", "limite_utilizado_cartao_credito", 
                     "valor_adiantamento", "flg_cheque_especial"]:
            if campo in dados and dados[campo] is not None:
                prompt += f"- {campo}: {dados[campo]}\n"
        
        # Adicionar percentuais de utilização calculados
        if "metricas_calculadas" in dados:
            if "percentual_uso_cheque_especial" in dados["metricas_calculadas"]:
                prompt += f"- percentual_uso_cheque_especial: {dados['metricas_calculadas']['percentual_uso_cheque_especial']}\n"
            if "percentual_uso_cartao_credito" in dados["metricas_calculadas"]:
                prompt += f"- percentual_uso_cartao_credito: {dados['metricas_calculadas']['percentual_uso_cartao_credito']}\n"
        
        # Adicionar dados de comportamento de uso de crédito
        prompt += "\n### Comportamento de Uso de Crédito\n"
        for campo in ["uso_cheque_especial_ultimos_3meses", "uso_credito_rotativo_ultimos_3meses",
                     "uso_credito_facil_ultimos_3meses", "uso_rotativo_cartao_ultimos_6meses",
                     "cheques_devolvidos_ultimos_6meses", "pix_trans_30d"]:
            if campo in dados and dados[campo] is not None:
                prompt += f"- {campo}: {dados[campo]}\n"
        
        # Adicionar dados de endividamento
        prompt += "\n\n## 6. ENDIVIDAMENTO\n"
        for campo in ["comprometimento_mensal", "percentual_comprometido_renda",
                     "scr_total_conceito_restrito", "valor_cpr_b3", "endividamento_total_conceito_amplo",
                     "percentual_comprometimento_patrimonio"]:
            if campo in dados and dados[campo] is not None:
                # Adicionar explicação para campos com conceito amplo/restrito
                if "conceito_amplo" in campo:
                    prompt += f"- {campo}: {dados[campo]} (inclui operações em todo o sistema financeiro)\n"
                elif "conceito_restrito" in campo:
                    prompt += f"- {campo}: {dados[campo]} (considera apenas operações diretas com o Sicredi)\n"
                else:
                    prompt += f"- {campo}: {dados[campo]}\n"
        
        # Adicionar classificação de saúde financeira
        if "metricas_calculadas" in dados and "classificacao_saude_financeira" in dados["metricas_calculadas"]:
            prompt += f"- classificacao_saude_financeira: {dados['metricas_calculadas']['classificacao_saude_financeira']}\n"
        
        # Adicionar dados de restritivos e inadimplência
        prompt += "\n\n## 7. RESTRITIVOS E INADIMPLÊNCIA\n"
        for campo in ["flg_inad", "valor_total_restritivos", "restricao_serasa", "restricao_spc", "restricao_scr"]:
            if campo in dados and dados[campo] is not None:
                prompt += f"- {campo}: {dados[campo]}\n"
        
        # Adicionar detalhamento de restritivos se houver
        if "valor_total_restritivos" in dados and dados["valor_total_restritivos"] and dados["valor_total_restritivos"] != "R$ 0,00":
            prompt += "\n### Detalhamento de Restritivos\n"
            for campo in ["qtd_restritivos_serasa", "vlr_restritivos_serasa", "qtd_restritivos_spc", "vlr_restritivos_spc",
                         "qtd_pefin", "vlr_pefin", "qtd_refin", "vlr_refin", "qtd_dividas", "vlr_dividas",
                         "qtd_ch_serasa", "vlr_ch_serasa", "qtd_protesto", "vlr_protesto",
                         "qtd_acao_judicial", "vlr_acao_judicial"]:
                if campo in dados and dados[campo] is not None and dados[campo] != 0 and dados[campo] != "R$ 0,00":
                    prompt += f"- {campo}: {dados[campo]}\n"
        
        # Adicionar dados de risco
        prompt += "\n\n## 8. PERFIL DE RISCO\n"
        for campo in ["descr_modelo", "faixa_risco_padrao", "pd_padrao", "pp_padrao"]:
            if campo in dados and dados[campo] is not None:
                prompt += f"- {campo}: {dados[campo]}\n"
        
        # Adicionar instruções para a análise
        prompt += """
        
        # SOLICITAÇÃO DE ANÁLISE
        
        Com base nos dados apresentados acima, elabore uma análise completa e detalhada do perfil deste associado do Sicredi. 
        Sua análise deve ser técnica, estratégica e abrangente, abordando os seguintes aspectos:
        
        ## 1. PERFIL SOCIODEMOGRÁFICO E PROFISSIONAL
        - Caracterização completa do associado
        - Análise do segmento e relevância estratégica
        """
        
        # Adicionar instruções específicas para PF ou PJ
        if is_pf:
            prompt += """
        - Análise do ciclo de vida, situação familiar e profissional
        - Potencial econômico com base na profissão, idade e perfil
        """
        elif is_pj:
            prompt += """
        - Análise do setor de atuação e natureza jurídica
        - Análise da estrutura societária e suas implicações
        - Potencial econômico com base no setor e porte
        """
        
        # Continuar com instruções gerais
        prompt += """
        
        ## 2. RELACIONAMENTO COM A COOPERATIVA
        - Análise do tempo e qualidade do relacionamento
        - Avaliação da satisfação do associado (ISA)
        - Análise da principalidade e potencial de aprofundamento
        - Avaliação da atualização cadastral e suas implicações
        - Análise do portfólio de produtos utilizados
        - Identificação de gaps de produtos e oportunidades de cross-selling
        
        ## 3. PERFIL FINANCEIRO
        - Análise da renda/faturamento e sua adequação ao segmento
        - Avaliação do patrimônio e capacidade financeira
        - Análise do capital social e engajamento cooperativo
        - Análise do endividamento total (interno e externo)
        - Avaliação do comprometimento de renda e patrimônio
        - Análise do comportamento de uso de crédito rotativo
        
        ## 4. PERFIL DE RISCO
        - Avaliação da classificação de risco e seus determinantes
        - Análise dos restritivos e seu impacto no relacionamento
        - Avaliação da gravidade e recorrência de problemas financeiros
        
        ## 5. OPORTUNIDADES E ALERTAS
        - Identificação de oportunidades de negócio específicas
        - Estratégias para aprofundamento do relacionamento
        - Recomendações para atualização cadastral (quando aplicável)
        - Identificação de sinais de alerta no comportamento financeiro
        - Recomendações para mitigação de riscos identificados
        
        ## 6. CONCLUSÃO
        - Síntese do perfil do associado e seu valor para a cooperativa
        - Avaliação do potencial de longo prazo do relacionamento
        - Próximos passos recomendados para o gestor da conta
        
        Sua análise deve ser extremamente detalhada, precisa e técnica, apresentando sempre dados concretos e quantitativos.
        Utilize formatação estruturada para facilitar a compreensão. Não omita nenhuma informação relevante, pois esta análise
        será utilizada como base para decisões críticas de relacionamento e negócios.
        
        IMPORTANTE: Certifique-se de mencionar explicitamente o valor da renda mensal do associado em sua análise.
        Também explique claramente a diferença entre valores em "conceito amplo" e "conceito restrito" quando estes termos aparecerem.
        """
        
        return prompt
    
    def construir_prompt_reduzido(self, dados: Dict[str, Any], cpf_cnpj: str, is_pf: bool, is_pj: bool) -> str:
        """
        Constrói uma versão reduzida do prompt para o modelo de fallback.
        
        Args:
            dados: Dicionário com os dados formatados do associado
            cpf_cnpj: CPF/CNPJ do associado
            is_pf: Booleano indicando se é pessoa física
            is_pj: Booleano indicando se é pessoa jurídica
            
        Returns:
            String contendo o prompt reduzido
        """
        # Criar uma versão resumida com apenas os dados mais importantes
        prompt = f"""
        # ANÁLISE DE PERFIL DO ASSOCIADO SICREDI - CPF/CNPJ: {cpf_cnpj}
        
        ## TIPO: {"PESSOA FÍSICA" if is_pf else "PESSOA JURÍDICA" if is_pj else "NÃO IDENTIFICADO"}
        
        ## DADOS BÁSICOS
        - Nome: {dados.get('nome_associado', 'Não informado')}
        - Segmento: {dados.get('des_segmento', 'Não informado')}
        """
        
        if is_pf:
            prompt += f"""
        - Idade: {dados.get('idade', 'Não informado')}
        - Gênero: {dados.get('flg_sexo', 'Não informado')}
        - Estado Civil: {dados.get('des_estado_civil', 'Não informado')}
        - Ocupação: {dados.get('des_cbo', 'Não informado')}
        """
        
        if is_pj:
            prompt += f"""
        - Natureza Jurídica: {dados.get('des_natureza_juridica', 'Não informado')}
        - Atividade: {dados.get('des_cnae', 'Não informado')}
        - Quantidade de Sócios: {dados.get('qt_socios', 'Não informado')}
        """
        
        prompt += f"""
        
        ## RELACIONAMENTO
        - Tempo de Relacionamento: {dados.get('anos_de_associacao', 'Não informado')} anos
        - Correntista: {dados.get('flg_correntista', 'Não informado')}
        - Carteira Ativa: {dados.get('flg_carteira_ativa', 'Não informado')}
        - ISA: {dados.get('isa', 'Não informado')}
        - Principalidade: {dados.get('principalidade', 'Não informado')}
        
        ## FINANCEIRO
        - Renda Mensal: {dados.get('renda_mensal', 'Não informado')} (INFORMAÇÃO CRUCIAL)
        - Patrimônio Total: {dados.get('patrimonio_total', 'Não informado')}
        - Saldo Total Sicredi (conceito amplo): {dados.get('saldo_total_sicredi_conceito_amplo', 'Não informado')}
        - Capital Social: {dados.get('capital_social_saldo', 'Não informado')}
        - Comprometimento Mensal: {dados.get('comprometimento_mensal', 'Não informado')}
        - Percentual da Renda Comprometido: {dados.get('percentual_comprometido_renda', 'Não informado')}
        - Endividamento Total (conceito amplo): {dados.get('endividamento_total_conceito_amplo', 'Não informado')}
        - SCR Total (conceito restrito): {dados.get('scr_total_conceito_restrito', 'Não informado')}
        
        ## RISCO E RESTRITIVOS
        - Inadimplente: {dados.get('flg_inad', 'Não informado')}
        - Valor Total Restritivos: {dados.get('valor_total_restritivos', 'Não informado')}
        - Faixa de Risco: {dados.get('faixa_risco_padrao', 'Não informado')}
        - PD (Probability of Default): {dados.get('pd_padrao', 'Não informado')}
        
        ## EXPLICAÇÃO DE CONCEITOS
        - Conceito Amplo: Inclui todas as operações do associado no sistema financeiro.
        - Conceito Restrito: Considera apenas operações diretas com o Sicredi.
        
        # SOLICITAÇÃO DE ANÁLISE
        
        Com base nos dados acima, forneça uma análise completa e detalhada do perfil do associado, abordando:
        
        1. Perfil sociodemográfico e profissional
        2. Relacionamento com a cooperativa
        3. Capacidade financeira e endividamento
        4. Perfil de risco
        5. Oportunidades e alertas
        
        Sua análise deve ser técnica, estratégica e orientada a ações concretas para o gestor da conta.
        
        IMPORTANTE: Certifique-se de mencionar explicitamente o valor da renda mensal do associado em sua análise.
        Também explique claramente a diferença entre valores em "conceito amplo" e "conceito restrito" quando relevante.
        """
        
        return prompt
    
    def construir_prompt_analise_conjuge(self, dados: Dict[str, Any], cpf_conjuge: str) -> str:
        """
        Constrói o prompt para análise específica do cônjuge.
        
        Args:
            dados: Dicionário com os dados formatados do cônjuge
            cpf_conjuge: CPF do cônjuge
            
        Returns:
            String contendo o prompt para análise do cônjuge
        """
        # Selecionar apenas os campos mais relevantes para a análise do cônjuge
        prompt = f"""
        # ANÁLISE DE CÔNJUGE DE ASSOCIADO SICREDI
        
        ## CPF: {cpf_conjuge}
        ## Nome: {dados.get('nome_associado', 'Não informado')}
        
        ## DADOS BÁSICOS
        - Idade: {dados.get('idade', 'Não informado')}
        - Gênero: {dados.get('flg_sexo', 'Não informado')}
        - Ocupação: {dados.get('des_cbo', 'Não informado')}
        - Segmento: {dados.get('des_segmento', 'Não informado')}
        
        ## RELACIONAMENTO COM A COOPERATIVA
        - Tempo de Associação: {dados.get('anos_de_associacao', 'Não informado')} anos
        - Correntista: {dados.get('flg_correntista', 'Não informado')}
        - ISA: {dados.get('isa', 'Não informado')}
        - Principalidade: {dados.get('principalidade', 'Não informado')}
        
        ## SITUAÇÃO FINANCEIRA
        - Renda Mensal: {dados.get('renda_mensal', 'Não informado')} (INFORMAÇÃO CRUCIAL)
        - Patrimônio Total: {dados.get('patrimonio_total', 'Não informado')}
        - Saldo Total Sicredi (conceito amplo): {dados.get('saldo_total_sicredi_conceito_amplo', 'Não informado')}
        - Capital Social: {dados.get('capital_social_saldo', 'Não informado')}
        
        ## ENDIVIDAMENTO E RISCO
        - Percentual da Renda Comprometido: {dados.get('percentual_comprometido_renda', 'Não informado')}
        - Endividamento Total (conceito amplo): {dados.get('endividamento_total_conceito_amplo', 'Não informado')}
        - SCR Total (conceito restrito): {dados.get('scr_total_conceito_restrito', 'Não informado')}
        - Inadimplente: {dados.get('flg_inad', 'Não informado')}
        - Valor Total Restritivos: {dados.get('valor_total_restritivos', 'Não informado')}
        - Faixa de Risco: {dados.get('faixa_risco_padrao', 'Não informado')}
        
        ## EXPLICAÇÃO DE CONCEITOS
        - Conceito Amplo: Inclui todas as operações no sistema financeiro.
        - Conceito Restrito: Considera apenas operações diretas com o Sicredi.
        
        # SOLICITAÇÃO DE ANÁLISE
        
        Com base nos dados acima, forneça uma análise concisa mas completa do cônjuge, focando em:
        
        1. Perfil financeiro do cônjuge e sua contribuição para a unidade familiar
        2. Qualidade do relacionamento do cônjuge com a cooperativa
        3. Riscos ou oportunidades que o perfil do cônjuge apresenta
        4. Como o perfil do cônjuge complementa ou contrasta com o do associado principal
        
        Seja objetivo e direto, destacando apenas os aspectos mais relevantes para a análise integrada do casal.
        
        IMPORTANTE: Certifique-se de mencionar explicitamente o valor da renda mensal do cônjuge em sua análise.
        Também explique claramente a diferença entre valores em "conceito amplo" e "conceito restrito" quando relevante.
        """
        
        return prompt
    
    def construir_prompt_analise_socio(self, dados: Dict[str, Any], cpf_socio: str, percentual: str) -> str:
        """
        Constrói o prompt para análise específica de um sócio.
        
        Args:
            dados: Dicionário com os dados formatados do sócio
            cpf_socio: CPF do sócio
            percentual: Percentual de participação na empresa
            
        Returns:
            String contendo o prompt para análise do sócio
        """
        # Selecionar apenas os campos mais relevantes para a análise do sócio
        prompt = f"""
        # ANÁLISE DE SÓCIO DE EMPRESA ASSOCIADA SICREDI
        
        ## CPF: {cpf_socio}
        ## Nome: {dados.get('nome_associado', 'Não informado')}
        ## Percentual de Participação: {percentual}
        
        ## DADOS BÁSICOS
        - Idade: {dados.get('idade', 'Não informado')}
        - Gênero: {dados.get('flg_sexo', 'Não informado')}
        - Ocupação: {dados.get('des_cbo', 'Não informado')}
        - Segmento: {dados.get('des_segmento', 'Não informado')}
        
        ## RELACIONAMENTO COM A COOPERATIVA
        - Tempo de Associação: {dados.get('anos_de_associacao', 'Não informado')} anos
        - Correntista: {dados.get('flg_correntista', 'Não informado')}
        - ISA: {dados.get('isa', 'Não informado')}
        - Principalidade: {dados.get('principalidade', 'Não informado')}
        
        ## SITUAÇÃO FINANCEIRA
        - Renda Mensal: {dados.get('renda_mensal', 'Não informado')} (INFORMAÇÃO CRUCIAL)
        - Patrimônio Total: {dados.get('patrimonio_total', 'Não informado')}
        - Saldo Total Sicredi (conceito amplo): {dados.get('saldo_total_sicredi_conceito_amplo', 'Não informado')}
        - Capital Social: {dados.get('capital_social_saldo', 'Não informado')}
        
        ## ENDIVIDAMENTO E RISCO
        - Percentual da Renda Comprometido: {dados.get('percentual_comprometido_renda', 'Não informado')}
        - Endividamento Total (conceito amplo): {dados.get('endividamento_total_conceito_amplo', 'Não informado')}
        - SCR Total (conceito restrito): {dados.get('scr_total_conceito_restrito', 'Não informado')}
        - Inadimplente: {dados.get('flg_inad', 'Não informado')}
        - Valor Total Restritivos: {dados.get('valor_total_restritivos', 'Não informado')}
        - Faixa de Risco: {dados.get('faixa_risco_padrao', 'Não informado')}
        
        ## EXPLICAÇÃO DE CONCEITOS
        - Conceito Amplo: Inclui todas as operações no sistema financeiro.
        - Conceito Restrito: Considera apenas operações diretas com o Sicredi.
        
        # SOLICITAÇÃO DE ANÁLISE
        
        Com base nos dados acima, forneça uma análise concisa mas completa do sócio, focando em:
        
        1. Perfil financeiro do sócio e sua relevância para a empresa (considerando seu percentual de participação)
        2. Qualidade do relacionamento do sócio com a cooperativa
        3. Riscos ou oportunidades que o perfil do sócio apresenta para a empresa
        4. Como o perfil financeiro do sócio pode impactar a saúde financeira da empresa
        
        Seja objetivo e direto, destacando apenas os aspectos mais relevantes para a análise integrada da empresa e seus sócios.
        
        IMPORTANTE: Certifique-se de mencionar explicitamente o valor da renda mensal do sócio em sua análise.
        Também explique claramente a diferença entre valores em "conceito amplo" e "conceito restrito" quando relevante.
        """
        
        return prompt
    
    def construir_prompt_analise_consolidada(self, cpf_cnpj: str, dados_principal: Dict[str, Any], 
                                           analise_principal: str, analises_relacionadas: Dict[str, Any],
                                           is_pf: bool, is_pj: bool) -> str:
        """
        Constrói o prompt para a análise consolidada integrando todas as análises.
        
        Args:
            cpf_cnpj: CPF/CNPJ do associado principal
            dados_principal: Dados formatados do associado principal
            analise_principal: Análise do associado principal
            analises_relacionadas: Dicionário com análises de cônjuge, sócios e grupo econômico
            is_pf: Booleano indicando se é pessoa física
            is_pj: Booleano indicando se é pessoa jurídica
            
        Returns:
            String contendo o prompt para análise consolidada
        """
        nome_associado = dados_principal.get("nome_associado", "Associado")
        renda_mensal = dados_principal.get("renda_mensal", "Não informado")
        
        # Iniciar o prompt com informações básicas
        prompt = f"""
        # ANÁLISE CONSOLIDADA DO ECOSSISTEMA FINANCEIRO DO ASSOCIADO
        
        ## Associado Principal: {nome_associado} ({cpf_cnpj})
        ## Tipo: {"PESSOA FÍSICA" if is_pf else "PESSOA JURÍDICA" if is_pj else "NÃO IDENTIFICADO"}
        ## Renda Mensal: {renda_mensal} (INFORMAÇÃO CRUCIAL)
        
        ## EXPLICAÇÃO DE CONCEITOS
        - Conceito Amplo: Inclui todas as operações no sistema financeiro.
        - Conceito Restrito: Considera apenas operações diretas com o Sicredi.
        
        Abaixo estão apresentadas as análises individuais do associado principal e suas relações (cônjuge, sócios, grupo econômico).
        Sua tarefa é integrar estas análises em uma visão holística e sistêmica, identificando padrões, conexões e insights
        que só emergem quando consideramos todo o ecossistema financeiro do associado.
        
        ## RESUMO DO ASSOCIADO PRINCIPAL
        
        """
        
        # Adicionar resumo dos dados principais do associado
        if is_pf:
            prompt += f"""
            - Nome: {dados_principal.get('nome_associado', 'Não informado')}
            - Idade: {dados_principal.get('idade', 'Não informado')}
            - Profissão: {dados_principal.get('des_cbo', 'Não informado')}
            - Estado Civil: {dados_principal.get('des_estado_civil', 'Não informado')}
            - Renda Mensal: {dados_principal.get('renda_mensal', 'Não informado')}
            - Patrimônio: {dados_principal.get('patrimonio_total', 'Não informado')}
            - Relacionamento: {dados_principal.get('anos_de_associacao', 'Não informado')} anos
            - Saldo Total Sicredi (conceito amplo): {dados_principal.get('saldo_total_sicredi_conceito_amplo', 'Não informado')}
            - Endividamento Total (conceito amplo): {dados_principal.get('endividamento_total_conceito_amplo', 'Não informado')}
            - SCR Total (conceito restrito): {dados_principal.get('scr_total_conceito_restrito', 'Não informado')}
            - Faixa de Risco: {dados_principal.get('faixa_risco_padrao', 'Não informado')}
            """
        else:
            prompt += f"""
            - Razão Social: {dados_principal.get('nome_associado', 'Não informado')}
            - Natureza Jurídica: {dados_principal.get('des_natureza_juridica', 'Não informado')}
            - Setor: {dados_principal.get('des_cnae', 'Não informado')}
            - Quantidade de Sócios: {dados_principal.get('qt_socios', 'Não informado')}
            - Renda/Faturamento Mensal: {dados_principal.get('renda_mensal', 'Não informado')}
            - Patrimônio: {dados_principal.get('patrimonio_total', 'Não informado')}
            - Relacionamento: {dados_principal.get('anos_de_associacao', 'Não informado')} anos
            - Saldo Total Sicredi (conceito amplo): {dados_principal.get('saldo_total_sicredi_conceito_amplo', 'Não informado')}
            - Endividamento Total (conceito amplo): {dados_principal.get('endividamento_total_conceito_amplo', 'Não informado')}
            - SCR Total (conceito restrito): {dados_principal.get('scr_total_conceito_restrito', 'Não informado')}
            - Faixa de Risco: {dados_principal.get('faixa_risco_padrao', 'Não informado')}
            """
        
        # Adicionar resumo das análises relacionadas
        
        # 1. Cônjuge (se aplicável)
        conjuge = analises_relacionadas.get("conjuge")
        if conjuge and is_pf:
            prompt += f"""
            
            ## RESUMO DO CÔNJUGE
            
            - Nome: {conjuge.get('nome', 'Não informado')}
            - CPF: {conjuge.get('cpf', 'Não informado')}
            - É Associado: {'Sim' if conjuge.get('is_associado') else 'Não'}
            """
            
            # Adicionar dados financeiros do cônjuge se for associado
            if conjuge.get('is_associado') and conjuge.get('dados'):
                dados_conjuge = conjuge.get('dados', {})
                prompt += f"""
                - Renda Mensal: {dados_conjuge.get('renda_mensal', 'Não informado')}
                - Patrimônio: {dados_conjuge.get('patrimonio_total', 'Não informado')}
                - Saldo Total Sicredi (conceito amplo): {dados_conjuge.get('saldo_total_sicredi_conceito_amplo', 'Não informado')}
                - Endividamento Total (conceito amplo): {dados_conjuge.get('endividamento_total_conceito_amplo', 'Não informado')}
                - SCR Total (conceito restrito): {dados_conjuge.get('scr_total_conceito_restrito', 'Não informado')}
                - Faixa de Risco: {dados_conjuge.get('faixa_risco_padrao', 'Não informado')}
                """
        
        # 2. Sócios (se aplicável)
        socios = analises_relacionadas.get("socios", [])
        if socios and is_pj:
            prompt += """
            
            ## RESUMO DOS SÓCIOS
            """
            
            for i, socio in enumerate(socios):
                prompt += f"""
                
                ### Sócio {i+1}: {socio.get('nome', 'Não informado')}
                - CPF: {socio.get('cpf', 'Não informado')}
                - Participação: {socio.get('percentual', 'Não informado')}
                - É Associado: {'Sim' if socio.get('is_associado') else 'Não'}
                """
                
                # Adicionar dados financeiros do sócio se for associado
                if socio.get('is_associado') and socio.get('dados'):
                    dados_socio = socio.get('dados', {})
                    prompt += f"""
                    - Renda Mensal: {dados_socio.get('renda_mensal', 'Não informado')}
                    - Patrimônio: {dados_socio.get('patrimonio_total', 'Não informado')}
                    - Saldo Total Sicredi (conceito amplo): {dados_socio.get('saldo_total_sicredi_conceito_amplo', 'Não informado')}
                    - Endividamento Total (conceito amplo): {dados_socio.get('endividamento_total_conceito_amplo', 'Não informado')}
                    - SCR Total (conceito restrito): {dados_socio.get('scr_total_conceito_restrito', 'Não informado')}
                    - Faixa de Risco: {dados_socio.get('faixa_risco_padrao', 'Não informado')}
                    """
        
        # 3. Grupo Econômico (se aplicável)
        grupo = analises_relacionadas.get("grupo_economico")
        if grupo:
            prompt += f"""
            
            ## RESUMO DO GRUPO ECONÔMICO
            
            - Nome do Grupo: {grupo.get('nome', 'Não informado')}
            - Código: {grupo.get('codigo', 'Não informado')}
            - Quantidade de Associados: {grupo.get('qtd_associados', 'Não informado')}
            """
            
            # Adicionar métricas do grupo se disponíveis
            if grupo.get('metricas'):
                metricas = grupo.get('metricas', {})
                prompt += f"""
                - Saldo Total Sicredi (conceito amplo): {metricas.get('total_saldo_total_sicredi_conceito_amplo', 'Não informado')}
                - Endividamento Total (conceito amplo): {metricas.get('total_endividamento_total_conceito_amplo', 'Não informado')}
                - Patrimônio Total: {metricas.get('total_patrimonio_total', 'Não informado')}
                - Renda Mensal Total: {metricas.get('total_renda_mensal', 'Não informado')}
                - PD Média: {metricas.get('pd_media', 'Não informado')}
                - Quantidade de Inadimplentes: {metricas.get('qtd_inadimplentes', 'Não informado')}
                """
        
        # Adicionar as análises individuais completas
        prompt += """
        
        # ANÁLISES INDIVIDUAIS COMPLETAS
        
        ## ANÁLISE DO ASSOCIADO PRINCIPAL
        
        """
        
        # Adicionar análise principal (limitando o tamanho para não exceder limites de tokens)
        analise_principal_resumida = analise_principal[:10000] if len(analise_principal) > 10000 else analise_principal
        if len(analise_principal) > 10000:
            analise_principal_resumida += "\n...(análise truncada para economizar espaço)..."
        
        prompt += analise_principal_resumida
        
        # Adicionar análise do cônjuge se disponível
        if conjuge and conjuge.get('analise'):
            prompt += """
            
            ## ANÁLISE DO CÔNJUGE
            
            """
            analise_conjuge = conjuge.get('analise', '')
            analise_conjuge_resumida = analise_conjuge[:5000] if len(analise_conjuge) > 5000 else analise_conjuge
            prompt += analise_conjuge_resumida
        
        # Adicionar análises dos sócios (resumidas)
        if socios:
            for i, socio in enumerate(socios):
                if socio.get('analise'):
                    prompt += f"""
                    
                    ## ANÁLISE DO SÓCIO {i+1}: {socio.get('nome', 'Não informado')}
                    
                    """
                    analise_socio = socio.get('analise', '')
                    analise_socio_resumida = analise_socio[:3000] if len(analise_socio) > 3000 else analise_socio
                    prompt += analise_socio_resumida
        
        # Adicionar análise do grupo econômico
        if grupo and grupo.get('analise'):
            prompt += """
            
            ## ANÁLISE DO GRUPO ECONÔMICO
            
            """
            analise_grupo = grupo.get('analise', '')
            analise_grupo_resumida = analise_grupo[:5000] if len(analise_grupo) > 5000 else analise_grupo
            prompt += analise_grupo_resumida
        
        # Adicionar instruções para a análise consolidada
        prompt += """
        
        # SOLICITAÇÃO DE ANÁLISE CONSOLIDADA
        
        Com base em todas as análises individuais apresentadas acima, elabore uma análise consolidada e holística que integre todas as informações
        em uma visão sistêmica do ecossistema financeiro do associado. Sua análise consolidada deve:
        
        1. Identificar padrões, conexões e dinâmicas que emergem apenas quando analisamos todas as relações em conjunto
        2. Avaliar a saúde financeira global do ecossistema do associado (associado principal + relações)
        3. Identificar riscos sistêmicos que podem afetar múltiplas entidades do ecossistema
        4. Destacar oportunidades que considerem todo o ecossistema de forma integrada
        5. Fornecer uma visão estratégica de longo prazo para o desenvolvimento deste ecossistema
        
        Sua análise deve ser estratégica, visionária e orientada para resultados concretos, destacando insights que não seriam evidentes
        nas análises individuais isoladas.
        
        IMPORTANTE: Certifique-se de mencionar explicitamente o valor da renda mensal do associado principal em sua análise.
        Também explique claramente a diferença entre valores em "conceito amplo" e "conceito restrito" quando relevante.
        """
        
        return prompt

# Função principal para uso em notebooks Databricks
def main():
    """
    Função principal para teste interativo da análise de perfil do associado
    """
    try:
        # Obter o CPF/CNPJ do widget (para teste interativo)
        try:
            cpf_cnpj = dbutils.widgets.get("cpf_cnpj")
        except:
            # Para testes diretos sem widget
            cpf_cnpj = "01492562130"  # CPF/CNPJ de exemplo
        
        logger.info(f"CPF/CNPJ a ser analisado: {cpf_cnpj}")
        
        # Criar instância do analisador
        analisador = AnalisadorPerfilAssociado()
        
        # Realizar a análise com tratamento de timeout
        try:
            # Definir um timeout global para a análise
            import signal
            
            def timeout_handler(signum, frame):
                raise TimeoutError("A análise excedeu o tempo limite de execução")
            
            # Configurar timeout de 5 minutos
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(300)  # 300 segundos = 5 minutos
            
            resultado = analisador.analisar_perfil_associado(cpf_cnpj)
            
            # Desativar o alarme
            signal.alarm(0)
            
        except TimeoutError as te:
            logger.error(f"Timeout na análise: {str(te)}")
            resultado = {
                "status": "error",
                "message": "A análise excedeu o tempo limite de execução. Tente novamente com um cluster mais potente ou em horário de menor carga."
            }
        
        # Exibir o resultado
        if resultado["status"] == "success":
            # Exibir a análise formatada
            displayHTML(
                f"<h2>Análise de Perfil do Associado - CPF/CNPJ {cpf_cnpj} ({resultado['tipo_pessoa']})</h2>"
                f"<div style='white-space: pre-wrap; font-family: Arial, sans-serif; line-height: 1.6; max-width: 1200px; margin: 0 auto;'>{resultado['analise_principal']}</div>"
                
                f"<h3>Análise Consolidada</h3>"
                f"<div style='white-space: pre-wrap; font-family: Arial, sans-serif; line-height: 1.6; max-width: 1200px; margin: 0 auto;'>{resultado['analise_consolidada']}</div>"
                
                f"<h3>Renda Mensal</h3>"
                f"<div style='font-weight: bold; font-size: 1.2em;'>{resultado['renda_mensal']}</div>"
            )
        else:
            # Exibir mensagem de erro
            displayHTML(f"<h2>Erro na Análise de Perfil do Associado</h2><div>{resultado['message']}</div>")
    
    except Exception as e:
        import traceback
        stack_trace = traceback.format_exc()
        logger.error(f"Erro na execução principal: {str(e)}\n{stack_trace}")
        displayHTML(f"<h2>Erro Crítico</h2><div>Ocorreu um erro inesperado: {str(e)}</div>")
        
        # Tentar reiniciar o SparkSession para futuras execuções
        try:
            SparkSessionManager.reset()
        except:
            pass

# Função para uso direto (sem Databricks)
def analisar_perfil_associado(cpf_cnpj: str) -> Dict[str, Any]:
    """
    Função de conveniência para análise de perfil do associado.
    
    Args:
        cpf_cnpj: CPF ou CNPJ do associado
        
    Returns:
        Dicionário com os resultados da análise
    """
    analisador = AnalisadorPerfilAssociado()
    return analisador.analisar_perfil_associado(cpf_cnpj)

# Se o script for executado diretamente (não importado)
if __name__ == "__main__":
    main()
}

ANALISE SCR{
import re
import json
import pandas as pd
import numpy as np
import concurrent.futures
import time
import logging
import sys
import traceback
import socket
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # Backend não-interativo para ambientes sem display
import seaborn as sns
import io
import base64
from pathlib import Path
from datetime import datetime
import os
from typing import Dict, List, Any, Optional, Tuple, Union
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count, sum as spark_sum, max as spark_max
from openai import OpenAI
import py4j.protocol

# Configuração avançada de logging com formatação colorida e detalhada
class ColoredFormatter(logging.Formatter):
    """Formatador de logs com cores para melhor visualização"""
    
    COLORS = {
        'DEBUG': '\033[94m',  # Azul
        'INFO': '\033[92m',   # Verde
        'WARNING': '\033[93m', # Amarelo
        'ERROR': '\033[91m',  # Vermelho
        'CRITICAL': '\033[91m\033[1m',  # Vermelho negrito
        'RESET': '\033[0m'    # Reset
    }
    
    def format(self, record):
        log_message = super().format(record)
        levelname = record.levelname
        if levelname in self.COLORS:
            return f"{self.COLORS[levelname]}{log_message}{self.COLORS['RESET']}"
        return log_message

# Configuração de logging avançada
def setup_logging(level=logging.INFO):
    """Configura o sistema de logging com formatação avançada"""
    logger = logging.getLogger("AnalisadorSCR")
    logger.setLevel(level)
    
    # Limpar handlers existentes
    if logger.handlers:
        logger.handlers = []
    
    # Handler para console com cores
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(level)
    
    # Formatação detalhada com timestamp, nível e contexto
    log_format = '%(asctime)s [%(levelname)s] %(name)s:%(lineno)d - %(message)s'
    colored_formatter = ColoredFormatter(log_format)
    console_handler.setFormatter(colored_formatter)
    
    logger.addHandler(console_handler)
    
    # Handler para arquivo (opcional)
    try:
        file_handler = logging.FileHandler(f"analisador_scr_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
        file_handler.setLevel(level)
        file_formatter = logging.Formatter(log_format)
        file_handler.setFormatter(file_formatter)
        logger.addHandler(file_handler)
    except:
        pass  # Ignora se não puder criar arquivo de log
    
    return logger

# Inicializar logger
logger = setup_logging()

class ResourceMonitor:
    """Monitora recursos do sistema e do Spark durante a execução"""
    
    def __init__(self, spark=None):
        self.spark = spark
        self.start_time = time.time()
        self.last_check = self.start_time
        self.check_interval = 30  # segundos entre verificações
        
    def set_spark(self, spark):
        """Define a sessão Spark para monitoramento"""
        self.spark = spark
        
    def check_resources(self, force=False):
        """Verifica recursos do sistema e Spark"""
        current_time = time.time()
        if not force and (current_time - self.last_check) < self.check_interval:
            return
            
        self.last_check = current_time
        elapsed = current_time - self.start_time
        
        # Informações básicas de recursos
        memory_info = {}
        try:
            import psutil
            process = psutil.Process()
            memory_info = {
                "memory_percent": process.memory_percent(),
                "memory_mb": process.memory_info().rss / (1024 * 1024)
            }
        except:
            memory_info = {"status": "psutil não disponível"}
            
        # Informações do Spark - versão compatível com diferentes versões do Spark
        spark_metrics = {}
        if self.spark:
            try:
                # Obter métricas básicas do Spark que funcionam em todas as versões
                spark_metrics = {
                    "app_id": self.spark.sparkContext.applicationId,
                    "default_parallelism": self.spark.sparkContext.defaultParallelism,
                    "version": self.spark.version
                }
                
                # Tentar obter informações sobre executores de forma segura
                try:
                    # Método alternativo para obter número de executores
                    executor_metrics = self.spark.sql("SELECT count(*) as executor_count FROM sys.executors").collect()
                    if executor_metrics:
                        spark_metrics["active_executors"] = executor_metrics[0]["executor_count"]
                except:
                    # Se falhar, não interrompe a execução
                    pass
                
                # Tentar obter métricas de memória via SQL
                try:
                    memory_metrics = self.spark.sql("SELECT * FROM sys.runtime").collect()
                    if memory_metrics:
                        for row in memory_metrics:
                            row_dict = row.asDict()
                            if "jvm.heap.used" in row_dict:
                                spark_metrics["jvm_heap_used_mb"] = row_dict["jvm.heap.used"] / (1024 * 1024)
                except:
                    # Se falhar, não interrompe a execução
                    pass
            except:
                spark_metrics = {"status": "Erro ao obter métricas do Spark"}
        
        # Log das informações de recursos
        logger.info(f"📊 MONITOR DE RECURSOS [Tempo decorrido: {elapsed:.1f}s]")
        logger.info(f"🖥️ Processo Python: {json.dumps(memory_info)}")
        logger.info(f"⚡ Métricas Spark: {json.dumps(spark_metrics)}")
        
        return {
            "elapsed_time": elapsed,
            "memory_info": memory_info,
            "spark_metrics": spark_metrics
        }

# Inicializar monitor de recursos
resource_monitor = ResourceMonitor()

class SparkSessionManager:
    """Gerencia a sessão Spark de forma robusta com mecanismos de retry e monitoramento"""
    
    _instance = None
    _init_attempts = 0
    _max_init_attempts = 3
    
    @classmethod
    def get_or_create(cls):
        """Obtém uma sessão Spark existente ou cria uma nova com configurações otimizadas"""
        if cls._instance is None:
            logger.info("🔄 Inicializando nova SparkSession (tentativa %d de %d)", 
                       cls._init_attempts + 1, cls._max_init_attempts)
            try:
                # Configurações otimizadas para o SparkSession
                spark = (SparkSession.builder
                    .appName("AnalisadorSCR")
                    .config("spark.sql.execution.arrow.pyspark.enabled", "true")
                    .config("spark.sql.execution.arrow.maxRecordsPerBatch", "10000")
                    .config("spark.databricks.io.cache.enabled", "true")
                    .config("spark.databricks.delta.preview.enabled", "true")
                    # Configurações adicionais para melhorar estabilidade
                    .config("spark.network.timeout", "800s")
                    .config("spark.executor.heartbeatInterval", "120s")
                    .config("spark.sql.broadcastTimeout", "600s")
                    .config("spark.sql.autoBroadcastJoinThreshold", "64MB")
                    # Configurações de memória
                    .config("spark.memory.fraction", "0.8")
                    .config("spark.memory.storageFraction", "0.3")
                    .config("spark.sql.shuffle.partitions", "200")
                    # Configurações para lidar com erros de conexão
                    .config("spark.task.maxFailures", "4")
                    .getOrCreate())
                
                # Definir configurações de log do Spark para reduzir ruído
                spark.sparkContext.setLogLevel("WARN")
                
                # Registrar informações sobre o cluster de forma segura
                logger.info("✅ SparkSession inicializada com sucesso")
                logger.info(f"📋 Versão do Spark: {spark.version}")
                logger.info(f"🔢 Paralelismo padrão: {spark.sparkContext.defaultParallelism}")
                
                # Tentar obter número de executores de forma segura (compatível com diferentes versões)
                try:
                    executor_count = spark.sql("SELECT count(*) as count FROM sys.executors").collect()[0]["count"]
                    logger.info(f"🖥️ Número de executores: {executor_count}")
                except:
                    logger.info("🖥️ Informação sobre executores não disponível")
                
                # Configurar o monitor de recursos
                resource_monitor.set_spark(spark)
                resource_monitor.check_resources(force=True)
                
                cls._instance = spark
                cls._init_attempts = 0
            except Exception as e:
                cls._init_attempts += 1
                logger.error(f"❌ Erro ao inicializar SparkSession: {str(e)}")
                
                if cls._init_attempts >= cls._max_init_attempts:
                    logger.critical("🛑 Número máximo de tentativas de inicialização excedido!")
                    raise
                
                # Espera exponencial antes de tentar novamente
                wait_time = 2 ** cls._init_attempts
                logger.warning(f"⏱️ Aguardando {wait_time}s antes de tentar novamente...")
                time.sleep(wait_time)
                return cls.get_or_create()
                
        return cls._instance
    
    @classmethod
    def reset(cls):
        """Reinicia a sessão Spark em caso de problemas"""
        if cls._instance:
            try:
                logger.info("🔄 Reiniciando SparkSession")
                cls._instance.stop()
            except:
                logger.warning("⚠️ Erro ao parar SparkSession existente, continuando com reset")
            cls._instance = None
        return cls.get_or_create()

    @classmethod
    def execute_with_retry(cls, func, *args, max_retries=3, **kwargs):
        """Executa uma função com retry automático em caso de erros de conexão"""
        for attempt in range(max_retries):
            try:
                return func(*args, **kwargs)
            except (py4j.protocol.Py4JNetworkError, socket.error) as e:
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt
                    logger.warning(f"⚠️ Erro de conexão na tentativa {attempt+1}/{max_retries}: {str(e)}")
                    logger.warning(f"⏱️ Aguardando {wait_time}s antes de tentar novamente...")
                    time.sleep(wait_time)
                    cls.reset()
                else:
                    logger.error(f"❌ Falha após {max_retries} tentativas: {str(e)}")
                    raise
            except Exception as e:
                logger.error(f"❌ Erro não relacionado à conexão: {str(e)}")
                raise

class GeradorGraficos:
    """
    Classe responsável por gerar gráficos informativos sobre os dados do SCR
    para inclusão em relatórios ou documentos PDF.
    """
    
    def __init__(self, output_dir=None):
        """
        Inicializa o gerador de gráficos.
        
        Args:
            output_dir: Diretório para salvar os gráficos. Se None, usa um diretório temporário.
        """
        # Configurar diretório de saída
        if output_dir is None:
            self.output_dir = Path(f"/tmp/scr_graficos_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
        else:
            self.output_dir = Path(output_dir)
            
        # Criar diretório se não existir
        os.makedirs(self.output_dir, exist_ok=True)
        
        # Configurar estilo dos gráficos
        plt.style.use('ggplot')
        sns.set_palette("deep")
        
        # Configurar fontes e tamanhos
        plt.rcParams['font.family'] = 'sans-serif'
        plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans', 'Liberation Sans']
        plt.rcParams['font.size'] = 12
        plt.rcParams['axes.titlesize'] = 14
        plt.rcParams['axes.labelsize'] = 12
        plt.rcParams['xtick.labelsize'] = 10
        plt.rcParams['ytick.labelsize'] = 10
        
        # Lista para armazenar informações sobre os gráficos gerados
        self.graficos_gerados = []
        
        logger.info(f"🎨 Gerador de gráficos inicializado. Diretório de saída: {self.output_dir}")
    
    def gerar_graficos_scr(self, dados_estruturados):
        """
        Gera todos os gráficos relevantes para a análise SCR.
        
        Args:
            dados_estruturados: Dicionário com os dados estruturados da análise SCR
            
        Returns:
            Dict: Dicionário com informações sobre os gráficos gerados
        """
        logger.info("🎨 Iniciando geração de gráficos para análise SCR")
        
        # Limpar lista de gráficos anteriores
        self.graficos_gerados = []
        
        try:
            # 1. Gráfico de composição da carteira (pizza)
            self.gerar_grafico_composicao_carteira(dados_estruturados)
            
            # 2. Gráfico de evolução do endividamento (linha)
            self.gerar_grafico_evolucao_endividamento(dados_estruturados)
            
            # 3. Gráfico de comparação com cônjuge (barras), se disponível
            if "analises_relacionadas" in dados_estruturados and "conjuge" in dados_estruturados["analises_relacionadas"]:
                conjuge = dados_estruturados["analises_relacionadas"]["conjuge"]
                if conjuge["status"] == "success" and "dados" in conjuge:
                    self.gerar_grafico_comparacao_conjuge(dados_estruturados, conjuge["dados"])
            
            # 4. Gráfico de distribuição por instituições financeiras (barras horizontais)
            self.gerar_grafico_instituicoes_financeiras(dados_estruturados)
            
            # 5. Gráfico de indicadores de alerta (radar)
            self.gerar_grafico_indicadores_alerta(dados_estruturados)
            
            logger.info(f"✅ Geração de gráficos concluída. Total: {len(self.graficos_gerados)} gráficos")
            
            return {
                "status": "success",
                "graficos": self.graficos_gerados,
                "diretorio": str(self.output_dir)
            }
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar gráficos: {str(e)}")
            return {
                "status": "error",
                "message": f"Erro ao gerar gráficos: {str(e)}",
                "graficos": self.graficos_gerados,
                "diretorio": str(self.output_dir)
            }
    
    def gerar_grafico_composicao_carteira(self, dados_estruturados):
        """
        Gera um gráfico de pizza mostrando a composição da carteira de crédito.
        """
        logger.info("🎨 Gerando gráfico de composição da carteira")
        
        try:
            # Extrair dados
            composicao = dados_estruturados["composicao_carteira"]
            
            # Preparar dados para o gráfico
            categorias = []
            valores = []
            percentuais = []
            
            for item in composicao:
                # Usar categoria completa ou categoria simples se a completa não estiver disponível
                categoria = item.get("categoria_completa", item.get("categoria", "Não categorizado"))
                categorias.append(categoria)
                valores.append(item.get("valor", 0))
                
                # Extrair percentual numérico (remover o símbolo %)
                perc_str = item.get("percentual", "0%")
                perc_num = float(perc_str.replace("%", "").strip())
                percentuais.append(perc_num)
            
            # Criar figura
            plt.figure(figsize=(10, 7))
            
            # Gerar gráfico de pizza
            wedges, texts, autotexts = plt.pie(
                valores, 
                autopct='%1.1f%%',
                startangle=90,
                shadow=False,
                explode=[0.05 if p > 30 else 0 for p in percentuais],  # Destacar categorias principais
                wedgeprops={'edgecolor': 'white', 'linewidth': 1.5}
            )
            
            # Melhorar a aparência dos textos
            for autotext in autotexts:
                autotext.set_color('white')
                autotext.set_fontsize(10)
                autotext.set_weight('bold')
            
            # Adicionar legenda
            plt.legend(
                wedges, 
                categorias,
                title="Categorias",
                loc="center left",
                bbox_to_anchor=(1, 0, 0.5, 1)
            )
            
            # Adicionar título
            plt.title("Composição da Carteira de Crédito", fontweight='bold', pad=20)
            
            # Ajustar layout
            plt.tight_layout()
            
            # Salvar gráfico
            nome_arquivo = "composicao_carteira.png"
            caminho_completo = self.output_dir / nome_arquivo
            plt.savefig(caminho_completo, dpi=300, bbox_inches='tight')
            plt.close()
            
            # Adicionar à lista de gráficos gerados
            self.graficos_gerados.append({
                "tipo": "composicao_carteira",
                "titulo": "Composição da Carteira de Crédito",
                "descricao": f"Distribuição das modalidades de crédito na carteira ativa total de R$ {sum(valores):,.2f}.",
                "arquivo": nome_arquivo,
                "caminho": str(caminho_completo)
            })
            
            logger.info(f"✅ Gráfico de composição da carteira gerado: {caminho_completo}")
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar gráfico de composição da carteira: {str(e)}")
    
    def gerar_grafico_evolucao_endividamento(self, dados_estruturados):
        """
        Gera um gráfico de linha mostrando a evolução do endividamento.
        """
        logger.info("🎨 Gerando gráfico de evolução do endividamento")
        
        try:
            # Extrair dados de evolução
            evolucao = dados_estruturados["evolucao_endividamento"]
            
            # Simular dados mensais com base nas informações disponíveis
            # (Como não temos os dados mensais completos, vamos criar uma aproximação)
            meses = 12
            valor_inicial = evolucao["resp_total_inicial"]
            valor_final = evolucao["resp_total_atual"]
            taxa_mensal = evolucao["taxa_variacao_mensal"] / 100  # Converter para decimal
            
            # Gerar valores mensais com base na taxa de variação
            valores = [valor_inicial]
            for i in range(1, meses):
                # Podemos usar uma progressão linear ou exponencial
                if abs(taxa_mensal) < 0.1:  # Se a taxa for pequena, usamos aproximação linear
                    incremento_mensal = (valor_final - valor_inicial) / (meses - 1)
                    valores.append(valores[-1] + incremento_mensal)
                else:
                    # Caso contrário, usamos crescimento com a taxa mensal
                    valores.append(valores[-1] * (1 + taxa_mensal))
            
            # Garantir que o último valor seja exatamente o valor final
            valores[-1] = valor_final
            
            # Gerar rótulos de meses
            mes_inicial = evolucao["mes_inicial"].split("/")
            mes_atual = evolucao["mes_atual"].split("/")
            
            # Converter para números
            mes_inicial_num = int(mes_inicial[0])
            ano_inicial_num = int(mes_inicial[1])
            
            # Gerar sequência de meses
            rotulos_meses = []
            mes = mes_inicial_num
            ano = ano_inicial_num
            
            for i in range(meses):
                rotulos_meses.append(f"{mes:02d}/{ano}")
                mes += 1
                if mes > 12:
                    mes = 1
                    ano += 1
            
            # Criar figura
            plt.figure(figsize=(12, 6))
            
            # Plotar linha de evolução
            plt.plot(rotulos_meses, valores, marker='o', linewidth=2, color='#1f77b4')
            
            # Adicionar linha de tendência
            z = np.polyfit(range(len(valores)), valores, 1)
            p = np.poly1d(z)
            plt.plot(rotulos_meses, p(range(len(valores))), "r--", linewidth=1)
            
            # Adicionar rótulos e título
            plt.title("Evolução da Responsabilidade Total", fontweight='bold')
            plt.xlabel("Mês/Ano")
            plt.ylabel("Valor (R$)")
            
            # Formatar eixo Y para moeda
            plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: f"R$ {x:,.0f}"))
            
            # Rotacionar rótulos do eixo X para melhor legibilidade
            plt.xticks(rotation=45)
            
            # Adicionar grade
            plt.grid(True, linestyle='--', alpha=0.7)
            
            # Adicionar anotações de variação
            variacao_percentual = evolucao["variacao_percentual"]
            plt.annotate(
                f"Variação: {variacao_percentual:.2f}%",
                xy=(len(rotulos_meses) - 1, valores[-1]),
                xytext=(len(rotulos_meses) - 3, valores[-1] * 1.1),
                arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=.2")
            )
            
            # Ajustar layout
            plt.tight_layout()
            
            # Salvar gráfico
            nome_arquivo = "evolucao_endividamento.png"
            caminho_completo = self.output_dir / nome_arquivo
            plt.savefig(caminho_completo, dpi=300, bbox_inches='tight')
            plt.close()
            
            # Adicionar à lista de gráficos gerados
            self.graficos_gerados.append({
                "tipo": "evolucao_endividamento",
                "titulo": "Evolução da Responsabilidade Total",
                "descricao": f"Evolução do endividamento total no período de {evolucao['mes_inicial']} a {evolucao['mes_atual']}, com variação de {variacao_percentual:.2f}%.",
                "arquivo": nome_arquivo,
                "caminho": str(caminho_completo)
            })
            
            logger.info(f"✅ Gráfico de evolução do endividamento gerado: {caminho_completo}")
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar gráfico de evolução do endividamento: {str(e)}")
    
    def gerar_grafico_comparacao_conjuge(self, dados_associado, dados_conjuge):
        """
        Gera um gráfico de barras comparando o endividamento do associado e cônjuge.
        """
        logger.info("🎨 Gerando gráfico de comparação com cônjuge")
        
        try:
            # Extrair dados do associado e cônjuge
            resp_total_associado = dados_associado["visao_geral"]["resp_total_atual"]
            resp_total_conjuge = dados_conjuge["visao_geral"]["resp_total_atual"]
            
            # Extrair nomes
            nome_associado = dados_associado.get("info_associado", {}).get("nome", "Associado Principal")
            nome_conjuge = dados_conjuge.get("nome", "Cônjuge")
            
            # Simplificar nomes para o gráfico (apenas primeiro e último nome)
            nome_associado_curto = nome_associado.split()[0]
            if len(nome_associado.split()) > 1:
                nome_associado_curto += " " + nome_associado.split()[-1]
                
            nome_conjuge_curto = nome_conjuge.split()[0]
            if len(nome_conjuge.split()) > 1:
                nome_conjuge_curto += " " + nome_conjuge.split()[-1]
            
            # Criar figura
            plt.figure(figsize=(10, 6))
            
            # Dados para o gráfico
            categorias = ['Responsabilidade Total', 'Carteira Ativa', 'Cartão de Crédito']
            
            # Valores do associado
            valores_associado = [
                resp_total_associado,
                dados_associado["visao_geral"]["carteira_ativa_atual"],
                # Encontrar valor de cartão de crédito
                next((item["valor"] for item in dados_associado["composicao_carteira"] 
                      if "cartão" in item["categoria"].lower() or "cartao" in item["categoria"].lower()), 0)
            ]
            
            # Valores do cônjuge
            valores_conjuge = [
                resp_total_conjuge,
                dados_conjuge["visao_geral"]["carteira_ativa_atual"],
                # Encontrar valor de cartão de crédito
                next((item["valor"] for item in dados_conjuge["composicao_carteira"] 
                      if "cartão" in item["categoria"].lower() or "cartao" in item["categoria"].lower()), 0)
            ]
            
            # Posições das barras
            x = np.arange(len(categorias))
            width = 0.35
            
            # Criar barras
            plt.bar(x - width/2, valores_associado, width, label=nome_associado_curto)
            plt.bar(x + width/2, valores_conjuge, width, label=nome_conjuge_curto)
            
            # Adicionar rótulos e título
            plt.title("Comparação de Endividamento: Associado vs. Cônjuge", fontweight='bold')
            plt.xlabel("Categoria")
            plt.ylabel("Valor (R$)")
            plt.xticks(x, categorias)
            
            # Formatar eixo Y para moeda
            plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: f"R$ {x:,.0f}"))
            
            # Adicionar valores nas barras
            def add_labels(bars):
                for bar in bars:
                    height = bar.get_height()
                    if height > 0:
                        plt.text(bar.get_x() + bar.get_width()/2., height,
                                f'R$ {height:,.0f}',
                                ha='center', va='bottom', rotation=0, fontsize=8)
            
            # Adicionar legenda
            plt.legend()
            
            # Adicionar grade
            plt.grid(True, linestyle='--', alpha=0.7, axis='y')
            
            # Ajustar layout
            plt.tight_layout()
            
            # Salvar gráfico
            nome_arquivo = "comparacao_conjuge.png"
            caminho_completo = self.output_dir / nome_arquivo
            plt.savefig(caminho_completo, dpi=300, bbox_inches='tight')
            plt.close()
            
            # Adicionar à lista de gráficos gerados
            percentual_conjuge = (resp_total_conjuge / resp_total_associado * 100) if resp_total_associado > 0 else 0
            
            self.graficos_gerados.append({
                "tipo": "comparacao_conjuge",
                "titulo": "Comparação de Endividamento: Associado vs. Cônjuge",
                "descricao": f"Comparação entre o endividamento do associado ({nome_associado_curto}) e seu cônjuge ({nome_conjuge_curto}). O cônjuge representa {percentual_conjuge:.1f}% do endividamento total do associado.",
                "arquivo": nome_arquivo,
                "caminho": str(caminho_completo)
            })
            
            logger.info(f"✅ Gráfico de comparação com cônjuge gerado: {caminho_completo}")
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar gráfico de comparação com cônjuge: {str(e)}")
    
    def gerar_grafico_instituicoes_financeiras(self, dados_estruturados):
        """
        Gera um gráfico de barras horizontais mostrando a distribuição por instituições financeiras.
        """
        logger.info("🎨 Gerando gráfico de distribuição por instituições financeiras")
        
        try:
            # Extrair dados
            qtd_instituicoes = dados_estruturados["visao_geral"]["qtd_instituicoes"]
            qtd_operacoes = dados_estruturados["visao_geral"]["qtd_operacoes"]
            
            # Como não temos os dados detalhados por instituição, vamos criar uma simulação
            # baseada nos dados agregados para fins de visualização
            
            # Simular distribuição de operações por instituição
            # (distribuição hipotética baseada em padrões comuns)
            instituicoes = [f"Instituição {i+1}" for i in range(qtd_instituicoes)]
            
            # Distribuição de operações seguindo uma distribuição de Pareto
            # (poucas instituições com muitas operações, muitas com poucas)
            ops_por_inst = np.random.pareto(1.5, qtd_instituicoes)
            ops_por_inst = ops_por_inst / ops_por_inst.sum() * qtd_operacoes
            ops_por_inst = np.round(ops_por_inst).astype(int)
            
            # Ajustar para garantir que a soma seja igual ao total de operações
            while ops_por_inst.sum() < qtd_operacoes:
                idx = np.random.randint(0, len(ops_por_inst))
                ops_por_inst[idx] += 1
            while ops_por_inst.sum() > qtd_operacoes:
                idx = np.argmax(ops_por_inst)
                if ops_por_inst[idx] > 1:
                    ops_por_inst[idx] -= 1
            
            # Ordenar por número de operações
            idx_sort = np.argsort(ops_por_inst)[::-1]
            instituicoes = [instituicoes[i] for i in idx_sort]
            ops_por_inst = ops_por_inst[idx_sort]
            
            # Criar figura
            plt.figure(figsize=(10, 8))
            
            # Criar barras horizontais
            bars = plt.barh(instituicoes, ops_por_inst, color=plt.cm.viridis(np.linspace(0, 0.8, len(instituicoes))))
            
            # Adicionar rótulos nas barras
            for i, bar in enumerate(bars):
                plt.text(bar.get_width() + 0.3, bar.get_y() + bar.get_height()/2, 
                        f"{ops_por_inst[i]}", 
                        va='center', fontsize=10)
            
            # Adicionar título e rótulos
            plt.title("Distribuição de Operações por Instituição Financeira", fontweight='bold')
            plt.xlabel("Número de Operações")
            plt.ylabel("Instituição Financeira")
            
            # Adicionar anotação com média
            media_ops = qtd_operacoes / qtd_instituicoes
            plt.axvline(x=media_ops, color='r', linestyle='--', alpha=0.7)
            plt.text(media_ops + 0.1, len(instituicoes) - 1, 
                    f"Média: {media_ops:.1f}", 
                    va='center', color='r', fontsize=10)
            
            # Ajustar layout
            plt.tight_layout()
            
            # Salvar gráfico
            nome_arquivo = "distribuicao_instituicoes.png"
            caminho_completo = self.output_dir / nome_arquivo
            plt.savefig(caminho_completo, dpi=300, bbox_inches='tight')
            plt.close()
            
            # Adicionar à lista de gráficos gerados
            self.graficos_gerados.append({
                "tipo": "distribuicao_instituicoes",
                "titulo": "Distribuição de Operações por Instituição Financeira",
                "descricao": f"Simulação da distribuição das {qtd_operacoes} operações entre as {qtd_instituicoes} instituições financeiras, com média de {media_ops:.1f} operações por instituição.",
                "arquivo": nome_arquivo,
                "caminho": str(caminho_completo),
                "nota": "Este gráfico é uma simulação baseada nos dados agregados disponíveis."
            })
            
            logger.info(f"✅ Gráfico de distribuição por instituições financeiras gerado: {caminho_completo}")
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar gráfico de distribuição por instituições financeiras: {str(e)}")
    
    def gerar_grafico_indicadores_alerta(self, dados_estruturados):
        """
        Gera um gráfico de radar mostrando os principais indicadores de alerta.
        """
        logger.info("🎨 Gerando gráfico de indicadores de alerta")
        
        try:
            # Extrair dados do resumo estatístico
            resumo = dados_estruturados["resumo_estatistico"]
            
            # Definir categorias e valores para o gráfico de radar
            categorias = [
                "Concentração\nCartão",
                "Crescimento\nEndividamento",
                "Diversificação\nCarteira",
                "Dispersão\nInstituições",
                "Operações por\nInstituição"
            ]
            
            # Mapear valores textuais para numéricos (escala de 0 a 100)
            # Concentração em cartão de crédito
            if "concentracao_maior_categoria" in resumo:
                perc_str = resumo["concentracao_maior_categoria"]
                concentracao = float(perc_str.replace("%", "").strip())
            else:
                # Valor padrão se não encontrado
                concentracao = 50
            
            # Velocidade de crescimento
            crescimento_map = {
                "Muito alta": 100,
                "Alta": 75,
                "Moderada": 50,
                "Estável": 25,
                "Decrescente": 0
            }
            crescimento = crescimento_map.get(resumo.get("velocidade_crescimento", "Moderada"), 50)
            
            # Diversificação da carteira
            diversificacao_map = {
                "Alta": 25,  # Valor baixo = melhor (mais diversificado)
                "Média": 50,
                "Baixa": 100  # Valor alto = pior (menos diversificado)
            }
            diversificacao = diversificacao_map.get(resumo.get("diversificacao", "Média"), 50)
            
            # Concentração em instituições
            concentracao_inst_map = {
                "Muito disperso": 100,
                "Disperso": 75,
                "Moderado": 50,
                "Concentrado": 25
            }
            concentracao_inst = concentracao_inst_map.get(resumo.get("concentracao_instituicoes", "Moderado"), 50)
            
            # Padrão de relacionamento
            padrao_rel_map = {
                "Alta concentração de operações por instituição": 75,
                "Padrão normal de operações por instituição": 50,
                "Baixa concentração de operações por instituição": 25
            }
            padrao_rel = padrao_rel_map.get(resumo.get("padrao_relacionamento", "Padrão normal de operações por instituição"), 50)
            
            # Valores para o gráfico (normalizar para escala 0-100)
            valores = [concentracao, crescimento, diversificacao, concentracao_inst, padrao_rel]
            
            # Criar figura
            plt.figure(figsize=(8, 8))
            
            # Criar gráfico de radar
            # Número de variáveis
            N = len(categorias)
            
            # Ângulos para cada eixo (divididos uniformemente)
            angulos = [n / float(N) * 2 * np.pi for n in range(N)]
            angulos += angulos[:1]  # Fechar o gráfico
            
            # Valores para o gráfico
            valores_radar = valores + [valores[0]]  # Fechar o gráfico
            
            # Criar o plot
            ax = plt.subplot(111, polar=True)
            
            # Desenhar o polígono
            ax.plot(angulos, valores_radar, 'o-', linewidth=2)
            ax.fill(angulos, valores_radar, alpha=0.25)
            
            # Adicionar rótulos
            ax.set_thetagrids(np.degrees(angulos[:-1]), categorias)
            
            # Ajustar os limites do eixo radial
            ax.set_ylim(0, 100)
            
            # Adicionar níveis de risco
            ax.set_rticks([25, 50, 75, 100])
            ax.set_yticklabels(['Baixo', 'Médio', 'Alto', 'Muito Alto'])
            
            # Adicionar título
            plt.title("Indicadores de Alerta", fontweight='bold', size=14, y=1.1)
            
            # Ajustar layout
            plt.tight_layout()
            
            # Salvar gráfico
            nome_arquivo = "indicadores_alerta.png"
            caminho_completo = self.output_dir / nome_arquivo
            plt.savefig(caminho_completo, dpi=300, bbox_inches='tight')
            plt.close()
            
            # Adicionar à lista de gráficos gerados
            self.graficos_gerados.append({
                "tipo": "indicadores_alerta",
                "titulo": "Indicadores de Alerta",
                "descricao": "Gráfico radar mostrando os principais indicadores de alerta. Valores mais próximos da borda externa indicam maior nível de alerta para aquele indicador.",
                "arquivo": nome_arquivo,
                "caminho": str(caminho_completo)
            })
            
            logger.info(f"✅ Gráfico de indicadores de alerta gerado: {caminho_completo}")
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar gráfico de indicadores de alerta: {str(e)}")
    
    def obter_graficos_base64(self):
        """
        Converte todos os gráficos gerados para strings base64 para inclusão em HTML ou JSON.
        
        Returns:
            List: Lista de dicionários com informações dos gráficos e strings base64
        """
        resultado = []
        
        for grafico in self.graficos_gerados:
            try:
                caminho = grafico["caminho"]
                with open(caminho, "rb") as img_file:
                    b64_string = base64.b64encode(img_file.read()).decode('utf-8')
                
                grafico_info = grafico.copy()
                grafico_info["base64"] = b64_string
                resultado.append(grafico_info)
                
            except Exception as e:
                logger.error(f"❌ Erro ao converter gráfico para base64: {str(e)}")
        
        return resultado

class AnalisadorSCR:
    """
    Classe principal para análise do Sistema de Informações de Crédito (SCR) de associados.
    Implementa funcionalidades avançadas para análise detalhada do endividamento no SFN.
    """
    
    def __init__(self):
        """Inicializa o analisador com configurações padrão."""
        logger.info("🚀 Inicializando AnalisadorSCR")
        self.timeout_analise_secundaria = 120  # timeout em segundos para análises secundárias
        self.max_retries = 4  # número máximo de tentativas para chamadas ao modelo
        self.cache_scr = {}  # cache para evitar consultas repetidas
        self.spark = None  # será inicializado sob demanda
        self.gerador_graficos = GeradorGraficos()  # inicializar gerador de gráficos
        
        # Configuração do cliente OpenAI
        try:
            self.openai_client = OpenAI(
                api_key='dapie6330b0d1f7ccef0e70f3bdd28b1e2a2',
                base_url="https://sicredi-coop-0914.cloud.databricks.com/serving-endpoints",
                timeout=180.0
            )
            logger.info("✅ Cliente OpenAI configurado com sucesso")
        except Exception as e:
            logger.error(f"❌ Erro ao configurar cliente OpenAI: {str(e)}")
            raise
    
    def _get_spark(self):
        """Obtém uma sessão Spark válida, com tratamento de reconexão"""
        if self.spark is None:
            logger.info("🔄 Obtendo sessão Spark")
            self.spark = SparkSessionManager.get_or_create()
            logger.info("✅ Sessão Spark obtida com sucesso")
        return self.spark
    
    def safe_int(self, value):
        """Converte valor para inteiro de forma segura, tratando NaN e None"""
        if pd.isna(value) or value is None:
            return 0
        try:
            return int(value)
        except:
            return 0
            
    def safe_float(self, value):
        """Converte valor para float de forma segura, tratando NaN e None"""
        if pd.isna(value) or value is None:
            return 0.0
        try:
            return float(value)
        except:
            return 0.0
    
    def analisar_scr_associado(self, cpf_cnpj: str) -> Dict[str, Any]:
        """
        Realiza uma análise completa do SCR de um associado, incluindo gráficos.
        
        Args:
            cpf_cnpj: CPF ou CNPJ do associado a ser analisado (com ou sem formatação)
        
        Returns:
            Dict: Dicionário com status, análise, dados e gráficos
        """
        start_time = time.time()
        logger.info(f"🔍 Iniciando análise do SCR para CPF/CNPJ: {cpf_cnpj}")
        
        try:
            # Limpar o CPF/CNPJ (remover caracteres não numéricos)
            cpf_cnpj_limpo = re.sub(r'[^0-9]', '', cpf_cnpj)
            
            # Validar o CPF/CNPJ
            if not cpf_cnpj_limpo:
                logger.warning(f"⚠️ CPF/CNPJ inválido: {cpf_cnpj}")
                return {
                    "status": "error",
                    "message": f"CPF/CNPJ inválido: {cpf_cnpj}"
                }
            
            if len(cpf_cnpj_limpo) != 11 and len(cpf_cnpj_limpo) != 14:
                logger.warning(f"⚠️ CPF/CNPJ com formato inválido: {cpf_cnpj}")
                return {
                    "status": "error",
                    "message": f"CPF/CNPJ com formato inválido: {cpf_cnpj}. Deve ter 11 dígitos (CPF) ou 14 dígitos (CNPJ)."
                }
            
            # Verificar cache
            cache_key = f"scr_{cpf_cnpj_limpo}"
            if cache_key in self.cache_scr:
                logger.info(f"🔄 Usando dados em cache para {cpf_cnpj_limpo}")
                cached_result = self.cache_scr[cache_key]
                elapsed = time.time() - start_time
                logger.info(f"✅ Análise concluída em {elapsed:.2f}s (usando cache)")
                return cached_result
            
            # Obter informações complementares do associado da tabela perfil_associado
            logger.info(f"📋 Obtendo informações complementares do associado {cpf_cnpj_limpo}")
            info_associado = self.obter_info_associado(cpf_cnpj_limpo)
            
            if info_associado:
                logger.info(f"👤 Associado identificado: {info_associado.get('nome_associado', 'Nome não disponível')}")
                logger.info(f"📊 Tipo de pessoa: {info_associado.get('tipo_pessoa', 'Não informado')}")
            else:
                logger.warning(f"⚠️ Informações complementares não encontradas para {cpf_cnpj_limpo}")
            
            # Determinar se é PF ou PJ
            tipo_pessoa = info_associado.get("tipo_pessoa", "").upper() if info_associado else ""
            is_pf = "FISICA" in tipo_pessoa or "FÍSICA" in tipo_pessoa
            is_pj = "JURIDICA" in tipo_pessoa or "JURÍDICA" in tipo_pessoa
            
            logger.info(f"👤 Tipo identificado: {'Pessoa Física' if is_pf else 'Pessoa Jurídica' if is_pj else 'Não determinado'}")
            
            # Iniciar análises paralelas para cônjuge e grupo econômico
            analises_relacionadas = {}
            futures = {}
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
                # Verificar se o associado pertence a um grupo econômico no SCR
                logger.info(f"🔍 Verificando grupo econômico para {cpf_cnpj_limpo}")
                grupo_economico_scr = self.verificar_grupo_economico_scr(cpf_cnpj_limpo)
                
                # Verificar se o associado pertence a um grupo econômico na tabela perfil_associado
                grupo_economico_perfil = info_associado.get("Codigo_conglomerado_economico") if info_associado else None
                
                # Usar o código de grupo econômico do SCR ou do perfil_associado, priorizando o SCR
                codigo_grupo = grupo_economico_scr or grupo_economico_perfil
                
                # Se pertence a um grupo econômico, iniciar análise do grupo
                if codigo_grupo:
                    logger.info(f"🏢 Iniciando análise do grupo econômico: {codigo_grupo}")
                    futures["grupo_economico"] = executor.submit(
                        self.analisar_grupo_economico, 
                        codigo_grupo, 
                        cpf_cnpj_limpo
                    )
                else:
                    logger.info("ℹ️ Associado não pertence a nenhum grupo econômico identificado")
                
                # Se for pessoa física e tiver cônjuge, iniciar análise do cônjuge
                if is_pf and info_associado and info_associado.get("cpf_conjuge"):
                    cpf_conjuge = re.sub(r'[^0-9]', '', str(info_associado.get("cpf_conjuge", "")))
                    nome_conjuge = info_associado.get("nome_pessoa_conjuge", "Cônjuge")
                    
                    if cpf_conjuge and len(cpf_conjuge) == 11:
                        logger.info(f"👨‍👩‍👧‍👦 Iniciando análise do SCR do cônjuge: {nome_conjuge} (CPF: {cpf_conjuge})")
                        futures["conjuge"] = executor.submit(
                            self.analisar_scr_conjuge, 
                            cpf_conjuge, 
                            nome_conjuge
                        )
                    else:
                        logger.warning(f"⚠️ CPF do cônjuge inválido ou não informado: {cpf_conjuge}")
                
                # Executar as consultas SQL para o associado principal
                logger.info(f"📊 Executando consultas SQL principais para {cpf_cnpj_limpo}")
                resultados = self.executar_consultas_sql(cpf_cnpj_limpo)
                
                # Verificar resultados das consultas
                if resultados["visao_geral"].empty:
                    logger.warning(f"⚠️ Consulta de visão geral não retornou dados para {cpf_cnpj_limpo}")
                if resultados["composicao_carteira"].empty:
                    logger.warning(f"⚠️ Consulta de composição da carteira não retornou dados para {cpf_cnpj_limpo}")
                if resultados["evolucao_endividamento"].empty:
                    logger.warning(f"⚠️ Consulta de evolução do endividamento não retornou dados para {cpf_cnpj_limpo}")
                
                # Coletar resultados das análises paralelas
                logger.info("⏳ Aguardando conclusão das análises paralelas")
                for key, future in futures.items():
                    try:
                        logger.info(f"🔄 Coletando resultados da análise de {key}")
                        resultado = future.result(timeout=self.timeout_analise_secundaria)
                        analises_relacionadas[key] = resultado
                        logger.info(f"✅ Análise de {key} concluída com sucesso")
                    except concurrent.futures.TimeoutError:
                        logger.warning(f"⏱️ Timeout na análise de {key} após {self.timeout_analise_secundaria}s")
                        analises_relacionadas[key] = {"status": "timeout", "message": f"A análise de {key} excedeu o tempo limite de {self.timeout_analise_secundaria}s"}
                    except Exception as e:
                        logger.error(f"❌ Erro na análise de {key}: {str(e)}")
                        analises_relacionadas[key] = {"status": "error", "message": f"Erro ao analisar {key}: {str(e)}"}
            
            # Verificar se há dados retornados para o associado principal
            if not resultados["visao_geral"].empty and not resultados["composicao_carteira"].empty and not resultados["evolucao_endividamento"].empty:
                # Estruturar os dados
                logger.info("🔄 Estruturando dados para análise")
                dados_estruturados = self.estruturar_dados(resultados)
                
                # Adicionar informações complementares do associado
                if info_associado:
                    dados_estruturados["info_associado"] = {
                        "nome": info_associado.get("nome_associado"),
                        "tipo_pessoa": info_associado.get("tipo_pessoa"),
                        "renda_mensal": info_associado.get("renda_mensal")
                    }
                
                # Adicionar análises relacionadas (cônjuge e grupo econômico)
                if analises_relacionadas:
                    dados_estruturados["analises_relacionadas"] = analises_relacionadas
                
                # Verificar monitor de recursos antes de chamar o modelo LLM
                resource_monitor.check_resources(force=True)
                
                # Enviar para o modelo LLM
                logger.info("🧠 Gerando análise com modelo LLM")
                analise = self.gerar_analise_llm(dados_estruturados)
                logger.info("✅ Análise LLM gerada com sucesso")
                
                # Gerar gráficos
                logger.info("📊 Gerando gráficos para a análise")
                resultado_graficos = self.gerador_graficos.gerar_graficos_scr(dados_estruturados)
                
                # Obter gráficos em base64 para inclusão em relatórios
                graficos_base64 = self.gerador_graficos.obter_graficos_base64()
                logger.info(f"✅ {len(graficos_base64)} gráficos gerados com sucesso")
                
                # Criar resultado final
                resultado = {
                    "status": "success",
                    "analise": analise,
                    "dados": dados_estruturados,
                    "graficos": resultado_graficos["graficos"],
                    "graficos_base64": graficos_base64
                }
                
                # Armazenar em cache
                self.cache_scr[cache_key] = resultado
                
                # Calcular tempo total
                elapsed = time.time() - start_time
                logger.info(f"✅ Análise completa do SCR concluída em {elapsed:.2f}s")
                
                return resultado
            else:
                logger.warning(f"⚠️ Dados insuficientes no SCR para {cpf_cnpj_limpo}")
                return {
                    "status": "error",
                    "message": f"Não foram encontrados dados de SCR para o CPF/CNPJ {cpf_cnpj_limpo}"
                }
        
        except Exception as e:
            elapsed = time.time() - start_time
            stack_trace = traceback.format_exc()
            logger.error(f"❌ Erro ao analisar SCR após {elapsed:.2f}s: {str(e)}")
            logger.error(f"Stack trace: {stack_trace}")
            return {
                "status": "error",
                "message": f"Erro ao analisar SCR do associado {cpf_cnpj}: {str(e)}",
                "details": stack_trace
            }
    
    def obter_info_associado(self, cpf_cnpj: str) -> Dict[str, Any]:
        """
        Obtém informações complementares do associado da tabela perfil_associado.
        
        Args:
            cpf_cnpj: CPF/CNPJ do associado (apenas números)
            
        Returns:
            Dict: Informações do associado ou None se não encontrado
        """
        try:
            logger.info(f"📋 Consultando informações do associado {cpf_cnpj}")
            spark = self._get_spark()
            
            # Consulta para obter informações básicas do associado
            sql_info = f"""
            SELECT 
                nome_associado,
                tipo_pessoa,
                renda_mensal,
                Codigo_conglomerado_economico,
                nome_grupo_economico,
                cpf_conjuge,
                nome_pessoa_conjuge
            FROM sicredi_coop_0914.bases_bi.perfil_associado
            WHERE num_cpf_cnpj = '{cpf_cnpj}'
            """
            
            # Executar com retry
            resultado = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_info).toPandas()
            )
            
            if resultado.empty:
                logger.warning(f"⚠️ Nenhuma informação encontrada para o associado {cpf_cnpj}")
                return None
            
            # Converter DataFrame para dicionário
            info = resultado.iloc[0].to_dict()
            
            # Tratar valores nulos
            for key, value in info.items():
                if pd.isna(value) or pd.isnull(value):
                    info[key] = None
            
            logger.info(f"✅ Informações do associado {cpf_cnpj} obtidas com sucesso")
            return info
            
        except Exception as e:
            logger.error(f"❌ Erro ao obter informações do associado: {str(e)}")
            return None
    
    def verificar_grupo_economico_scr(self, cpf_cnpj: str) -> Optional[str]:
        """
        Verifica se o CPF/CNPJ pertence a algum grupo econômico no SCR
        
        Args:
            cpf_cnpj: CPF ou CNPJ do associado
            
        Returns:
            str: Código do grupo econômico ou None se não pertencer a nenhum grupo
        """
        try:
            logger.info(f"🔍 Verificando grupo econômico no SCR para {cpf_cnpj}")
            spark = self._get_spark()
            
            # Consulta para verificar se o CPF/CNPJ pertence a um grupo econômico
            sql_grupo = f"""
            SELECT DISTINCT cod_grupo_economico
            FROM sicredi_coop_0914.bases_bi.tb_scr_bureau_completo
            WHERE cpf_cnpj = '{cpf_cnpj}'
            AND cod_grupo_economico IS NOT NULL
            AND cod_grupo_economico <> ''
            LIMIT 1
            """
            
            # Executar com retry
            resultado = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_grupo).toPandas()
            )
            
            if not resultado.empty and pd.notna(resultado['cod_grupo_economico'].iloc[0]):
                codigo_grupo = resultado['cod_grupo_economico'].iloc[0]
                logger.info(f"✅ Grupo econômico encontrado: {codigo_grupo}")
                return codigo_grupo
            else:
                logger.info(f"ℹ️ Nenhum grupo econômico encontrado no SCR para {cpf_cnpj}")
                return None
                
        except Exception as e:
            logger.error(f"❌ Erro ao verificar grupo econômico no SCR: {str(e)}")
            return None
    
    def analisar_scr_conjuge(self, cpf_conjuge: str, nome_conjuge: str) -> Dict[str, Any]:
        """
        Realiza uma análise do SCR do cônjuge do associado principal.
        
        Args:
            cpf_conjuge: CPF do cônjuge
            nome_conjuge: Nome do cônjuge
            
        Returns:
            Dict: Dados estruturados da análise do SCR do cônjuge
        """
        start_time = time.time()
        try:
            logger.info(f"🔍 Analisando SCR do cônjuge: {nome_conjuge} (CPF: {cpf_conjuge})")
            
            # Executar as consultas SQL para o cônjuge
            resultados = self.executar_consultas_sql(cpf_conjuge)
            
            # Verificar se há dados retornados
            if not resultados["visao_geral"].empty and not resultados["composicao_carteira"].empty and not resultados["evolucao_endividamento"].empty:
                # Estruturar os dados
                logger.info(f"🔄 Estruturando dados do SCR do cônjuge {cpf_conjuge}")
                dados_estruturados = self.estruturar_dados(resultados)
                
                # Adicionar informações do cônjuge
                dados_estruturados["cpf"] = cpf_conjuge
                dados_estruturados["nome"] = nome_conjuge
                
                elapsed = time.time() - start_time
                logger.info(f"✅ Análise do SCR do cônjuge concluída em {elapsed:.2f}s")
                
                return {
                    "status": "success",
                    "dados": dados_estruturados
                }
            else:
                logger.warning(f"⚠️ Não foram encontrados dados de SCR para o cônjuge {cpf_conjuge}")
                return {
                    "status": "no_data",
                    "message": f"Não foram encontrados dados de SCR para o cônjuge {cpf_conjuge}"
                }
                
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"❌ Erro ao analisar SCR do cônjuge após {elapsed:.2f}s: {str(e)}")
            return {
                "status": "error",
                "message": f"Erro ao analisar SCR do cônjuge {cpf_conjuge}: {str(e)}"
            }
    
    def analisar_grupo_economico(self, cod_grupo: str, cpf_cnpj_principal: str) -> Dict[str, Any]:
        """
        Realiza uma análise do grupo econômico no SCR
        
        Args:
            cod_grupo: Código do grupo econômico
            cpf_cnpj_principal: CPF/CNPJ do associado principal
            
        Returns:
            Dict: Dados estruturados da análise do grupo econômico
        """
        start_time = time.time()
        try:
            logger.info(f"🏢 Analisando grupo econômico {cod_grupo}")
            spark = self._get_spark()
            
            # Consulta para obter os membros do grupo econômico
            sql_membros = f"""
            SELECT DISTINCT cpf_cnpj
            FROM sicredi_coop_0914.bases_bi.tb_scr_bureau_completo
            WHERE cod_grupo_economico = '{cod_grupo}'
            AND cpf_cnpj <> '{cpf_cnpj_principal}'
            """
            
            # Executar com retry
            membros_df = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_membros).toPandas()
            )
            
            membros = membros_df['cpf_cnpj'].tolist() if not membros_df.empty else []
            logger.info(f"👥 Grupo econômico {cod_grupo} possui {len(membros)} membros adicionais")
            
            # Consulta para obter data base mais recente
            data_base_recente = SparkSessionManager.execute_with_retry(
                lambda: spark.sql("""
                SELECT MAX(data_base) as data_base_recente
                FROM sicredi_coop_0914.bases_bi.tb_scr_bureau_completo
                """).toPandas()['data_base_recente'].iloc[0]
            )
            
            logger.info(f"📅 Usando data base mais recente: {data_base_recente}")
            
            # Consulta para obter dados consolidados do grupo econômico
            sql_grupo_resumo = f"""
            WITH dados_grupo AS (
                SELECT 
                    cpf_cnpj,
                    data_base,
                    categoria,
                    valor,
                    qtd_ins_financeira,
                    qtd_operacao_sfn
                FROM sicredi_coop_0914.bases_bi.tb_scr_bureau_completo
                WHERE cod_grupo_economico = '{cod_grupo}'
                AND data_base = '{data_base_recente}'
            )
            
            SELECT 
                COUNT(DISTINCT cpf_cnpj) AS qtd_membros,
                SUM(CASE WHEN categoria = 'Carteira Ativa (A)' THEN valor ELSE 0 END) AS carteira_ativa_total,
                SUM(CASE WHEN categoria = 'Responsabilidade Total (F) = C + D + E' THEN valor ELSE 0 END) AS responsabilidade_total,
                MAX(CASE WHEN categoria = 'Responsabilidade Total (F) = C + D + E' THEN qtd_ins_financeira ELSE 0 END) AS max_instituicoes,
                SUM(CASE WHEN categoria = 'Responsabilidade Total (F) = C + D + E' THEN qtd_operacao_sfn ELSE 0 END) AS total_operacoes
            FROM dados_grupo
            """
            
            # Executar com retry
            grupo_resumo = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_grupo_resumo).toPandas()
            )
            
            # Consulta para obter a composição da carteira do grupo
            sql_composicao_grupo = f"""
            WITH dados_grupo AS (
                SELECT 
                    cpf_cnpj,
                    data_base,
                    categoria,
                    subcategoria,
                    valor
                FROM sicredi_coop_0914.bases_bi.tb_scr_bureau_completo
                WHERE cod_grupo_economico = '{cod_grupo}'
                AND data_base = '{data_base_recente}'
                AND categoria IN ('Empréstimos', 'Capital de Giro', 'Crédito Pessoal', 
                                 'Cheque Especial', 'Conta Garantida', 'Outros Empréstimos',
                                 'Financiamentos', 'Cartão De Crédito - Compra À Vista E Parcelado',
                                 'Outros Créditos (demais)', 'Coobrigações')
                AND valor > 0
            )
            
            SELECT 
                categoria,
                SUM(valor) AS valor_total,
                ROUND(SUM(valor) * 100.0 / (
                    SELECT SUM(valor) FROM dados_grupo
                ), 0) || '%' AS percentual
            FROM dados_grupo
            GROUP BY categoria
            ORDER BY valor_total DESC
            """
            
            # Executar com retry
            composicao_grupo = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_composicao_grupo).toPandas()
            )
            
            # Estruturar os dados do grupo
            if not grupo_resumo.empty:
                gr = grupo_resumo.iloc[0]
                
                dados_grupo = {
                    "cod_grupo": cod_grupo,
                    "membros": membros,
                    "qtd_membros": self.safe_int(gr["qtd_membros"]),
                    "carteira_ativa_total": self.safe_float(gr["carteira_ativa_total"]),
                    "responsabilidade_total": self.safe_float(gr["responsabilidade_total"]),
                    "max_instituicoes": self.safe_int(gr["max_instituicoes"]),
                    "total_operacoes": self.safe_int(gr["total_operacoes"]),
                    "composicao_carteira": []
                }
                
                # Adicionar composição da carteira do grupo
                for _, row in composicao_grupo.iterrows():
                    dados_grupo["composicao_carteira"].append({
                        "categoria": row["categoria"],
                        "valor_total": self.safe_float(row["valor_total"]),
                        "percentual": row["percentual"]
                    })
                
                # Obter nomes dos membros do grupo (quando disponíveis)
                if membros:
                    logger.info(f"🔍 Obtendo informações detalhadas dos {len(membros)} membros do grupo")
                    membros_info = []
                    for cpf_cnpj_membro in membros:
                        info = self.obter_info_associado(cpf_cnpj_membro)
                        if info:
                            membros_info.append({
                                "cpf_cnpj": cpf_cnpj_membro,
                                "nome": info.get("nome_associado", "Nome não disponível"),
                                "tipo_pessoa": info.get("tipo_pessoa", "Não informado")
                            })
                            logger.info(f"👤 Membro identificado: {info.get('nome_associado', 'Nome não disponível')} ({cpf_cnpj_membro})")
                        else:
                            membros_info.append({
                                "cpf_cnpj": cpf_cnpj_membro,
                                "nome": "Nome não disponível",
                                "tipo_pessoa": "Não informado"
                            })
                            logger.info(f"👤 Membro não identificado: {cpf_cnpj_membro}")
                    
                    dados_grupo["membros_info"] = membros_info
                
                elapsed = time.time() - start_time
                logger.info(f"✅ Análise do grupo econômico concluída em {elapsed:.2f}s")
                
                return {
                    "status": "success",
                    "dados": dados_grupo
                }
            else:
                logger.warning(f"⚠️ Não foram encontrados dados consolidados do grupo econômico {cod_grupo}")
                return {
                    "status": "no_data",
                    "message": f"Não foram encontrados dados consolidados do grupo econômico {cod_grupo}",
                    "dados": {
                        "cod_grupo": cod_grupo,
                        "membros": membros,
                        "qtd_membros": len(membros)
                    }
                }
                
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"❌ Erro ao analisar grupo econômico após {elapsed:.2f}s: {str(e)}")
            return {
                "status": "error",
                "message": f"Erro ao analisar grupo econômico {cod_grupo}: {str(e)}"
            }
    
    def executar_consultas_sql(self, cpf_cnpj: str) -> Dict[str, pd.DataFrame]:
        """
        Executa as três consultas SQL principais e retorna os resultados
        
        Args:
            cpf_cnpj: CPF ou CNPJ do associado (apenas números)
            
        Returns:
            Dict: Dicionário contendo os DataFrames com os resultados das consultas
        """
        start_time = time.time()
        logger.info(f"📊 Iniciando execução de consultas SQL para {cpf_cnpj}")
        
        # Verificar se os dados já estão em cache
        cache_key = f"sql_{cpf_cnpj}"
        if cache_key in self.cache_scr:
            logger.info(f"🔄 Usando resultados SQL em cache para {cpf_cnpj}")
            return self.cache_scr[cache_key]
        
        # SQL para visão geral
        sql_visao_geral = f"""
        -- Consulta para obter a visão geral do associado com evolução histórica
        WITH meses_recentes AS (
            -- Seleciona os últimos 12 meses de dados disponíveis para o associado
            SELECT DISTINCT data_base
            FROM sicredi_coop_0914.bases_bi.tb_scr_bureau_completo
            WHERE cpf_cnpj = '{cpf_cnpj}'
            ORDER BY data_base DESC
            LIMIT 12
        ),

        resumo_mensal AS (
            -- Extrai os principais indicadores para cada mês
            SELECT 
                scr.data_base,
                -- Formatação da data_base (AAAAMM) para MM/AAAA
                CONCAT(SUBSTRING(scr.data_base, 5, 2), '/', SUBSTRING(scr.data_base, 1, 4)) AS mes_ano,
                SUM(CASE WHEN scr.categoria = 'Carteira Ativa (A)' THEN scr.valor ELSE 0 END) AS carteira_ativa,
                SUM(CASE WHEN scr.categoria = 'Prejuízo (B)' THEN scr.valor ELSE 0 END) AS prejuizo,
                SUM(CASE WHEN scr.categoria = 'Carteira de Crédito (C) = A + B' THEN scr.valor ELSE 0 END) AS carteira_credito,
                SUM(CASE WHEN scr.categoria = 'Coobrigações (E)' THEN scr.valor ELSE 0 END) AS coobrigacoes,
                SUM(CASE WHEN scr.categoria = 'Responsabilidade Total (F) = C + D + E' THEN scr.valor ELSE 0 END) AS responsabilidade_total,
                SUM(CASE WHEN scr.categoria = 'Limite de Crédito (H)' THEN scr.valor ELSE 0 END) AS limite_credito,
                MAX(CASE WHEN scr.categoria = 'Responsabilidade Total (F) = C + D + E' THEN scr.qtd_ins_financeira ELSE NULL END) AS qtd_ins_financeira,
                MAX(CASE WHEN scr.categoria = 'Responsabilidade Total (F) = C + D + E' THEN scr.qtd_operacao_sfn ELSE NULL END) AS qtd_operacao_sfn
            FROM sicredi_coop_0914.bases_bi.tb_scr_bureau_completo scr
            JOIN meses_recentes m ON scr.data_base = m.data_base
            WHERE scr.cpf_cnpj = '{cpf_cnpj}'
            GROUP BY scr.data_base
            ORDER BY scr.data_base DESC
        ),

        tendencias AS (
            -- Calcula tendências e variações nos últimos meses
            SELECT
                MAX(CASE WHEN rn = 1 THEN mes_ano END) AS mes_atual,
                MAX(CASE WHEN rn = 1 THEN carteira_ativa END) AS carteira_ativa_atual,
                MAX(CASE WHEN rn = 3 THEN carteira_ativa END) AS carteira_ativa_3m,
                MAX(CASE WHEN rn = 6 THEN carteira_ativa END) AS carteira_ativa_6m,
                MAX(CASE WHEN rn = 12 THEN carteira_ativa END) AS carteira_ativa_12m,
                
                MAX(CASE WHEN rn = 1 THEN responsabilidade_total END) AS resp_total_atual,
                MAX(CASE WHEN rn = 3 THEN responsabilidade_total END) AS resp_total_3m,
                MAX(CASE WHEN rn = 6 THEN responsabilidade_total END) AS resp_total_6m,
                MAX(CASE WHEN rn = 12 THEN responsabilidade_total END) AS resp_total_12m,
                
                MAX(CASE WHEN rn = 1 THEN qtd_ins_financeira END) AS qtd_inst_atual,
                MAX(CASE WHEN rn = 12 THEN qtd_ins_financeira END) AS qtd_inst_12m,
                
                MAX(CASE WHEN rn = 1 THEN qtd_operacao_sfn END) AS qtd_op_atual,
                MAX(CASE WHEN rn = 12 THEN qtd_operacao_sfn END) AS qtd_op_12m
            FROM (
                SELECT 
                    *,
                    ROW_NUMBER() OVER (ORDER BY data_base DESC) AS rn
                FROM resumo_mensal
            ) ranked
        )

        -- Resultado final com todos os dados relevantes
        SELECT 
            -- Informações de identificação
            '{cpf_cnpj}' AS cpf_cnpj,
            
            -- Resumo da situação atual
            t.mes_atual,
            t.carteira_ativa_atual,
            t.resp_total_atual,
            t.qtd_inst_atual,
            t.qtd_op_atual,
            
            -- Variações percentuais
            CASE 
                WHEN t.carteira_ativa_3m > 0 
                THEN ROUND((t.carteira_ativa_atual - t.carteira_ativa_3m) / t.carteira_ativa_3m * 100, 2)
                ELSE 0
            END AS var_perc_carteira_3m,
            
            CASE 
                WHEN t.carteira_ativa_12m > 0 
                THEN ROUND((t.carteira_ativa_atual - t.carteira_ativa_12m) / t.carteira_ativa_12m * 100, 2)
                ELSE 0
            END AS var_perc_carteira_12m,
            
            CASE 
                WHEN t.resp_total_3m > 0 
                THEN ROUND((t.resp_total_atual - t.resp_total_3m) / t.resp_total_3m * 100, 2)
                ELSE 0
            END AS var_perc_resp_total_3m,
            
            CASE 
                WHEN t.resp_total_12m > 0 
                THEN ROUND((t.resp_total_atual - t.resp_total_12m) / t.resp_total_12m * 100, 2)
                ELSE 0
            END AS var_perc_resp_total_12m,
            
            -- Variação na quantidade de instituições e operações
            (t.qtd_inst_atual - t.qtd_inst_12m) AS var_qtd_inst_12m,
            (t.qtd_op_atual - t.qtd_op_12m) AS var_qtd_op_12m
        FROM tendencias t
        """
        
        # SQL para composição da carteira
        sql_composicao_carteira = f"""
        -- Consulta para obter a composição atual da carteira
        WITH meses_recentes AS (
            -- Seleciona os últimos 12 meses de dados disponíveis para o associado
            SELECT DISTINCT data_base
            FROM sicredi_coop_0914.bases_bi.tb_scr_bureau_completo
            WHERE cpf_cnpj = '{cpf_cnpj}'
            ORDER BY data_base DESC
            LIMIT 12
        ),

        resumo_mensal AS (
            -- Extrai os principais indicadores para cada mês
            SELECT 
                scr.data_base,
                -- Formatação da data_base (AAAAMM) para MM/AAAA
                CONCAT(SUBSTRING(scr.data_base, 5, 2), '/', SUBSTRING(scr.data_base, 1, 4)) AS mes_ano,
                SUM(CASE WHEN scr.categoria = 'Carteira Ativa (A)' THEN scr.valor ELSE 0 END) AS carteira_ativa,
                SUM(CASE WHEN scr.categoria = 'Prejuízo (B)' THEN scr.valor ELSE 0 END) AS prejuizo,
                SUM(CASE WHEN scr.categoria = 'Carteira de Crédito (C) = A + B' THEN scr.valor ELSE 0 END) AS carteira_credito,
                SUM(CASE WHEN scr.categoria = 'Coobrigações (E)' THEN scr.valor ELSE 0 END) AS coobrigacoes,
                SUM(CASE WHEN scr.categoria = 'Responsabilidade Total (F) = C + D + E' THEN scr.valor ELSE 0 END) AS responsabilidade_total,
                SUM(CASE WHEN scr.categoria = 'Limite de Crédito (H)' THEN scr.valor ELSE 0 END) AS limite_credito,
                MAX(CASE WHEN scr.categoria = 'Responsabilidade Total (F) = C + D + E' THEN scr.qtd_ins_financeira ELSE NULL END) AS qtd_instituicoes,
                MAX(CASE WHEN scr.categoria = 'Responsabilidade Total (F) = C + D + E' THEN scr.qtd_operacao_sfn ELSE NULL END) AS qtd_operacoes
            FROM sicredi_coop_0914.bases_bi.tb_scr_bureau_completo scr
            JOIN meses_recentes m ON scr.data_base = m.data_base
            WHERE scr.cpf_cnpj = '{cpf_cnpj}'
            GROUP BY scr.data_base
            ORDER BY scr.data_base DESC
        ),

        composicao_atual AS (
            -- Extrai a composição da carteira no mês mais recente
            SELECT 
                scr.categoria,
                scr.subcategoria,
                scr.valor,
                scr.percentual
            FROM sicredi_coop_0914.bases_bi.tb_scr_bureau_completo scr
            WHERE 
                scr.cpf_cnpj = '{cpf_cnpj}' AND
                scr.data_base = (SELECT MAX(data_base) FROM resumo_mensal) AND
                scr.valor > 0 AND
                scr.categoria IN ('Empréstimos', 'Capital de Giro', 'Crédito Pessoal', 
                                 'Cheque Especial', 'Conta Garantida', 'Outros Empréstimos',
                                 'Financiamentos', 'Cartão De Crédito - Compra À Vista E Parcelado',
                                 'Outros Créditos (demais)', 'Coobrigações')
            ORDER BY scr.valor DESC
        )

        -- Consulta para composição atual
        SELECT
            categoria,
            subcategoria,
            CASE 
                WHEN subcategoria IS NULL THEN categoria 
                ELSE CONCAT(categoria, ' - ', subcategoria) 
            END AS categoria_completa,
            valor,
            percentual
        FROM composicao_atual
        ORDER BY valor DESC
        """
        
        # SQL para evolução do endividamento
        sql_evolucao_endividamento = f"""
        -- Consulta para analisar a evolução do endividamento - Parte 1: Tendência
        WITH meses_recentes AS (
            -- Seleciona os últimos 12 meses de dados disponíveis para o associado
            SELECT DISTINCT data_base
            FROM sicredi_coop_0914.bases_bi.tb_scr_bureau_completo
            WHERE cpf_cnpj = '{cpf_cnpj}'
            ORDER BY data_base DESC
            LIMIT 12
        ),

        evolucao_mensal AS (
            -- Extrai os principais indicadores para cada mês
            SELECT 
                scr.data_base,
                -- Formatação da data_base (AAAAMM) para MM/AAAA
                CONCAT(SUBSTRING(scr.data_base, 5, 2), '/', SUBSTRING(scr.data_base, 1, 4)) AS mes_ano,
                SUM(CASE WHEN scr.categoria = 'Carteira Ativa (A)' THEN scr.valor ELSE 0 END) AS carteira_ativa,
                SUM(CASE WHEN scr.categoria = 'Prejuízo (B)' THEN scr.valor ELSE 0 END) AS prejuizo,
                SUM(CASE WHEN scr.categoria = 'Responsabilidade Total (F) = C + D + E' THEN scr.valor ELSE 0 END) AS responsabilidade_total,
                SUM(CASE WHEN scr.categoria = 'Empréstimos' THEN scr.valor ELSE 0 END) AS emprestimos,
                SUM(CASE WHEN scr.categoria = 'Financiamentos' THEN scr.valor ELSE 0 END) AS financiamentos,
                SUM(CASE WHEN scr.categoria = 'Cartão De Crédito - Compra À Vista E Parcelado' THEN scr.valor ELSE 0 END) AS cartao_credito,
                MAX(CASE WHEN scr.categoria = 'Responsabilidade Total (F) = C + D + E' THEN scr.qtd_ins_financeira ELSE NULL END) AS qtd_instituicoes,
                MAX(CASE WHEN scr.categoria = 'Responsabilidade Total (F) = C + D + E' THEN scr.qtd_operacao_sfn ELSE NULL END) AS qtd_operacoes
            FROM sicredi_coop_0914.bases_bi.tb_scr_bureau_completo scr
            JOIN meses_recentes m ON scr.data_base = m.data_base
            WHERE scr.cpf_cnpj = '{cpf_cnpj}'
            GROUP BY scr.data_base
            ORDER BY scr.data_base
        ),

        calculo_tendencias AS (
            -- Calcula tendências e médias móveis
            SELECT
                data_base,
                mes_ano,
                carteira_ativa,
                prejuizo,
                responsabilidade_total,
                emprestimos,
                financiamentos,
                cartao_credito,
                qtd_instituicoes,
                qtd_operacoes,
                
                -- Variação mensal
                LAG(responsabilidade_total, 1) OVER (ORDER BY data_base) AS resp_total_anterior,
                LAG(carteira_ativa, 1) OVER (ORDER BY data_base) AS carteira_ativa_anterior,
                
                -- Média móvel de 3 meses
                AVG(responsabilidade_total) OVER (
                    ORDER BY data_base
                    ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
                ) AS media_movel_3m,
                
                -- Tendência (regressão linear simplificada)
                ROW_NUMBER() OVER (ORDER BY data_base) AS periodo
            FROM evolucao_mensal
        ),

        tendencia_linear AS (
            -- Cálculo de coeficientes para regressão linear
            SELECT
                COUNT(*) AS n,
                SUM(periodo) AS sum_x,
                SUM(responsabilidade_total) AS sum_y,
                SUM(periodo * periodo) AS sum_xx,
                SUM(periodo * responsabilidade_total) AS sum_xy,
                
                -- Coeficientes da regressão linear (y = a + bx)
                (COUNT(*) * SUM(periodo * responsabilidade_total) - SUM(periodo) * SUM(responsabilidade_total)) / 
                (COUNT(*) * SUM(periodo * periodo) - SUM(periodo) * SUM(periodo)) AS b,
                
                (SUM(responsabilidade_total) - 
                 ((COUNT(*) * SUM(periodo * responsabilidade_total) - SUM(periodo) * SUM(responsabilidade_total)) / 
                  (COUNT(*) * SUM(periodo * periodo) - SUM(periodo) * SUM(periodo))) * SUM(periodo)) / COUNT(*) AS a
            FROM calculo_tendencias
        ),

        indicadores_tendencia AS (
            -- Calcula indicadores de tendência
            SELECT
                -- Último mês
                MAX(CASE WHEN rn = 1 THEN mes_ano END) AS mes_atual,
                MAX(CASE WHEN rn = 1 THEN responsabilidade_total END) AS resp_total_atual,
                
                -- Primeiro mês (mais antigo dos 12)
                MAX(CASE WHEN rn = (SELECT COUNT(*) FROM calculo_tendencias) THEN mes_ano END) AS mes_inicial,
                MAX(CASE WHEN rn = (SELECT COUNT(*) FROM calculo_tendencias) THEN responsabilidade_total END) AS resp_total_inicial,
                
                -- Variação total no período
                MAX(CASE WHEN rn = 1 THEN responsabilidade_total END) - 
                MAX(CASE WHEN rn = (SELECT COUNT(*) FROM calculo_tendencias) THEN responsabilidade_total END) AS variacao_absoluta,
                
                CASE 
                    WHEN MAX(CASE WHEN rn = (SELECT COUNT(*) FROM calculo_tendencias) THEN responsabilidade_total END) > 0
                    THEN (MAX(CASE WHEN rn = 1 THEN responsabilidade_total END) - 
                         MAX(CASE WHEN rn = (SELECT COUNT(*) FROM calculo_tendencias) THEN responsabilidade_total END)) / 
                         MAX(CASE WHEN rn = (SELECT COUNT(*) FROM calculo_tendencias) THEN responsabilidade_total END) * 100
                    ELSE 0
                END AS variacao_percentual,
                
                -- Coeficiente angular da regressão
                (SELECT b FROM tendencia_linear) AS coef_angular
            FROM (
                SELECT 
                    *,
                    ROW_NUMBER() OVER (ORDER BY data_base DESC) AS rn
                FROM calculo_tendencias
            ) ranked
        )

        -- Resultado final com análise de endividamento
        SELECT 
            '{cpf_cnpj}' AS cpf_cnpj,
            i.mes_inicial,
            i.mes_atual,
            i.resp_total_inicial,
            i.resp_total_atual,
            i.variacao_absoluta,
            ROUND(i.variacao_percentual, 2) AS variacao_percentual,
            
            -- Interpretação da tendência
            CASE
                WHEN i.coef_angular > 0 THEN 'CRESCENTE'
                WHEN i.coef_angular < 0 THEN 'DECRESCENTE'
                ELSE 'ESTÁVEL'
            END AS tendencia_endividamento,
            
            ROUND(i.coef_angular, 2) AS taxa_variacao_mensal
        FROM indicadores_tendencia i
        """
        
        # Executar as consultas no Spark
        spark = self._get_spark()
        
        try:
            logger.info("📊 Executando consulta de visão geral")
            visao_geral = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_visao_geral).toPandas()
            )
            
            logger.info("📊 Executando consulta de composição da carteira")
            composicao_carteira = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_composicao_carteira).toPandas()
            )
            
            logger.info("📊 Executando consulta de evolução do endividamento")
            evolucao_endividamento = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_evolucao_endividamento).toPandas()
            )
            
            resultados = {
                "visao_geral": visao_geral,
                "composicao_carteira": composicao_carteira,
                "evolucao_endividamento": evolucao_endividamento
            }
            
            # Verificar resultados
            if not visao_geral.empty:
                logger.info(f"📈 Visão geral: {len(visao_geral)} registros obtidos")
            else:
                logger.warning("⚠️ Consulta de visão geral não retornou dados")
                
            if not composicao_carteira.empty:
                logger.info(f"📊 Composição da carteira: {len(composicao_carteira)} categorias identificadas")
            else:
                logger.warning("⚠️ Consulta de composição da carteira não retornou dados")
                
            if not evolucao_endividamento.empty:
                logger.info(f"📈 Evolução do endividamento: dados obtidos de {evolucao_endividamento['mes_inicial'].iloc[0]} a {evolucao_endividamento['mes_atual'].iloc[0]}")
            else:
                logger.warning("⚠️ Consulta de evolução do endividamento não retornou dados")
            
            # Armazenar no cache
            self.cache_scr[cache_key] = resultados
            
            elapsed = time.time() - start_time
            logger.info(f"✅ Consultas SQL executadas com sucesso em {elapsed:.2f}s")
            
            return resultados
            
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"❌ Erro ao executar consultas SQL após {elapsed:.2f}s: {str(e)}")
            
            # Tentar reiniciar a sessão Spark
            logger.warning("🔄 Tentando reiniciar a sessão Spark após erro")
            SparkSessionManager.reset()
            self.spark = SparkSessionManager.get_or_create()
            
            # Tentar novamente as consultas
            logger.info("🔄 Executando consultas novamente após reinicialização do Spark")
            try:
                visao_geral = self.spark.sql(sql_visao_geral).toPandas()
                composicao_carteira = self.spark.sql(sql_composicao_carteira).toPandas()
                evolucao_endividamento = self.spark.sql(sql_evolucao_endividamento).toPandas()
                
                resultados = {
                    "visao_geral": visao_geral,
                    "composicao_carteira": composicao_carteira,
                    "evolucao_endividamento": evolucao_endividamento
                }
                
                elapsed_retry = time.time() - start_time
                logger.info(f"✅ Consultas SQL executadas com sucesso após retry em {elapsed_retry:.2f}s")
                return resultados
            except Exception as e2:
                elapsed_retry = time.time() - start_time
                logger.error(f"❌ Falha definitiva nas consultas SQL após {elapsed_retry:.2f}s: {str(e2)}")
                return {
                    "visao_geral": pd.DataFrame(),
                    "composicao_carteira": pd.DataFrame(),
                    "evolucao_endividamento": pd.DataFrame()
                }
    
    def estruturar_dados(self, resultados: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """
        Estrutura os dados para envio ao modelo LLM
        
        Args:
            resultados: Dicionário contendo os DataFrames com os resultados das consultas
            
        Returns:
            Dict: Dados estruturados para análise
        """
        start_time = time.time()
        logger.info("🔄 Estruturando dados para análise")
        
        dados_estruturados = {
            "visao_geral": {},
            "composicao_carteira": [],
            "evolucao_endividamento": {},
            "resumo_estatistico": {}
        }
        
        # Processar visão geral
        if not resultados["visao_geral"].empty:
            vg = resultados["visao_geral"].iloc[0]
            dados_estruturados["visao_geral"] = {
                "cpf_cnpj": vg["cpf_cnpj"],
                "mes_atual": vg["mes_atual"],
                "carteira_ativa_atual": self.safe_float(vg["carteira_ativa_atual"]),
                "resp_total_atual": self.safe_float(vg["resp_total_atual"]),
                "qtd_instituicoes": self.safe_int(vg["qtd_inst_atual"]),
                "qtd_operacoes": self.safe_int(vg["qtd_op_atual"]),
                "variacao_carteira_3m": self.safe_float(vg["var_perc_carteira_3m"]),
                "variacao_carteira_12m": self.safe_float(vg["var_perc_carteira_12m"]),
                "variacao_resp_total_3m": self.safe_float(vg["var_perc_resp_total_3m"]),
                "variacao_resp_total_12m": self.safe_float(vg["var_perc_resp_total_12m"]),
                "variacao_qtd_inst_12m": self.safe_int(vg["var_qtd_inst_12m"]),
                "variacao_qtd_op_12m": self.safe_int(vg["var_qtd_op_12m"])
            }
            logger.info(f"📊 Visão geral estruturada: Responsabilidade total R$ {dados_estruturados['visao_geral']['resp_total_atual']:,.2f}")
        
        # Processar composição da carteira
        if not resultados["composicao_carteira"].empty:
            for _, row in resultados["composicao_carteira"].iterrows():
                dados_estruturados["composicao_carteira"].append({
                    "categoria": row["categoria"],
                    "subcategoria": row["subcategoria"] if pd.notna(row["subcategoria"]) else None,
                    "categoria_completa": row["categoria_completa"],
                    "valor": self.safe_float(row["valor"]),
                    "percentual": row["percentual"]
                })
            logger.info(f"📊 Composição da carteira estruturada: {len(dados_estruturados['composicao_carteira'])} categorias")
        
        # Processar evolução do endividamento
        if not resultados["evolucao_endividamento"].empty:
            ee = resultados["evolucao_endividamento"].iloc[0]
            dados_estruturados["evolucao_endividamento"] = {
                "mes_inicial": ee["mes_inicial"],
                "mes_atual": ee["mes_atual"],
                "resp_total_inicial": self.safe_float(ee["resp_total_inicial"]),
                "resp_total_atual": self.safe_float(ee["resp_total_atual"]),
                "variacao_absoluta": self.safe_float(ee["variacao_absoluta"]),
                "variacao_percentual": self.safe_float(ee["variacao_percentual"]),
                "tendencia_endividamento": ee["tendencia_endividamento"],
                "taxa_variacao_mensal": self.safe_float(ee["taxa_variacao_mensal"])
            }
            logger.info(f"📈 Evolução do endividamento estruturada: Tendência {ee['tendencia_endividamento']}, variação {ee['variacao_percentual']}%")
        
        # Calcular estatísticas adicionais
        logger.info("🧮 Calculando estatísticas adicionais")
        dados_estruturados["resumo_estatistico"] = self.calcular_estatisticas_adicionais(dados_estruturados)
        
        elapsed = time.time() - start_time
        logger.info(f"✅ Estruturação de dados concluída em {elapsed:.2f}s")
        
        return dados_estruturados
    
    def calcular_estatisticas_adicionais(self, dados: Dict[str, Any]) -> Dict[str, Any]:
        """
        Calcula estatísticas adicionais para enriquecer a análise
        
        Args:
            dados: Dados estruturados das consultas
            
        Returns:
            Dict: Estatísticas adicionais calculadas
        """
        start_time = time.time()
        logger.info("🧮 Iniciando cálculo de estatísticas adicionais")
        resumo = {}
        
        # Se não houver dados suficientes, retorna um resumo vazio
        if not dados["visao_geral"] or not dados["evolucao_endividamento"]:
            logger.warning("⚠️ Dados insuficientes para calcular estatísticas adicionais")
            return resumo
        
        # Concentração da carteira (% da maior categoria)
        if dados["composicao_carteira"]:
            maior_categoria = max(dados["composicao_carteira"], key=lambda x: x["valor"])
            resumo["maior_categoria"] = maior_categoria["categoria_completa"]
            resumo["concentracao_maior_categoria"] = maior_categoria["percentual"]
            logger.info(f"📊 Maior categoria: {maior_categoria['categoria_completa']} ({maior_categoria['percentual']})")
        
        # Velocidade de crescimento (classificação)
        var_perc = dados["evolucao_endividamento"]["variacao_percentual"]
        if var_perc > 100:
            resumo["velocidade_crescimento"] = "Muito alta"
        elif var_perc > 50:
            resumo["velocidade_crescimento"] = "Alta"
        elif var_perc > 10:
            resumo["velocidade_crescimento"] = "Moderada"
        elif var_perc > -10:
            resumo["velocidade_crescimento"] = "Estável"
        else:
            resumo["velocidade_crescimento"] = "Decrescente"
        logger.info(f"📈 Velocidade de crescimento: {resumo.get('velocidade_crescimento', 'N/A')} ({var_perc:.2f}%)")
        
        # Diversificação da carteira
        qtd_categorias = len(set([item["categoria"] for item in dados["composicao_carteira"]]))
        if qtd_categorias >= 5:
            resumo["diversificacao"] = "Alta"
        elif qtd_categorias >= 3:
            resumo["diversificacao"] = "Média"
        else:
            resumo["diversificacao"] = "Baixa"
        logger.info(f"📊 Diversificação da carteira: {resumo.get('diversificacao', 'N/A')} ({qtd_categorias} categorias)")
        
        # Índice de concentração em instituições financeiras
        qtd_inst = dados["visao_geral"]["qtd_instituicoes"]
        if qtd_inst >= 6:
            resumo["concentracao_instituicoes"] = "Muito disperso"
        elif qtd_inst >= 4:
            resumo["concentracao_instituicoes"] = "Disperso"
        elif qtd_inst >= 2:
            resumo["concentracao_instituicoes"] = "Moderado"
        else:
            resumo["concentracao_instituicoes"] = "Concentrado"
        logger.info(f"🏦 Concentração em instituições: {resumo.get('concentracao_instituicoes', 'N/A')} ({qtd_inst} instituições)")
        
        # Tendência de crescimento nos últimos 3 meses vs 12 meses
        var_3m = dados["visao_geral"]["variacao_resp_total_3m"]
        var_12m = dados["visao_geral"]["variacao_resp_total_12m"]
        
        if var_3m > var_12m:
            resumo["tendencia_recente"] = "Aceleração do endividamento"
        elif var_3m < 0 and var_12m > 0:
            resumo["tendencia_recente"] = "Reversão recente (redução)"
        elif var_3m > 0 and var_12m < 0:
            resumo["tendencia_recente"] = "Reversão recente (aumento)"
        elif var_3m < var_12m and var_3m > 0:
            resumo["tendencia_recente"] = "Desaceleração do crescimento"
        else:
            resumo["tendencia_recente"] = "Estabilidade"
        logger.info(f"📈 Tendência recente: {resumo.get('tendencia_recente', 'N/A')} (3m: {var_3m:.2f}%, 12m: {var_12m:.2f}%)")
        
        # Relação entre operações e instituições
        if qtd_inst > 0:
            ops_por_inst = dados["visao_geral"]["qtd_operacoes"] / qtd_inst
            if ops_por_inst > 3:
                resumo["padrao_relacionamento"] = "Alta concentração de operações por instituição"
            elif ops_por_inst > 1.5:
                resumo["padrao_relacionamento"] = "Padrão normal de operações por instituição"
            else:
                resumo["padrao_relacionamento"] = "Baixa concentração de operações por instituição"
            logger.info(f"🔄 Padrão de relacionamento: {resumo.get('padrao_relacionamento', 'N/A')} ({ops_por_inst:.2f} operações/instituição)")
        
        # Classificação do nível de endividamento
        resp_total = dados["visao_geral"]["resp_total_atual"]
        if resp_total > 500000:
            resumo["nivel_endividamento"] = "Muito elevado"
        elif resp_total > 100000:
            resumo["nivel_endividamento"] = "Elevado"
        elif resp_total > 30000:
            resumo["nivel_endividamento"] = "Moderado"
        elif resp_total > 5000:
            resumo["nivel_endividamento"] = "Baixo"
        else:
            resumo["nivel_endividamento"] = "Muito baixo"
        logger.info(f"💰 Nível de endividamento: {resumo.get('nivel_endividamento', 'N/A')} (R$ {resp_total:,.2f})")
        
        elapsed = time.time() - start_time
        logger.info(f"✅ Cálculo de estatísticas adicionais concluído em {elapsed:.2f}s")
        
        return resumo
    
    def gerar_analise_llm(self, dados_estruturados: Dict[str, Any]) -> str:
        """
        Envia os dados estruturados para o modelo LLM e retorna a análise
        
        Args:
            dados_estruturados: Dados estruturados para análise
            
        Returns:
            str: Análise gerada pelo modelo LLM
        """
        start_time = time.time()
        logger.info("🧠 Iniciando geração de análise com modelo LLM")
        
        # Formatar valores monetários
        def formatar_moeda(valor):
            if valor is None or valor == 0:
                return "R$ 0,00"
            return f"R$ {valor:,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")
        
        # Formatar percentuais
        def formatar_percentual(valor):
            if valor is None:
                return "0,00%"
            return f"{valor:.2f}%".replace(".", ",")
        
        # Obter nome do associado e CPF/CNPJ para o cabeçalho
        nome_associado = "Não informado"
        cpf_cnpj = dados_estruturados["visao_geral"].get("cpf_cnpj", "")
        
        if "info_associado" in dados_estruturados and dados_estruturados["info_associado"].get("nome"):
            nome_associado = dados_estruturados["info_associado"].get("nome")
            logger.info(f"👤 Gerando análise para: {nome_associado} ({cpf_cnpj})")
        
        # Construir o prompt para análise técnica do SCR
        logger.info("📝 Construindo prompt para o modelo LLM")
        prompt = f"""
        # ANÁLISE TÉCNICA DO SISTEMA DE INFORMAÇÕES DE CRÉDITO (SCR) - DOC 3040

        ## ASSOCIADO: {nome_associado} - CPF/CNPJ: {cpf_cnpj}

        Você é um analista financeiro especializado em análise de risco de crédito e interpretação de dados do Sistema de Informações de Crédito (SCR) do Banco Central. Foi solicitado que você elabore uma análise técnica focada exclusivamente nos dados do SCR do associado, sem abordar aspectos de perfil pessoal ou profissional que já são tratados por outra análise.

        ## DADOS DO SCR - VISÃO GERAL

        **CPF/CNPJ:** {dados_estruturados["visao_geral"]["cpf_cnpj"]}  
        **Nome do Associado:** {nome_associado}  
        **Data de referência:** {dados_estruturados["visao_geral"]["mes_atual"]}  
        **Período analisado:** {dados_estruturados["evolucao_endividamento"]["mes_inicial"]} a {dados_estruturados["evolucao_endividamento"]["mes_atual"]}

        ## SÍNTESE DA SITUAÇÃO ATUAL

        | Indicador | Valor | Variação 3 meses | Variação 12 meses |
        |-----------|-------|------------------|-------------------|
        | Carteira Ativa | {formatar_moeda(dados_estruturados["visao_geral"]["carteira_ativa_atual"])} | {formatar_percentual(dados_estruturados["visao_geral"]["variacao_carteira_3m"])} | {formatar_percentual(dados_estruturados["visao_geral"]["variacao_carteira_12m"])} |
        | Responsabilidade Total | {formatar_moeda(dados_estruturados["visao_geral"]["resp_total_atual"])} | {formatar_percentual(dados_estruturados["visao_geral"]["variacao_resp_total_3m"])} | {formatar_percentual(dados_estruturados["visao_geral"]["variacao_resp_total_12m"])} |
        | Quantidade de Instituições | {dados_estruturados["visao_geral"]["qtd_instituicoes"]} | - | {dados_estruturados["visao_geral"]["variacao_qtd_inst_12m"]} |
        | Quantidade de Operações | {dados_estruturados["visao_geral"]["qtd_operacoes"]} | - | {dados_estruturados["visao_geral"]["variacao_qtd_op_12m"]} |

        ## COMPOSIÇÃO DETALHADA DA CARTEIRA

        """
        
        # Adicionar tabela de composição da carteira
        prompt += """
        | Categoria | Valor | Percentual |
        |-----------|-------|------------|
        """
        
        for item in dados_estruturados["composicao_carteira"]:
            prompt += f"| {item['categoria_completa']} | {formatar_moeda(item['valor'])} | {item['percentual']} |\n"
        
        # Adicionar evolução do endividamento
        evolucao = dados_estruturados["evolucao_endividamento"]
        prompt += f"""

        ## ANÁLISE DE TENDÊNCIA DO ENDIVIDAMENTO

        **Responsabilidade inicial:** {formatar_moeda(evolucao["resp_total_inicial"])}  
        **Responsabilidade atual:** {formatar_moeda(evolucao["resp_total_atual"])}  
        **Variação absoluta:** {formatar_moeda(evolucao["variacao_absoluta"])}  
        **Variação percentual:** {formatar_percentual(evolucao["variacao_percentual"])}  
        **Tendência identificada:** {evolucao["tendencia_endividamento"]}  
        **Taxa média de variação mensal:** {formatar_percentual(evolucao["taxa_variacao_mensal"])}

        ## INDICADORES ESTATÍSTICOS COMPLEMENTARES

        """
        
        # Adicionar estatísticas adicionais em formato de tabela
        prompt += """
        | Indicador | Valor |
        |-----------|-------|
        """
        
        for chave, valor in dados_estruturados["resumo_estatistico"].items():
            prompt += f"| {chave.replace('_', ' ').title()} | {valor} |\n"
        
        # Adicionar informações do cônjuge, se disponíveis
        if "analises_relacionadas" in dados_estruturados and "conjuge" in dados_estruturados["analises_relacionadas"]:
            conjuge = dados_estruturados["analises_relacionadas"]["conjuge"]
            if conjuge["status"] == "success" and "dados" in conjuge:
                try:
                    dados_conjuge = conjuge["dados"]
                    logger.info(f"👨‍👩‍👧‍👦 Adicionando análise do cônjuge ao prompt")
                    prompt += f"""

            ## ANÁLISE COMPARATIVA - CÔNJUGE

            **Nome:** {dados_conjuge.get("nome", "Não informado")}  
            **CPF:** {dados_conjuge.get("cpf", "Não informado")}

            ### Endividamento do Cônjuge

            **Responsabilidade Total:** {formatar_moeda(dados_conjuge["visao_geral"].get("resp_total_atual", 0))}  
            **Carteira Ativa:** {formatar_moeda(dados_conjuge["visao_geral"].get("carteira_ativa_atual", 0))}  
            **Quantidade de Instituições:** {dados_conjuge["visao_geral"].get("qtd_instituicoes", 0)}  
            **Quantidade de Operações:** {dados_conjuge["visao_geral"].get("qtd_operacoes", 0)}  
            **Tendência do Endividamento:** {dados_conjuge["evolucao_endividamento"].get("tendencia_endividamento", "Não informado")}

            ### Principais Categorias de Crédito do Cônjuge
            """
                    # Adicionar até 3 principais categorias do cônjuge
                    for i, item in enumerate(dados_conjuge.get("composicao_carteira", [])[:3]):
                        prompt += f"""
            {i+1}. {item.get('categoria_completa', 'Não informado')}: {formatar_moeda(item.get('valor', 0))} ({item.get('percentual', '0%')})"""
                except Exception as e:
                    logger.warning(f"⚠️ Erro ao processar dados do cônjuge para o prompt: {str(e)}")
                    prompt += f"""

            ## ANÁLISE COMPARATIVA - CÔNJUGE

            **Nome:** {conjuge.get("nome", "Não informado")}  
            **CPF:** {conjuge.get("cpf", "Não informado")}

            Não foi possível processar os dados detalhados do cônjuge.
            """
        
        # Adicionar informações do grupo econômico, se disponíveis
        if "analises_relacionadas" in dados_estruturados and "grupo_economico" in dados_estruturados["analises_relacionadas"]:
            grupo = dados_estruturados["analises_relacionadas"]["grupo_economico"]
            if grupo["status"] == "success" and "dados" in grupo:
                try:
                    dados_grupo = grupo["dados"]
                    logger.info(f"🏢 Adicionando análise do grupo econômico ao prompt")
                    prompt += f"""

            ## ANÁLISE DO GRUPO ECONÔMICO

            **Código do Grupo:** {dados_grupo["cod_grupo"]}  
            **Quantidade de Membros:** {dados_grupo["qtd_membros"]}  
            **Carteira Ativa Total do Grupo:** {formatar_moeda(dados_grupo["carteira_ativa_total"])}  
            **Responsabilidade Total do Grupo:** {formatar_moeda(dados_grupo["responsabilidade_total"])}  
            **Máximo de Instituições por Membro:** {dados_grupo["max_instituicoes"]}  
            **Total de Operações no Grupo:** {dados_grupo["total_operacoes"]}

            ### Composição da Carteira do Grupo

            | Categoria | Valor | Percentual |
            |-----------|-------|------------|
            """
                    
                    # Adicionar composição da carteira do grupo em formato de tabela
                    for item in dados_grupo["composicao_carteira"]:
                        prompt += f"| {item['categoria']} | {formatar_moeda(item['valor_total'])} | {item['percentual']} |\n"
                    
                    # Adicionar lista de membros do grupo
                    if "membros_info" in dados_grupo:
                        prompt += """
                        
            ### Membros do Grupo Econômico
            """
                        
                        for i, membro in enumerate(dados_grupo["membros_info"]):
                            if membro["cpf_cnpj"] != dados_estruturados["visao_geral"]["cpf_cnpj"]:
                                prompt += f"""
            {i+1}. {membro['nome']} ({membro['cpf_cnpj']}) - {membro['tipo_pessoa']}"""
                except Exception as e:
                    logger.warning(f"⚠️ Erro ao processar dados do grupo econômico para o prompt: {str(e)}")
                    prompt += f"""

            ## ANÁLISE DO GRUPO ECONÔMICO

            **Código do Grupo:** {grupo["dados"].get("cod_grupo", "Não informado")}

            Não foi possível processar os dados detalhados do grupo econômico.
            """
        
        # Adicionar solicitação de análise técnica focada no SCR
        prompt += """

        # SOLICITAÇÃO DE ANÁLISE TÉCNICA DO SCR

        Com base nos dados apresentados acima, elabore uma análise técnica detalhada focada exclusivamente nos dados do Sistema de Informações de Crédito (SCR) do associado. Sua análise deve ser estruturada da seguinte forma:

        ## 1. INTRODUÇÃO
        
        Breve introdução identificando o associado pelo nome e CPF/CNPJ e explicando que esta é uma análise focada exclusivamente no SCR (Sistema de Informações de Crédito) com base no documento 3040 do Banco Central.

        ## 2. ANÁLISE PRINCIPAL DO ASSOCIADO

        ### 2.1 Composição da Carteira de Crédito
        - Análise detalhada da distribuição do endividamento entre diferentes categorias
        - Identificação de concentrações excessivas em modalidades específicas
        - Avaliação da adequação da composição considerando o perfil de risco
        - Análise de diversificação e seus impactos na exposição ao risco

        ### 2.2 Evolução Temporal do Endividamento
        - Interpretação detalhada da tendência identificada (crescente, decrescente ou estável)
        - Análise da velocidade de variação do endividamento
        - Comparação entre tendências de curto prazo (3 meses) e médio prazo (12 meses)
        - Identificação de pontos de inflexão ou mudanças significativas no padrão
        - Projeção do endividamento para os próximos meses com base na taxa de variação observada

        ### 2.3 Relacionamento com Instituições Financeiras
        - Avaliação do número de instituições financeiras e sua evolução
        - Interpretação do significado da concentração ou dispersão observada
        - Análise do número de operações e sua variação
        - Identificação de padrões de "rolagem" de dívidas ou multiplicação de fontes de crédito

        ### 2.4 Indicadores de Alerta e Sinais de Risco
        - Identificação objetiva de sinais de alerta no comportamento de crédito
        - Análise de padrões que indiquem potencial deterioração financeira
        - Avaliação técnica dos riscos identificados e sua gravidade
        """
        
        # Adicionar seções para análise do cônjuge e grupo econômico, se aplicável
        if ("analises_relacionadas" in dados_estruturados and 
            ("conjuge" in dados_estruturados["analises_relacionadas"] and dados_estruturados["analises_relacionadas"]["conjuge"].get("status") == "success" or
             "grupo_economico" in dados_estruturados["analises_relacionadas"] and dados_estruturados["analises_relacionadas"]["grupo_economico"].get("status") == "success")):
            
            prompt += """

        ## 3. ANÁLISES COMPLEMENTARES
        """
            
            if "conjuge" in dados_estruturados["analises_relacionadas"] and dados_estruturados["analises_relacionadas"]["conjuge"].get("status") == "success":
                prompt += """

        ### 3.1 Análise Resumida do SCR do Cônjuge
        - Breve análise da situação do cônjuge no SCR
        - Comparação com o perfil do associado principal
        - Identificação de padrões comuns ou divergentes
        - Principais pontos de atenção no endividamento do cônjuge
        """
            
            if "grupo_economico" in dados_estruturados["analises_relacionadas"] and dados_estruturados["analises_relacionadas"]["grupo_economico"].get("status") == "success":
                prompt += """

        ### 3.2 Análise Resumida do Grupo Econômico
        - Breve análise da situação do grupo econômico no SCR
        - Relevância do associado principal dentro do grupo
        - Identificação de padrões comuns ou divergentes
        - Principais pontos de atenção no endividamento do grupo
        """
            
            # Adicionar seção para análise consolidada
            prompt += """

        ## 4. ANÁLISE CONSOLIDADA
        - Visão integrada considerando o associado, cônjuge e/ou grupo econômico
        - Avaliação de riscos sistêmicos e interconexões
        - Identificação de vulnerabilidades compartilhadas
        - Avaliação do risco de contágio financeiro entre os membros relacionados
        """
        
        # Finalizar o prompt com a conclusão
        prompt += """

        ## 5. CONCLUSÃO TÉCNICA
        - Síntese técnica do perfil de endividamento no SCR
        - Avaliação objetiva dos principais riscos identificados
        - Perspectivas de evolução do endividamento com base nas tendências observadas

        ---

        **Importante:**

        1. Mantenha o foco exclusivamente na análise técnica dos dados do SCR, sem abordar aspectos de perfil pessoal ou profissional do associado.
        
        2. Utilize linguagem técnica apropriada para análise de crédito, com foco em dados quantitativos e padrões objetivos.
        
        3. Apresente dados quantitativos sempre que possível, incluindo percentuais, valores e comparações objetivas.
        
        4. Identifique padrões e correlações entre diferentes aspectos do comportamento financeiro no SCR.
        
        5. Organize sua análise em seções bem delimitadas, utilizando formatação adequada para facilitar a consulta.
        
        6. Evite fazer suposições sobre o perfil do associado que não estejam diretamente evidenciadas nos dados do SCR.
        
        7. Lembre-se que esta análise é uma skill específica de um agente de IA analista de crédito, focada exclusivamente na análise do SCR. Outras skills complementares analisarão outros aspectos como perfil do associado e histórico de relacionamento com a cooperativa.
        """
        
        # Implementar mecanismo de retry com backoff exponencial
        max_retries = self.max_retries
        retry_delay = 10  # segundos
        
        logger.info(f"🤖 Enviando prompt para o modelo LLM (tamanho: {len(prompt)} caracteres)")
        
        for attempt in range(max_retries):
            try:
                # Registrar tentativa
                # Registrar tentativa
                logger.info(f"🔄 Tentativa {attempt+1}/{max_retries} de chamada ao modelo LLM")
                
                # Monitorar recursos antes da chamada
                resource_monitor.check_resources(force=True)
                
                # Registrar início da chamada
                call_start = time.time()
                
                # Chamar o modelo usando a API OpenAI configurada para Databricks
                response = self.openai_client.chat.completions.create(
                    model="databricks-claude-3-7-sonnet",
                    messages=[
                        {"role": "system", "content": "Você é um analista financeiro especializado em análise de risco de crédito e interpretação de dados do Sistema de Informações de Crédito (SCR) do Banco Central. Sua análise deve ser técnica, detalhada e baseada em evidências, com foco exclusivo nos dados do SCR, sem abordar aspectos de perfil pessoal ou profissional do associado."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.0,
                    max_tokens=8000
                )
                
                # Registrar tempo de resposta
                call_duration = time.time() - call_start
                logger.info(f"✅ Resposta do modelo LLM recebida em {call_duration:.2f}s")
                
                # Extrair e retornar a resposta
                analise = response.choices[0].message.content
                
                # Registrar estatísticas da resposta
                logger.info(f"📊 Análise gerada com {len(analise)} caracteres")
                
                # Tempo total de geração
                elapsed = time.time() - start_time
                logger.info(f"✅ Análise LLM concluída em {elapsed:.2f}s")
                
                return analise
                
            except Exception as e:
                if "timeout" in str(e).lower() and attempt < max_retries - 1:
                    # Se for timeout e não for a última tentativa, esperar e tentar novamente
                    logger.warning(f"⚠️ Tentativa {attempt+1} falhou com timeout. Tentando novamente em {retry_delay} segundos...")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # Backoff exponencial
                else:
                    # Se for outro erro ou a última tentativa, tentar com um prompt mais curto
                    logger.error(f"❌ Erro na chamada ao modelo LLM: {str(e)}")
                    logger.warning("⚠️ Tentando com prompt reduzido como fallback")
                    
                    try:
                        # Criar uma versão reduzida do prompt
                        prompt_reduzido = prompt.split("# SOLICITAÇÃO DE ANÁLISE TÉCNICA DO SCR")[0] + """
                        
                        # SOLICITAÇÃO DE ANÁLISE TÉCNICA DO SCR
                        
                        Com base nos dados apresentados acima, elabore uma análise técnica focada exclusivamente nos dados do SCR, abordando:
                        
                        1. Introdução: Identificando o associado pelo nome e CPF/CNPJ, explicando que esta é uma análise focada no SCR
                        2. Análise Principal: Composição da carteira, evolução do endividamento, relacionamento com instituições e indicadores de alerta
                        3. Análises Complementares: Breve análise do cônjuge e/ou grupo econômico (se aplicável)
                        4. Análise Consolidada: Visão integrada considerando todas as partes relacionadas (se aplicável)
                        5. Conclusão Técnica: Síntese do perfil de endividamento e perspectivas
                        
                        Mantenha o foco nos dados técnicos do SCR, sem abordar aspectos de perfil pessoal ou profissional.
                        """
                        
                        logger.info("🔄 Tentando modelo alternativo com prompt reduzido")
                        response = self.openai_client.chat.completions.create(
                            model="databricks-llama-4-maverick",
                            messages=[
                                {"role": "system", "content": "Você é um analista financeiro especializado em análise de risco de crédito e interpretação de dados do SCR."},
                                {"role": "user", "content": prompt_reduzido}
                            ],
                            temperature=0.0,
                            max_tokens=8000
                        )
                        
                        analise = response.choices[0].message.content
                        logger.info("✅ Análise gerada com modelo alternativo")
                        return analise
                        
                    except Exception as e2:
                        logger.error(f"❌ Erro no modelo de fallback: {str(e2)}")
                        # Em caso de falha total, retornar uma análise básica com os dados principais
                        nome_associado = dados_estruturados.get("info_associado", {}).get("nome", "Associado")
                        cpf_cnpj = dados_estruturados["visao_geral"].get("cpf_cnpj", "")
                        resp_total = formatar_moeda(dados_estruturados["visao_geral"].get("resp_total_atual", 0))
                        tendencia = dados_estruturados["evolucao_endividamento"].get("tendencia_endividamento", "Não disponível")
                        var_12m = formatar_percentual(dados_estruturados["visao_geral"].get("variacao_resp_total_12m", 0))
                        
                        logger.warning("⚠️ Gerando análise básica de emergência")
                        return f"""
                        # ANÁLISE TÉCNICA DO SCR - {nome_associado} (CPF/CNPJ: {cpf_cnpj})
                        
                        ## ANÁLISE BÁSICA DE EMERGÊNCIA
                        
                        Não foi possível gerar uma análise completa devido a limitações técnicas. Abaixo estão os principais indicadores do SCR:
                        
                        - Responsabilidade Total: {resp_total}
                        - Tendência do Endividamento: {tendencia}
                        - Variação em 12 meses: {var_12m}
                        - Quantidade de Instituições: {dados_estruturados["visao_geral"].get("qtd_instituicoes", 0)}
                        - Quantidade de Operações: {dados_estruturados["visao_geral"].get("qtd_operacoes", 0)}
                        
                        ## Principais Categorias de Crédito
                        
                        {', '.join([f"{item['categoria_completa']}: {item['percentual']}" for item in dados_estruturados["composicao_carteira"][:3]])}
                        
                        ## Indicadores de Alerta
                        
                        {', '.join([f"{k.replace('_', ' ').title()}: {v}" for k, v in dados_estruturados["resumo_estatistico"].items()][:5])}
                        
                        Esta é uma análise técnica focada exclusivamente nos dados do SCR (Sistema de Informações de Crédito) com base no documento 3040 do Banco Central.
                        """
        
        # Se todas as tentativas falharem
        logger.critical("❌ Todas as tentativas de geração de análise falharam")
        return "Erro ao gerar análise com o modelo LLM: Todas as tentativas falharam."

# Função para uso em notebooks Databricks
def analisar_scr_associado(cpf_cnpj: str) -> Dict[str, Any]:
    """
    Função de conveniência para análise do SCR de um associado.
    
    Args:
        cpf_cnpj: CPF ou CNPJ do associado
        
    Returns:
        Dict: Dicionário com os resultados da análise
    """
    logger.info(f"🚀 Iniciando análise do SCR para {cpf_cnpj} via função de conveniência")
    analisador = AnalisadorSCR()
    resultado = analisador.analisar_scr_associado(cpf_cnpj)
    logger.info(f"✅ Análise concluída com status: {resultado.get('status', 'desconhecido')}")
    return resultado

# Função principal para teste da análise de SCR
def main():
    """
    Função principal para teste da análise de SCR
    """
    logger.info("🚀 Iniciando execução principal do AnalisadorSCR")
    
    # Obter o CPF/CNPJ do widget (para teste interativo)
    try:
        cpf_cnpj = dbutils.widgets.get("cpf_cnpj")
        logger.info(f"📋 CPF/CNPJ obtido do widget: {cpf_cnpj}")
    except:
        # Para testes diretos sem widget
        cpf_cnpj = "01492562130"  # CPF/CNPJ de exemplo
        logger.info(f"📋 Usando CPF/CNPJ de exemplo: {cpf_cnpj}")
    
    # Realizar a análise
    start_time = time.time()
    analisador = AnalisadorSCR()
    resultado = analisador.analisar_scr_associado(cpf_cnpj)
    elapsed = time.time() - start_time
    
    # Exibir o resultado
    if resultado["status"] == "success":
        # Verificar se há análises relacionadas
        tem_conjuge = "analises_relacionadas" in resultado["dados"] and "conjuge" in resultado["dados"]["analises_relacionadas"]
        tem_grupo = "analises_relacionadas" in resultado["dados"] and "grupo_economico" in resultado["dados"]["analises_relacionadas"]
        
        logger.info(f"✅ Análise concluída com sucesso em {elapsed:.2f}s")
        logger.info(f"👨‍👩‍👧‍👦 Análise inclui dados do cônjuge: {'Sim' if tem_conjuge else 'Não'}")
        logger.info(f"🏢 Análise inclui dados do grupo econômico: {'Sim' if tem_grupo else 'Não'}")
        logger.info(f"📊 Foram gerados {len(resultado.get('graficos', []))} gráficos")
        
        # Exibir a análise formatada
        try:
            # Criar HTML com análise e gráficos
            html_output = f"""
            <h2>Análise Técnica do SCR - {cpf_cnpj}</h2>
            {'<p><strong>Análise inclui dados do cônjuge</strong></p>' if tem_conjuge else ''}
            {'<p><strong>Análise inclui dados do grupo econômico</strong></p>' if tem_grupo else ''}
            
            <div style='white-space: pre-wrap; font-family: Arial, sans-serif; line-height: 1.6; max-width: 1200px; margin: 0 auto;'>
                {resultado['analise']}
            </div>
            
            <h3>Gráficos Gerados</h3>
            <div style='display: flex; flex-wrap: wrap; gap: 20px;'>
            """
            
            # Adicionar gráficos ao HTML
            for grafico in resultado.get("graficos_base64", []):
                html_output += f"""
                <div style='margin-bottom: 30px; width: 100%;'>
                    <h4>{grafico['titulo']}</h4>
                    <img src="data:image/png;base64,{grafico['base64']}" style='max-width: 100%; height: auto;'>
                    <p><em>{grafico['descricao']}</em></p>
                </div>
                """
            
            html_output += "</div>"
            
            displayHTML(html_output)
            logger.info("📄 Análise e gráficos exibidos com sucesso na interface HTML")
        except:
            # Fallback para ambientes sem displayHTML
            print(f"Análise Técnica do SCR - {cpf_cnpj}")
            print(f"Status: {resultado['status']}")
            print(resultado['analise'])
            print(f"\nForam gerados {len(resultado.get('graficos', []))} gráficos no diretório: {resultado.get('graficos', [{}])[0].get('caminho', '').rsplit('/', 1)[0] if resultado.get('graficos') else ''}")
            logger.info("📄 Análise exibida como texto no console")
    else:
        # Exibir mensagem de erro
        try:
            displayHTML(f"<h2>Erro na Análise SCR</h2><div>{resultado['message']}</div>")
            logger.error(f"❌ Erro na análise: {resultado['message']}")
        except:
            print(f"Erro na Análise SCR: {resultado['message']}")
            logger.error(f"❌ Erro na análise: {resultado['message']}")

# Se o script for executado diretamente (não importado)
if __name__ == "__main__":
    logger.info("🏁 Executando AnalisadorSCR como script principal")
    main()

}

ANALISE CARTEIRA{
import re
import json
import pandas as pd
import numpy as np
import concurrent.futures
import time
import logging
import sys
import traceback
import socket
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # Backend não-interativo para ambientes sem display
import seaborn as sns
import io
import base64
from pathlib import Path
from datetime import datetime
import os
from typing import Dict, List, Any, Optional, Tuple, Union
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count, sum as spark_sum, max as spark_max, min as spark_min, avg as spark_avg, expr
from pyspark.sql.types import DecimalType, DoubleType
from openai import OpenAI
import py4j.protocol

# Configuração avançada de logging com formatação colorida e detalhada
class ColoredFormatter(logging.Formatter):
    """Formatador de logs com cores para melhor visualização"""
    
    COLORS = {
        'DEBUG': '\033[94m',  # Azul
        'INFO': '\033[92m',   # Verde
        'WARNING': '\033[93m', # Amarelo
        'ERROR': '\033[91m',  # Vermelho
        'CRITICAL': '\033[91m\033[1m',  # Vermelho negrito
        'RESET': '\033[0m'    # Reset
    }
    
    def format(self, record):
        log_message = super().format(record)
        levelname = record.levelname
        if levelname in self.COLORS:
            return f"{self.COLORS[levelname]}{log_message}{self.COLORS['RESET']}"
        return log_message

# Configuração de logging avançada
def setup_logging(level=logging.INFO):
    """Configura o sistema de logging com formatação avançada"""
    logger = logging.getLogger("AnalisadorCredito")
    logger.setLevel(level)
    
    # Limpar handlers existentes
    if logger.handlers:
        logger.handlers = []
    
    # Handler para console com cores
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(level)
    
    # Formatação detalhada com timestamp, nível e contexto
    log_format = '%(asctime)s [%(levelname)s] %(name)s:%(lineno)d - %(message)s'
    colored_formatter = ColoredFormatter(log_format)
    console_handler.setFormatter(colored_formatter)
    
    logger.addHandler(console_handler)
    
    # Handler para arquivo (opcional)
    try:
        file_handler = logging.FileHandler(f"analisador_credito_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
        file_handler.setLevel(level)
        file_formatter = logging.Formatter(log_format)
        file_handler.setFormatter(file_formatter)
        logger.addHandler(file_handler)
    except:
        pass  # Ignora se não puder criar arquivo de log
    
    return logger

# Inicializar logger
logger = setup_logging()

class ResourceMonitor:
    """Monitora recursos do sistema e do Spark durante a execução"""
    
    def __init__(self, spark=None):
        self.spark = spark
        self.start_time = time.time()
        self.last_check = self.start_time
        self.check_interval = 30  # segundos entre verificações
        
    def set_spark(self, spark):
        """Define a sessão Spark para monitoramento"""
        self.spark = spark
        
    def check_resources(self, force=False):
        """Verifica recursos do sistema e Spark"""
        current_time = time.time()
        if not force and (current_time - self.last_check) < self.check_interval:
            return
            
        self.last_check = current_time
        elapsed = current_time - self.start_time
        
        # Informações básicas de recursos
        memory_info = {}
        try:
            import psutil
            process = psutil.Process()
            memory_info = {
                "memory_percent": process.memory_percent(),
                "memory_mb": process.memory_info().rss / (1024 * 1024)
            }
        except:
            memory_info = {"status": "psutil não disponível"}
            
        # Informações do Spark - versão compatível com diferentes versões do Spark
        spark_metrics = {}
        if self.spark:
            try:
                # Obter métricas básicas do Spark que funcionam em todas as versões
                spark_metrics = {
                    "app_id": self.spark.sparkContext.applicationId,
                    "default_parallelism": self.spark.sparkContext.defaultParallelism,
                    "version": self.spark.version
                }
                
                # Tentar obter informações sobre executores de forma segura
                try:
                    # Método alternativo para obter número de executores
                    executor_metrics = self.spark.sql("SELECT count(*) as executor_count FROM sys.executors").collect()
                    if executor_metrics:
                        spark_metrics["active_executors"] = executor_metrics[0]["executor_count"]
                except:
                    # Se falhar, não interrompe a execução
                    pass
                
                # Tentar obter métricas de memória via SQL
                try:
                    memory_metrics = self.spark.sql("SELECT * FROM sys.runtime").collect()
                    if memory_metrics:
                        for row in memory_metrics:
                            row_dict = row.asDict()
                            if "jvm.heap.used" in row_dict:
                                spark_metrics["jvm_heap_used_mb"] = row_dict["jvm.heap.used"] / (1024 * 1024)
                except:
                    # Se falhar, não interrompe a execução
                    pass
            except:
                spark_metrics = {"status": "Erro ao obter métricas do Spark"}
        
        # Log das informações de recursos
        logger.info(f"📊 MONITOR DE RECURSOS [Tempo decorrido: {elapsed:.1f}s]")
        logger.info(f"🖥️ Processo Python: {json.dumps(memory_info)}")
        logger.info(f"⚡ Métricas Spark: {json.dumps(spark_metrics)}")
        
        return {
            "elapsed_time": elapsed,
            "memory_info": memory_info,
            "spark_metrics": spark_metrics
        }

# Inicializar monitor de recursos
resource_monitor = ResourceMonitor()

class SparkSessionManager:
    """Gerencia a sessão Spark de forma robusta com mecanismos de retry e monitoramento"""
    
    _instance = None
    _init_attempts = 0
    _max_init_attempts = 3
    
    @classmethod
    def get_or_create(cls):
        """Obtém uma sessão Spark existente ou cria uma nova com configurações otimizadas"""
        if cls._instance is None:
            logger.info("🔄 Inicializando nova SparkSession (tentativa %d de %d)", 
                       cls._init_attempts + 1, cls._max_init_attempts)
            try:
                # Configurações otimizadas para o SparkSession
                spark = (SparkSession.builder
                    .appName("AnalisadorCredito")
                    .config("spark.sql.execution.arrow.pyspark.enabled", "true")
                    .config("spark.sql.execution.arrow.maxRecordsPerBatch", "10000")
                    .config("spark.databricks.io.cache.enabled", "true")
                    .config("spark.databricks.delta.preview.enabled", "true")
                    # Configurações adicionais para melhorar estabilidade
                    .config("spark.network.timeout", "800s")
                    .config("spark.executor.heartbeatInterval", "120s")
                    .config("spark.sql.broadcastTimeout", "600s")
                    .config("spark.sql.autoBroadcastJoinThreshold", "64MB")
                    # Configurações de memória
                    .config("spark.memory.fraction", "0.8")
                    .config("spark.memory.storageFraction", "0.3")
                    .config("spark.sql.shuffle.partitions", "200")
                    # Configurações para lidar com erros de conexão
                    .config("spark.task.maxFailures", "4")
                    .getOrCreate())
                
                # Definir configurações de log do Spark para reduzir ruído
                spark.sparkContext.setLogLevel("WARN")
                
                # Registrar informações sobre o cluster de forma segura
                logger.info("✅ SparkSession inicializada com sucesso")
                logger.info(f"📋 Versão do Spark: {spark.version}")
                logger.info(f"🔢 Paralelismo padrão: {spark.sparkContext.defaultParallelism}")
                
                # Tentar obter número de executores de forma segura (compatível com diferentes versões)
                try:
                    executor_count = spark.sql("SELECT count(*) as count FROM sys.executors").collect()[0]["count"]
                    logger.info(f"🖥️ Número de executores: {executor_count}")
                except:
                    logger.info("🖥️ Informação sobre executores não disponível")
                
                # Configurar o monitor de recursos
                resource_monitor.set_spark(spark)
                resource_monitor.check_resources(force=True)
                
                cls._instance = spark
                cls._init_attempts = 0
            except Exception as e:
                cls._init_attempts += 1
                logger.error(f"❌ Erro ao inicializar SparkSession: {str(e)}")
                
                if cls._init_attempts >= cls._max_init_attempts:
                    logger.critical("🛑 Número máximo de tentativas de inicialização excedido!")
                    raise
                
                # Espera exponencial antes de tentar novamente
                wait_time = 2 ** cls._init_attempts
                logger.warning(f"⏱️ Aguardando {wait_time}s antes de tentar novamente...")
                time.sleep(wait_time)
                return cls.get_or_create()
                
        return cls._instance
    
    @classmethod
    def reset(cls):
        """Reinicia a sessão Spark em caso de problemas"""
        if cls._instance:
            try:
                logger.info("🔄 Reiniciando SparkSession")
                cls._instance.stop()
            except:
                logger.warning("⚠️ Erro ao parar SparkSession existente, continuando com reset")
            cls._instance = None
        return cls.get_or_create()

    @classmethod
    def execute_with_retry(cls, func, *args, max_retries=3, **kwargs):
        """Executa uma função com retry automático em caso de erros de conexão"""
        for attempt in range(max_retries):
            try:
                return func(*args, **kwargs)
            except (py4j.protocol.Py4JNetworkError, socket.error) as e:
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt
                    logger.warning(f"⚠️ Erro de conexão na tentativa {attempt+1}/{max_retries}: {str(e)}")
                    logger.warning(f"⏱️ Aguardando {wait_time}s antes de tentar novamente...")
                    time.sleep(wait_time)
                    cls.reset()
                else:
                    logger.error(f"❌ Falha após {max_retries} tentativas: {str(e)}")
                    raise
            except Exception as e:
                logger.error(f"❌ Erro não relacionado à conexão: {str(e)}")
                raise

class GeradorGraficos:
    """
    Classe responsável por gerar gráficos informativos sobre os dados de crédito
    para inclusão em relatórios ou documentos PDF.
    """
    
    def __init__(self, output_dir=None):
        """
        Inicializa o gerador de gráficos.
        
        Args:
            output_dir: Diretório para salvar os gráficos. Se None, usa um diretório temporário.
        """
        # Configurar diretório de saída
        if output_dir is None:
            self.output_dir = Path(f"/tmp/credito_graficos_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
        else:
            self.output_dir = Path(output_dir)
            
        # Criar diretório se não existir
        os.makedirs(self.output_dir, exist_ok=True)
        
        # Configurar estilo dos gráficos
        plt.style.use('ggplot')
        sns.set_palette("deep")
        
        # Configurar fontes e tamanhos
        plt.rcParams['font.family'] = 'sans-serif'
        plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans', 'Liberation Sans']
        plt.rcParams['font.size'] = 12
        plt.rcParams['axes.titlesize'] = 14
        plt.rcParams['axes.labelsize'] = 12
        plt.rcParams['xtick.labelsize'] = 10
        plt.rcParams['ytick.labelsize'] = 10
        
        # Lista para armazenar informações sobre os gráficos gerados
        self.graficos_gerados = []
        
        logger.info(f"🎨 Gerador de gráficos inicializado. Diretório de saída: {self.output_dir}")
    
    def gerar_graficos_credito(self, dados_estruturados):
        """
        Gera todos os gráficos relevantes para a análise de crédito.
        
        Args:
            dados_estruturados: Dicionário com os dados estruturados da análise de crédito
            
        Returns:
            Dict: Dicionário com informações sobre os gráficos gerados
        """
        logger.info("🎨 Iniciando geração de gráficos para análise de crédito")
        
        # Limpar lista de gráficos anteriores
        self.graficos_gerados = []
        
        try:
            # 1. Gráfico de evolução da carteira (linha)
            self.gerar_grafico_evolucao_carteira(dados_estruturados)
            
            # 2. Gráfico de composição da carteira por tipo de produto (pizza)
            self.gerar_grafico_composicao_carteira(dados_estruturados)
            
            # 3. Gráfico de distribuição por vencimento (barras)
            self.gerar_grafico_distribuicao_vencimento(dados_estruturados)
            
            # 4. Gráfico de evolução dos estágios IFRS 9 (área empilhada)
            self.gerar_grafico_evolucao_estagios(dados_estruturados)
            
            # 5. Gráfico de sazonalidade de pagamentos (barras)
            self.gerar_grafico_sazonalidade_pagamentos(dados_estruturados)
            
            # 6. Gráfico de histórico de inadimplência (linha)
            self.gerar_grafico_historico_inadimplencia(dados_estruturados)
            
            # 7. Gráfico de indicadores de alerta (radar)
            self.gerar_grafico_indicadores_alerta(dados_estruturados)
            
            # 8. Gráfico de comparação com cônjuge (barras), se disponível
            if "analises_relacionadas" in dados_estruturados and "conjuge" in dados_estruturados["analises_relacionadas"]:
                conjuge = dados_estruturados["analises_relacionadas"]["conjuge"]
                if conjuge["status"] == "success" and "dados" in conjuge:
                    self.gerar_grafico_comparacao_conjuge(dados_estruturados, conjuge["dados"])
            
            # 9. Gráfico de grupo econômico (barras horizontais), se disponível
            if "analises_relacionadas" in dados_estruturados and "grupo_economico" in dados_estruturados["analises_relacionadas"]:
                grupo = dados_estruturados["analises_relacionadas"]["grupo_economico"]
                if grupo["status"] == "success" and "dados" in grupo:
                    self.gerar_grafico_grupo_economico(dados_estruturados, grupo["dados"])
            
            logger.info(f"✅ Geração de gráficos concluída. Total: {len(self.graficos_gerados)} gráficos")
            
            return {
                "status": "success",
                "graficos": self.graficos_gerados,
                "diretorio": str(self.output_dir)
            }
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar gráficos: {str(e)}")
            return {
                "status": "error",
                "message": f"Erro ao gerar gráficos: {str(e)}",
                "graficos": self.graficos_gerados,
                "diretorio": str(self.output_dir)
            }
    
    def gerar_grafico_evolucao_carteira(self, dados_estruturados):
        """
        Gera um gráfico de linha mostrando a evolução da carteira ao longo do tempo.
        """
        logger.info("🎨 Gerando gráfico de evolução da carteira")
        
        try:
            # Extrair dados
            evolucao = dados_estruturados["evolucao_carteira"]
            
            if not evolucao:
                logger.warning("⚠️ Sem dados para gerar gráfico de evolução da carteira")
                return
            
            # Preparar dados para o gráfico
            datas = []
            saldos = []
            provisoes = []
            
            # Ordenar por data crescente
            evolucao_ordenada = sorted(evolucao, key=lambda x: x["ano_mes"])
            
            for item in evolucao_ordenada:
                # Converter ano_mes para formato legível
                ano_mes = str(item["ano_mes"])
                mes = ano_mes[-2:]
                ano = ano_mes[:-2]
                data_formatada = f"{mes}/{ano}"
                
                datas.append(data_formatada)
                saldos.append(item["saldo_total"])
                provisoes.append(item["provisao_total"])
            
            # Criar figura
            plt.figure(figsize=(12, 6))
            
            # Plotar linhas
            plt.plot(datas, saldos, marker='o', linewidth=2, label='Saldo Total')
            plt.plot(datas, provisoes, marker='s', linewidth=2, label='Provisão Total')
            
            # Adicionar rótulos e título
            plt.title("Evolução da Carteira de Crédito", fontweight='bold')
            plt.xlabel("Mês/Ano")
            plt.ylabel("Valor (R$)")
            
            # Formatar eixo Y para moeda
            plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: f"R$ {x:,.0f}"))
            
            # Rotacionar rótulos do eixo X para melhor legibilidade
            plt.xticks(rotation=45)
            
            # Adicionar legenda
            plt.legend()
            
            # Adicionar grade
            plt.grid(True, linestyle='--', alpha=0.7)
            
            # Calcular variação percentual do primeiro ao último mês
            if len(saldos) > 1 and saldos[0] > 0:
                variacao_percentual = (saldos[-1] - saldos[0]) / saldos[0] * 100
                plt.annotate(
                    f"Variação: {variacao_percentual:.2f}%",
                    xy=(len(datas) - 1, saldos[-1]),
                    xytext=(len(datas) - 3, saldos[-1] * 1.1),
                    arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=.2")
                )
            
            # Ajustar layout
            plt.tight_layout()
            
            # Salvar gráfico
            nome_arquivo = "evolucao_carteira.png"
            caminho_completo = self.output_dir / nome_arquivo
            plt.savefig(caminho_completo, dpi=300, bbox_inches='tight')
            plt.close()
            
            # Adicionar à lista de gráficos gerados
            self.graficos_gerados.append({
                "tipo": "evolucao_carteira",
                "titulo": "Evolução da Carteira de Crédito",
                "descricao": f"Evolução do saldo total e provisões ao longo do tempo.",
                "arquivo": nome_arquivo,
                "caminho": str(caminho_completo)
            })
            
            logger.info(f"✅ Gráfico de evolução da carteira gerado: {caminho_completo}")
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar gráfico de evolução da carteira: {str(e)}")
    
    def gerar_grafico_composicao_carteira(self, dados_estruturados):
        """
        Gera um gráfico de pizza mostrando a composição da carteira por tipo de produto.
        """
        logger.info("🎨 Gerando gráfico de composição da carteira")
        
        try:
            # Extrair dados
            distribuicao = dados_estruturados["distribuicao_tipo_produto"]
            
            if not distribuicao:
                logger.warning("⚠️ Sem dados para gerar gráfico de composição da carteira")
                return
            
            # Preparar dados para o gráfico
            tipos = []
            valores = []
            percentuais = []
            
            for item in distribuicao:
                tipos.append(item["tipo_produto"])
                valores.append(item["saldo_atual"])
                percentuais.append(item["percentual"])
            
            # Criar figura
            plt.figure(figsize=(10, 7))
            
            # Gerar gráfico de pizza
            wedges, texts, autotexts = plt.pie(
                valores, 
                autopct='%1.1f%%',
                startangle=90,
                shadow=False,
                explode=[0.05 if p > 30 else 0 for p in percentuais],  # Destacar categorias principais
                wedgeprops={'edgecolor': 'white', 'linewidth': 1.5}
            )
            
            # Melhorar a aparência dos textos
            for autotext in autotexts:
                autotext.set_color('white')
                autotext.set_fontsize(10)
                autotext.set_weight('bold')
            
            # Adicionar legenda
            plt.legend(
                wedges, 
                tipos,
                title="Tipos de Produto",
                loc="center left",
                bbox_to_anchor=(1, 0, 0.5, 1)
            )
            
            # Adicionar título
            plt.title("Composição da Carteira por Tipo de Produto", fontweight='bold', pad=20)
            
            # Ajustar layout
            plt.tight_layout()
            
            # Salvar gráfico
            nome_arquivo = "composicao_carteira.png"
            caminho_completo = self.output_dir / nome_arquivo
            plt.savefig(caminho_completo, dpi=300, bbox_inches='tight')
            plt.close()
            
            # Adicionar à lista de gráficos gerados
            self.graficos_gerados.append({
                "tipo": "composicao_carteira",
                "titulo": "Composição da Carteira por Tipo de Produto",
                "descricao": f"Distribuição dos tipos de produto na carteira ativa total de R$ {sum(valores):,.2f}.",
                "arquivo": nome_arquivo,
                "caminho": str(caminho_completo)
            })
            
            logger.info(f"✅ Gráfico de composição da carteira gerado: {caminho_completo}")
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar gráfico de composição da carteira: {str(e)}")
    
    def gerar_grafico_distribuicao_vencimento(self, dados_estruturados):
        """
        Gera um gráfico de barras mostrando a distribuição por vencimento.
        """
        logger.info("🎨 Gerando gráfico de distribuição por vencimento")
        
        try:
            # Extrair dados
            distribuicao = dados_estruturados["distribuicao_vencimento"]
            
            if not distribuicao:
                logger.warning("⚠️ Sem dados para gerar gráfico de distribuição por vencimento")
                return
            
            # Preparar dados para o gráfico
            categorias = ['Curto Prazo\n(até 90 dias)', 'Médio Prazo\n(91 a 360 dias)', 'Longo Prazo\n(acima de 361 dias)']
            valores = [
                distribuicao["ate_90_dias"],
                distribuicao["de_91_a_360_dias"],
                distribuicao["acima_361_dias"]
            ]
            percentuais = [
                distribuicao["percentual_curto_prazo"],
                distribuicao["percentual_medio_prazo"],
                distribuicao["percentual_longo_prazo"]
            ]
            
            # Criar figura
            plt.figure(figsize=(10, 6))
            
            # Criar barras
            bars = plt.bar(categorias, valores, color=plt.cm.viridis(np.linspace(0.2, 0.8, len(categorias))))
            
            # Adicionar rótulos de percentual nas barras
            for i, bar in enumerate(bars):
                height = bar.get_height()
                plt.text(bar.get_x() + bar.get_width()/2., height,
                        f'{percentuais[i]:.1f}%',
                        ha='center', va='bottom', rotation=0)
            
            # Adicionar rótulos e título
            plt.title("Distribuição por Prazo de Vencimento", fontweight='bold')
            plt.ylabel("Valor (R$)")
            
            # Formatar eixo Y para moeda
            plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: f"R$ {x:,.0f}"))
            
            # Adicionar grade
            plt.grid(True, linestyle='--', alpha=0.7, axis='y')
            
            # Ajustar layout
            plt.tight_layout()
            
            # Salvar gráfico
            nome_arquivo = "distribuicao_vencimento.png"
            caminho_completo = self.output_dir / nome_arquivo
            plt.savefig(caminho_completo, dpi=300, bbox_inches='tight')
            plt.close()
            
            # Adicionar à lista de gráficos gerados
            self.graficos_gerados.append({
                "tipo": "distribuicao_vencimento",
                "titulo": "Distribuição por Prazo de Vencimento",
                "descricao": f"Distribuição dos valores da carteira por prazo de vencimento.",
                "arquivo": nome_arquivo,
                "caminho": str(caminho_completo)
            })
            
            logger.info(f"✅ Gráfico de distribuição por vencimento gerado: {caminho_completo}")
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar gráfico de distribuição por vencimento: {str(e)}")
    
    def gerar_grafico_evolucao_estagios(self, dados_estruturados):
        """
        Gera um gráfico de área empilhada mostrando a evolução dos estágios IFRS 9.
        """
        logger.info("🎨 Gerando gráfico de evolução dos estágios IFRS 9")
        
        try:
            # Extrair dados
            evolucao = dados_estruturados["evolucao_estagios"]
            
            if not evolucao:
                logger.warning("⚠️ Sem dados para gerar gráfico de evolução dos estágios")
                return
            
            # Preparar dados para o gráfico
            datas = []
            estagio1 = []
            estagio2 = []
            estagio3 = []
            
            # Ordenar por data crescente
            evolucao_ordenada = sorted(evolucao, key=lambda x: x["ano_mes"])
            
            for item in evolucao_ordenada:
                # Converter ano_mes para formato legível
                ano_mes = str(item["ano_mes"])
                mes = ano_mes[-2:]
                ano = ano_mes[:-2]
                data_formatada = f"{mes}/{ano}"
                
                datas.append(data_formatada)
                estagio1.append(item["saldo_estagio1"])
                estagio2.append(item["saldo_estagio2"])
                estagio3.append(item["saldo_estagio3"])
            
            # Criar figura
            plt.figure(figsize=(12, 6))
            
            # Criar gráfico de área empilhada
            plt.stackplot(datas, 
                         estagio1, estagio2, estagio3,
                         labels=['Estágio 1', 'Estágio 2', 'Estágio 3'],
                         alpha=0.8,
                         colors=['#4CAF50', '#FFC107', '#F44336'])
            
            # Adicionar rótulos e título
            plt.title("Evolução dos Estágios IFRS 9", fontweight='bold')
            plt.xlabel("Mês/Ano")
            plt.ylabel("Saldo (R$)")
            
            # Formatar eixo Y para moeda
            plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: f"R$ {x:,.0f}"))
            
            # Rotacionar rótulos do eixo X para melhor legibilidade
            plt.xticks(rotation=45)
            
            # Adicionar legenda
            plt.legend(loc='upper left')
            
            # Adicionar grade
            plt.grid(True, linestyle='--', alpha=0.7)
            
            # Ajustar layout
            plt.tight_layout()
            
            # Salvar gráfico
            nome_arquivo = "evolucao_estagios.png"
            caminho_completo = self.output_dir / nome_arquivo
            plt.savefig(caminho_completo, dpi=300, bbox_inches='tight')
            plt.close()
            
            # Adicionar à lista de gráficos gerados
            self.graficos_gerados.append({
                "tipo": "evolucao_estagios",
                "titulo": "Evolução dos Estágios IFRS 9",
                "descricao": "Evolução dos saldos por estágio IFRS 9 ao longo do tempo.",
                "arquivo": nome_arquivo,
                "caminho": str(caminho_completo)
            })
            
            logger.info(f"✅ Gráfico de evolução dos estágios gerado: {caminho_completo}")
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar gráfico de evolução dos estágios: {str(e)}")
    
    def gerar_grafico_sazonalidade_pagamentos(self, dados_estruturados):
        """
        Gera um gráfico de barras mostrando a sazonalidade de pagamentos.
        """
        logger.info("🎨 Gerando gráfico de sazonalidade de pagamentos")
        
        try:
            # Extrair dados
            sazonalidade = dados_estruturados["sazonalidade_pagamentos"]
            
            if not sazonalidade:
                logger.warning("⚠️ Sem dados para gerar gráfico de sazonalidade de pagamentos")
                return
            
            # Preparar dados para o gráfico
            meses = []
            pagamentos = []
            debitos = []
            amortizacao = []
            
            # Mapear números de meses para nomes
            nomes_meses = {
                '01': 'Jan', '02': 'Fev', '03': 'Mar', '04': 'Abr',
                '05': 'Mai', '06': 'Jun', '07': 'Jul', '08': 'Ago',
                '09': 'Set', '10': 'Out', '11': 'Nov', '12': 'Dez'
            }
            
            # Ordenar por mês
            sazonalidade_ordenada = sorted(sazonalidade, key=lambda x: int(x["mes"]))
            
            for item in sazonalidade_ordenada:
                mes_num = item["mes"]
                mes_nome = nomes_meses.get(mes_num, mes_num)
                
                meses.append(mes_nome)
                pagamentos.append(item["media_pagamentos_mensal"])
                debitos.append(item["media_novos_debitos_mensal"])
                amortizacao.append(item["media_amortizacao_liquida"])
            
            # Criar figura
            plt.figure(figsize=(12, 6))
            
            # Criar barras para pagamentos e débitos
            width = 0.35
            x = np.arange(len(meses))
            
            bar1 = plt.bar(x - width/2, pagamentos, width, label='Pagamentos', color='#4CAF50')
            bar2 = plt.bar(x + width/2, debitos, width, label='Novos Débitos', color='#F44336')
            
            # Adicionar linha para amortização líquida
            plt.plot(x, amortizacao, marker='o', linestyle='-', color='#2196F3', linewidth=2, label='Amortização Líquida')
            
            # Adicionar rótulos e título
            plt.title("Sazonalidade de Pagamentos", fontweight='bold')
            plt.xlabel("Mês")
            plt.ylabel("Valor (R$)")
            plt.xticks(x, meses)
            
            # Formatar eixo Y para moeda
            plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: f"R$ {x:,.0f}"))
            
            # Adicionar legenda
            plt.legend()
            
            # Adicionar grade
            plt.grid(True, linestyle='--', alpha=0.7, axis='y')
            
            # Ajustar layout
            plt.tight_layout()
            
            # Salvar gráfico
            nome_arquivo = "sazonalidade_pagamentos.png"
            caminho_completo = self.output_dir / nome_arquivo
            plt.savefig(caminho_completo, dpi=300, bbox_inches='tight')
            plt.close()
            
            # Adicionar à lista de gráficos gerados
            self.graficos_gerados.append({
                "tipo": "sazonalidade_pagamentos",
                "titulo": "Sazonalidade de Pagamentos",
                "descricao": "Padrão sazonal de pagamentos, novos débitos e amortização líquida ao longo do ano.",
                "arquivo": nome_arquivo,
                "caminho": str(caminho_completo)
            })
            
            logger.info(f"✅ Gráfico de sazonalidade de pagamentos gerado: {caminho_completo}")
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar gráfico de sazonalidade de pagamentos: {str(e)}")
    
    def gerar_grafico_historico_inadimplencia(self, dados_estruturados):
        """
        Gera um gráfico de linha mostrando o histórico de inadimplência.
        """
        logger.info("🎨 Gerando gráfico de histórico de inadimplência")
        
        try:
            # Extrair dados
            historico = dados_estruturados["historico_inadimplencia"]
            
            if not historico:
                logger.warning("⚠️ Sem dados para gerar gráfico de histórico de inadimplência")
                return
            
            # Preparar dados para o gráfico
            datas = []
            percentual_em_dia = []
            saldo_em_atraso = []
            
            # Ordenar por data crescente
            historico_ordenado = sorted(historico, key=lambda x: x["ano_mes"])
            
            for item in historico_ordenado:
                # Converter ano_mes para formato legível
                ano_mes = str(item["ano_mes"])
                mes = ano_mes[-2:]
                ano = ano_mes[:-2]
                data_formatada = f"{mes}/{ano}"
                
                datas.append(data_formatada)
                percentual_em_dia.append(item["percentual_operacoes_em_dia"])
                saldo_em_atraso.append(item["saldo_em_atraso"])
            
            # Criar figura com dois eixos Y
            fig, ax1 = plt.subplots(figsize=(12, 6))
            
            # Eixo Y esquerdo: Percentual de operações em dia
            color = 'tab:blue'
            ax1.set_xlabel('Mês/Ano')
            ax1.set_ylabel('% Operações em Dia', color=color)
            ax1.plot(datas, percentual_em_dia, marker='o', color=color, linewidth=2)
            ax1.tick_params(axis='y', labelcolor=color)
            ax1.set_ylim([0, 105])  # Limite para percentual
            
            # Eixo Y direito: Saldo em atraso
            ax2 = ax1.twinx()
            color = 'tab:red'
            ax2.set_ylabel('Saldo em Atraso (R$)', color=color)
            ax2.plot(datas, saldo_em_atraso, marker='s', color=color, linewidth=2, linestyle='--')
            ax2.tick_params(axis='y', labelcolor=color)
            
            # Formatar eixo Y direito para moeda
            ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: f"R$ {x:,.0f}"))
            
            # Rotacionar rótulos do eixo X para melhor legibilidade
            plt.xticks(rotation=45)
            
            # Adicionar título
            plt.title("Histórico de Inadimplência", fontweight='bold')
            
            # Adicionar grade
            ax1.grid(True, linestyle='--', alpha=0.7)
            
            # Adicionar legenda
            lines1, labels1 = ax1.get_legend_handles_labels()
            lines2, labels2 = ax2.get_legend_handles_labels()
            ax1.legend(lines1 + lines2, ['% Operações em Dia', 'Saldo em Atraso'], loc='upper right')
            
            # Ajustar layout
            plt.tight_layout()
            
            # Salvar gráfico
            nome_arquivo = "historico_inadimplencia.png"
            caminho_completo = self.output_dir / nome_arquivo
            plt.savefig(caminho_completo, dpi=300, bbox_inches='tight')
            plt.close()
            
            # Adicionar à lista de gráficos gerados
            self.graficos_gerados.append({
                "tipo": "historico_inadimplencia",
                "titulo": "Histórico de Inadimplência",
                "descricao": "Evolução do percentual de operações em dia e saldo em atraso ao longo do tempo.",
                "arquivo": nome_arquivo,
                "caminho": str(caminho_completo)
            })
            
            logger.info(f"✅ Gráfico de histórico de inadimplência gerado: {caminho_completo}")
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar gráfico de histórico de inadimplência: {str(e)}")
    
    def gerar_grafico_indicadores_alerta(self, dados_estruturados):
        """
        Gera um gráfico de radar mostrando os principais indicadores de alerta.
        """
        logger.info("🎨 Gerando gráfico de indicadores de alerta")
        
        try:
            # Extrair dados do resumo estatístico
            resumo = dados_estruturados["resumo_estatistico"]
            
            if not resumo:
                logger.warning("⚠️ Sem dados para gerar gráfico de indicadores de alerta")
                return
            
            # Definir categorias e valores para o gráfico de radar
            categorias = [
                "Concentração\nCarteira",
                "Pressão de\nPagamento",
                "Histórico de\nInadimplência",
                "Tendência\nRating",
                "Sazonalidade"
            ]
            
            # Mapear valores textuais para numéricos (escala de 0 a 100)
            # Concentração da carteira
            if "nivel_concentracao" in resumo:
                concentracao_map = {
                    "Muito alta": 100,
                    "Alta": 75,
                    "Moderada": 50,
                    "Baixa": 25
                }
                concentracao = concentracao_map.get(resumo["nivel_concentracao"], 50)
            else:
                concentracao = 50
            
            # Pressão de pagamento
            pressao_map = {
                "Alta": 100,
                "Moderada": 50,
                "Baixa": 25,
                "Não determinada": 50
            }
            pressao = pressao_map.get(resumo.get("pressao_pagamento_curto_prazo", "Não determinada"), 50)
            
            # Histórico de inadimplência
            inadimplencia_map = {
                "Com ocorrências recentes": 100,
                "Sem ocorrências recentes": 25
            }
            inadimplencia = inadimplencia_map.get(resumo.get("historico_inadimplencia", "Não determinado"), 50)
            
            # Tendência de rating
            tendencia_map = {
                "Piora significativa": 100,
                "Piora moderada": 75,
                "Estável": 50,
                "Melhora leve": 35,
                "Melhora moderada": 25,
                "Melhora significativa": 10
            }
            tendencia = tendencia_map.get(resumo.get("tendencia_rating", "Estável"), 50)
            
            # Sazonalidade
            sazonalidade_map = {
                "Alta": 100,
                "Moderada": 50,
                "Baixa": 25,
                "Não identificada": 0
            }
            sazonalidade = sazonalidade_map.get(resumo.get("nivel_sazonalidade", "Não identificada"), 50)
            
            # Valores para o gráfico (normalizar para escala 0-100)
            valores = [concentracao, pressao, inadimplencia, tendencia, sazonalidade]
            
            # Criar figura
            plt.figure(figsize=(8, 8))
            
            # Criar gráfico de radar
            # Número de variáveis
            N = len(categorias)
            
            # Ângulos para cada eixo (divididos uniformemente)
            angulos = [n / float(N) * 2 * np.pi for n in range(N)]
            angulos += angulos[:1]  # Fechar o gráfico
            
            # Valores para o gráfico
            valores_radar = valores + [valores[0]]  # Fechar o gráfico
            
            # Criar o plot
            ax = plt.subplot(111, polar=True)
            
            # Desenhar o polígono
            ax.plot(angulos, valores_radar, 'o-', linewidth=2)
            ax.fill(angulos, valores_radar, alpha=0.25)
            
            # Adicionar rótulos
            ax.set_thetagrids(np.degrees(angulos[:-1]), categorias)
            
            # Ajustar os limites do eixo radial
            ax.set_ylim(0, 100)
            
            # Adicionar níveis de risco
            ax.set_rticks([25, 50, 75, 100])
            ax.set_yticklabels(['Baixo', 'Médio', 'Alto', 'Muito Alto'])
            
            # Adicionar título
            plt.title("Indicadores de Alerta", fontweight='bold', size=14, y=1.1)
            
            # Ajustar layout
            plt.tight_layout()
            
            # Salvar gráfico
            nome_arquivo = "indicadores_alerta.png"
            caminho_completo = self.output_dir / nome_arquivo
            plt.savefig(caminho_completo, dpi=300, bbox_inches='tight')
            plt.close()
            
            # Adicionar à lista de gráficos gerados
            self.graficos_gerados.append({
                "tipo": "indicadores_alerta",
                "titulo": "Indicadores de Alerta",
                "descricao": "Gráfico radar mostrando os principais indicadores de alerta. Valores mais próximos da borda externa indicam maior nível de alerta para aquele indicador.",
                "arquivo": nome_arquivo,
                "caminho": str(caminho_completo)
            })
            
            logger.info(f"✅ Gráfico de indicadores de alerta gerado: {caminho_completo}")
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar gráfico de indicadores de alerta: {str(e)}")
    
    def gerar_grafico_comparacao_conjuge(self, dados_associado, dados_conjuge):
        """
        Gera um gráfico de barras comparando o endividamento do associado e cônjuge.
        """
        logger.info("🎨 Gerando gráfico de comparação com cônjuge")
        
        try:
            # Extrair dados do associado e cônjuge
            saldo_total_associado = dados_associado["situacao_atual"]["saldo_total"]
            saldo_total_conjuge = dados_conjuge["situacao_atual"]["saldo_total"]
            
            # Extrair nomes
            nome_associado = dados_associado.get("perfil_associado", {}).get("nome", "Associado Principal")
            nome_conjuge = dados_conjuge.get("perfil_associado", {}).get("nome", "Cônjuge")
            
            # Simplificar nomes para o gráfico (apenas primeiro e último nome)
            nome_associado_curto = nome_associado.split()[0]
            if len(nome_associado.split()) > 1:
                nome_associado_curto += " " + nome_associado.split()[-1]
                
            nome_conjuge_curto = nome_conjuge.split()[0]
            if len(nome_conjuge.split()) > 1:
                nome_conjuge_curto += " " + nome_conjuge.split()[-1]
            
            # Criar figura
            plt.figure(figsize=(10, 6))
            
            # Dados para o gráfico
            categorias = ['Saldo Total', 'Provisão', 'Saldo Vencido']
            
            # Valores do associado
            valores_associado = [
                saldo_total_associado,
                dados_associado["situacao_atual"]["provisao_total"],
                dados_associado["situacao_atual"]["saldo_vencido"]
            ]
            
            # Valores do cônjuge
            valores_conjuge = [
                saldo_total_conjuge,
                dados_conjuge["situacao_atual"]["provisao_total"],
                dados_conjuge["situacao_atual"]["saldo_vencido"]
            ]
            
            # Posições das barras
            x = np.arange(len(categorias))
            width = 0.35
            
            # Criar barras
            plt.bar(x - width/2, valores_associado, width, label=nome_associado_curto)
            plt.bar(x + width/2, valores_conjuge, width, label=nome_conjuge_curto)
            
            # Adicionar rótulos e título
            plt.title("Comparação de Endividamento: Associado vs. Cônjuge", fontweight='bold')
            plt.xlabel("Categoria")
            plt.ylabel("Valor (R$)")
            plt.xticks(x, categorias)
            
            # Formatar eixo Y para moeda
            plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: f"R$ {x:,.0f}"))
            
            # Adicionar valores nas barras
            def add_labels(bars):
                for bar in bars:
                    height = bar.get_height()
                    if height > 0:
                        plt.text(bar.get_x() + bar.get_width()/2., height,
                                f'R$ {height:,.0f}',
                                ha='center', va='bottom', rotation=0, fontsize=8)
            
            # Adicionar legenda
            plt.legend()
            
            # Adicionar grade
            plt.grid(True, linestyle='--', alpha=0.7, axis='y')
            
            # Ajustar layout
            plt.tight_layout()
            
            # Salvar gráfico
            nome_arquivo = "comparacao_conjuge.png"
            caminho_completo = self.output_dir / nome_arquivo
            plt.savefig(caminho_completo, dpi=300, bbox_inches='tight')
            plt.close()
            
            # Adicionar à lista de gráficos gerados
            percentual_conjuge = (saldo_total_conjuge / saldo_total_associado * 100) if saldo_total_associado > 0 else 0
            
            self.graficos_gerados.append({
                "tipo": "comparacao_conjuge",
                "titulo": "Comparação de Endividamento: Associado vs. Cônjuge",
                "descricao": f"Comparação entre o endividamento do associado ({nome_associado_curto}) e seu cônjuge ({nome_conjuge_curto}). O cônjuge representa {percentual_conjuge:.1f}% do endividamento total do associado.",
                "arquivo": nome_arquivo,
                "caminho": str(caminho_completo)
            })
            
            logger.info(f"✅ Gráfico de comparação com cônjuge gerado: {caminho_completo}")
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar gráfico de comparação com cônjuge: {str(e)}")
    
    def gerar_grafico_grupo_economico(self, dados_associado, dados_grupo):
        """
        Gera um gráfico de barras horizontais mostrando a distribuição do endividamento no grupo econômico.
        """
        logger.info("🎨 Gerando gráfico de grupo econômico")
        
        try:
            # Extrair dados do grupo
            membros = dados_grupo.get("membros_info", [])
            
            if not membros:
                logger.warning("⚠️ Sem dados de membros para gerar gráfico de grupo econômico")
                return
            
            # Preparar dados para o gráfico
            nomes = []
            saldos = []
            
            # Extrair CPF/CNPJ do associado principal
            cpf_cnpj_principal = dados_associado["perfil_associado"]["cpf_cnpj"]
            
            # Adicionar associado principal
            nomes.append("Associado Principal")
            saldos.append(dados_associado["situacao_atual"]["saldo_total"])
            
            # Adicionar outros membros do grupo
            for membro in membros:
                if membro["cpf_cnpj"] != cpf_cnpj_principal:
                    nome_curto = membro["nome"].split()[0]
                    if len(membro["nome"].split()) > 1:
                        nome_curto += " " + membro["nome"].split()[-1]
                    
                    nomes.append(nome_curto)
                    # Usar saldo do membro se disponível, ou um valor estimado
                    saldo = membro.get("saldo_total", dados_grupo.get("saldo_medio_membros", 0))
                    saldos.append(saldo)
            
            # Ordenar por saldo (decrescente)
            indices_ordenados = np.argsort(saldos)[::-1]
            nomes = [nomes[i] for i in indices_ordenados]
            saldos = [saldos[i] for i in indices_ordenados]
            
            # Criar figura
            plt.figure(figsize=(10, 8))
            
            # Criar barras horizontais
            bars = plt.barh(nomes, saldos, color=plt.cm.viridis(np.linspace(0, 0.8, len(nomes))))
            
            # Adicionar rótulos nas barras
            for i, bar in enumerate(bars):
                plt.text(bar.get_width() + 0.3, bar.get_y() + bar.get_height()/2, 
                        f"R$ {saldos[i]:,.0f}", 
                        va='center', fontsize=10)
            
            # Adicionar título e rótulos
            plt.title("Distribuição de Endividamento no Grupo Econômico", fontweight='bold')
            plt.xlabel("Saldo Total (R$)")
            plt.ylabel("Membro do Grupo")
            
            # Formatar eixo X para moeda
            plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: f"R$ {x:,.0f}"))
            
            # Adicionar grade
            plt.grid(True, linestyle='--', alpha=0.7, axis='x')
            
            # Ajustar layout
            plt.tight_layout()
            
            # Salvar gráfico
            nome_arquivo = "grupo_economico.png"
            caminho_completo = self.output_dir / nome_arquivo
            plt.savefig(caminho_completo, dpi=300, bbox_inches='tight')
            plt.close()
            
            # Adicionar à lista de gráficos gerados
            self.graficos_gerados.append({
                "tipo": "grupo_economico",
                "titulo": "Distribuição de Endividamento no Grupo Econômico",
                "descricao": f"Distribuição do endividamento entre os {len(nomes)} membros do grupo econômico.",
                "arquivo": nome_arquivo,
                "caminho": str(caminho_completo)
            })
            
            logger.info(f"✅ Gráfico de grupo econômico gerado: {caminho_completo}")
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar gráfico de grupo econômico: {str(e)}")
    
    def obter_graficos_base64(self):
        """
        Converte todos os gráficos gerados para strings base64 para inclusão em HTML ou JSON.
        
        Returns:
            List: Lista de dicionários com informações dos gráficos e strings base64
        """
        resultado = []
        
        for grafico in self.graficos_gerados:
            try:
                caminho = grafico["caminho"]
                with open(caminho, "rb") as img_file:
                    b64_string = base64.b64encode(img_file.read()).decode('utf-8')
                
                grafico_info = grafico.copy()
                grafico_info["base64"] = b64_string
                resultado.append(grafico_info)
                
            except Exception as e:
                logger.error(f"❌ Erro ao converter gráfico para base64: {str(e)}")
        
        return resultado

class AnalisadorCredito:
    """
    Classe principal para análise do histórico de crédito de associados.
    Implementa funcionalidades avançadas para análise detalhada do comportamento de crédito.
    """
    
    def __init__(self):
        """Inicializa o analisador com configurações padrão."""
        logger.info("🚀 Inicializando AnalisadorCredito")
        self.timeout_analise_secundaria = 120  # timeout em segundos para análises secundárias
        self.max_retries = 4  # número máximo de tentativas para chamadas ao modelo
        self.cache_credito = {}  # cache para evitar consultas repetidas
        self.spark = None  # será inicializado sob demanda
        self.gerador_graficos = GeradorGraficos()  # inicializar gerador de gráficos
        
        # Configuração do cliente OpenAI
        try:
            self.openai_client = OpenAI(
                api_key='dapie6330b0d1f7ccef0e70f3bdd28b1e2a2',
                base_url="https://sicredi-coop-0914.cloud.databricks.com/serving-endpoints",
                timeout=180.0
            )
            logger.info("✅ Cliente OpenAI configurado com sucesso")
        except Exception as e:
            logger.error(f"❌ Erro ao configurar cliente OpenAI: {str(e)}")
            raise
    
    def _get_spark(self):
        """Obtém uma sessão Spark válida, com tratamento de reconexão"""
        if self.spark is None:
            logger.info("🔄 Obtendo sessão Spark")
            self.spark = SparkSessionManager.get_or_create()
            logger.info("✅ Sessão Spark obtida com sucesso")
        return self.spark
    
    def safe_int(self, value):
        """Converte valor para inteiro de forma segura, tratando NaN e None"""
        if pd.isna(value) or value is None:
            return 0
        try:
            return int(value)
        except:
            return 0
            
    def safe_float(self, value):
        """Converte valor para float de forma segura, tratando NaN e None"""
        if pd.isna(value) or value is None:
            return 0.0
        try:
            return float(value)
        except:
            return 0.0
    
    def analisar_historico_credito_associado(self, cpf_cnpj: str) -> Dict[str, Any]:
        """
        Realiza uma análise completa do histórico de crédito de um associado, incluindo gráficos.
        
        Args:
            cpf_cnpj: CPF ou CNPJ do associado a ser analisado (com ou sem formatação)
        
        Returns:
            Dict: Dicionário com status, análise, dados e gráficos
        """
        start_time = time.time()
        logger.info(f"🔍 Iniciando análise do histórico de crédito para CPF/CNPJ: {cpf_cnpj}")
        
        try:
            # Limpar o CPF/CNPJ (remover caracteres não numéricos)
            cpf_cnpj_limpo = re.sub(r'[^0-9]', '', cpf_cnpj)
            
            # Validar o CPF/CNPJ
            if not cpf_cnpj_limpo:
                logger.warning(f"⚠️ CPF/CNPJ inválido: {cpf_cnpj}")
                return {
                    "status": "error",
                    "message": f"CPF/CNPJ inválido: {cpf_cnpj}"
                }
            
            if len(cpf_cnpj_limpo) != 11 and len(cpf_cnpj_limpo) != 14:
                logger.warning(f"⚠️ CPF/CNPJ com formato inválido: {cpf_cnpj}")
                return {
                    "status": "error",
                    "message": f"CPF/CNPJ com formato inválido: {cpf_cnpj}. Deve ter 11 dígitos (CPF) ou 14 dígitos (CNPJ)."
                }
            
            # Verificar cache
            cache_key = f"credito_{cpf_cnpj_limpo}"
            if cache_key in self.cache_credito:
                logger.info(f"🔄 Usando dados em cache para {cpf_cnpj_limpo}")
                cached_result = self.cache_credito[cache_key]
                elapsed = time.time() - start_time
                logger.info(f"✅ Análise concluída em {elapsed:.2f}s (usando cache)")
                return cached_result
            
            # Obter informações complementares do associado da tabela perfil_associado
            logger.info(f"📋 Obtendo informações complementares do associado {cpf_cnpj_limpo}")
            info_associado = self.obter_info_associado(cpf_cnpj_limpo)
            
            if info_associado:
                logger.info(f"👤 Associado identificado: {info_associado.get('nome_associado', 'Nome não disponível')}")
                logger.info(f"📊 Tipo de pessoa: {info_associado.get('tipo_pessoa', 'Não informado')}")
            else:
                logger.warning(f"⚠️ Informações complementares não encontradas para {cpf_cnpj_limpo}")
            
            # Determinar se é PF ou PJ
            tipo_pessoa = info_associado.get("tipo_pessoa", "").upper() if info_associado else ""
            is_pf = "FISICA" in tipo_pessoa or "FÍSICA" in tipo_pessoa
            is_pj = "JURIDICA" in tipo_pessoa or "JURÍDICA" in tipo_pessoa
            
            logger.info(f"👤 Tipo identificado: {'Pessoa Física' if is_pf else 'Pessoa Jurídica' if is_pj else 'Não determinado'}")
            
            # Iniciar análises paralelas para cônjuge e grupo econômico
            analises_relacionadas = {}
            futures = {}
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
                # Verificar se o associado pertence a um grupo econômico
                logger.info(f"🔍 Verificando grupo econômico para {cpf_cnpj_limpo}")
                grupo_economico = self.verificar_grupo_economico(cpf_cnpj_limpo)
                
                # Se pertence a um grupo econômico, iniciar análise do grupo
                if grupo_economico:
                    logger.info(f"🏢 Iniciando análise do grupo econômico: {grupo_economico}")
                    futures["grupo_economico"] = executor.submit(
                        self.analisar_grupo_economico, 
                        grupo_economico, 
                        cpf_cnpj_limpo
                    )
                else:
                    logger.info("ℹ️ Associado não pertence a nenhum grupo econômico identificado")
                
                # Se for pessoa física e tiver cônjuge, iniciar análise do cônjuge
                if is_pf and info_associado and info_associado.get("cpf_conjuge"):
                    cpf_conjuge = re.sub(r'[^0-9]', '', str(info_associado.get("cpf_conjuge", "")))
                    nome_conjuge = info_associado.get("nome_pessoa_conjuge", "Cônjuge")
                    
                    if cpf_conjuge and len(cpf_conjuge) == 11:
                        logger.info(f"👨‍👩‍👧‍👦 Iniciando análise do histórico de crédito do cônjuge: {nome_conjuge} (CPF: {cpf_conjuge})")
                        futures["conjuge"] = executor.submit(
                            self.analisar_credito_conjuge, 
                            cpf_conjuge, 
                            nome_conjuge
                        )
                    else:
                        logger.warning(f"⚠️ CPF do cônjuge inválido ou não informado: {cpf_conjuge}")
                
                # Executar as consultas SQL para o associado principal
                logger.info(f"📊 Executando consultas SQL principais para {cpf_cnpj_limpo}")
                resultados = self.executar_consultas_sql(cpf_cnpj_limpo)
                
                # Verificar resultados das consultas
                if resultados["perfil_associado"].empty:
                    logger.warning(f"⚠️ Consulta de perfil do associado não retornou dados para {cpf_cnpj_limpo}")
                if resultados["situacao_atual"].empty:
                    logger.warning(f"⚠️ Consulta de situação atual não retornou dados para {cpf_cnpj_limpo}")
                
                # Coletar resultados das análises paralelas
                logger.info("⏳ Aguardando conclusão das análises paralelas")
                for key, future in futures.items():
                    try:
                        logger.info(f"🔄 Coletando resultados da análise de {key}")
                        resultado = future.result(timeout=self.timeout_analise_secundaria)
                        analises_relacionadas[key] = resultado
                        logger.info(f"✅ Análise de {key} concluída com sucesso")
                    except concurrent.futures.TimeoutError:
                        logger.warning(f"⏱️ Timeout na análise de {key} após {self.timeout_analise_secundaria}s")
                        analises_relacionadas[key] = {"status": "timeout", "message": f"A análise de {key} excedeu o tempo limite de {self.timeout_analise_secundaria}s"}
                    except Exception as e:
                        logger.error(f"❌ Erro na análise de {key}: {str(e)}")
                        analises_relacionadas[key] = {"status": "error", "message": f"Erro ao analisar {key}: {str(e)}"}
            
            # Verificar se há dados retornados para o associado principal
            if not resultados["perfil_associado"].empty and not resultados["situacao_atual"].empty:
                # Estruturar os dados
                logger.info("🔄 Estruturando dados para análise")
                dados_estruturados = self.estruturar_dados(resultados)
                
                # Adicionar informações complementares do associado
                if info_associado:
                    dados_estruturados["info_associado"] = {
                        "nome": info_associado.get("nome_associado"),
                        "tipo_pessoa": info_associado.get("tipo_pessoa"),
                        "renda_mensal": info_associado.get("renda_mensal")
                    }
                
                # Adicionar análises relacionadas (cônjuge e grupo econômico)
                if analises_relacionadas:
                    dados_estruturados["analises_relacionadas"] = analises_relacionadas
                
                # Verificar monitor de recursos antes de chamar o modelo LLM
                resource_monitor.check_resources(force=True)
                
                # Enviar para o modelo LLM
                logger.info("🧠 Gerando análise com modelo LLM")
                analise = self.gerar_analise_llm(dados_estruturados)
                logger.info("✅ Análise LLM gerada com sucesso")
                
                # Gerar gráficos
                logger.info("📊 Gerando gráficos para a análise")
                resultado_graficos = self.gerador_graficos.gerar_graficos_credito(dados_estruturados)
                
                # Obter gráficos em base64 para inclusão em relatórios
                graficos_base64 = self.gerador_graficos.obter_graficos_base64()
                logger.info(f"✅ {len(graficos_base64)} gráficos gerados com sucesso")
                
                # Criar resultado final
                resultado = {
                    "status": "success",
                    "analise": analise,
                    "dados": dados_estruturados,
                    "graficos": resultado_graficos["graficos"],
                    "graficos_base64": graficos_base64
                }
                
                # Armazenar em cache
                self.cache_credito[cache_key] = resultado
                
                # Calcular tempo total
                elapsed = time.time() - start_time
                logger.info(f"✅ Análise completa do histórico de crédito concluída em {elapsed:.2f}s")
                
                return resultado
            else:
                logger.warning(f"⚠️ Dados insuficientes no histórico de crédito para {cpf_cnpj_limpo}")
                return {
                    "status": "error",
                    "message": f"Não foram encontrados dados de histórico de crédito para o CPF/CNPJ {cpf_cnpj_limpo}"
                }
        
        except Exception as e:
            elapsed = time.time() - start_time
            stack_trace = traceback.format_exc()
            logger.error(f"❌ Erro ao analisar histórico de crédito após {elapsed:.2f}s: {str(e)}")
            logger.error(f"Stack trace: {stack_trace}")
            return {
                "status": "error",
                "message": f"Erro ao analisar histórico de crédito do associado {cpf_cnpj}: {str(e)}",
                "details": stack_trace
            }
    
    def obter_info_associado(self, cpf_cnpj: str) -> Dict[str, Any]:
        """
        Obtém informações complementares do associado da tabela perfil_associado.
        
        Args:
            cpf_cnpj: CPF/CNPJ do associado (apenas números)
            
        Returns:
            Dict: Informações do associado ou None se não encontrado
        """
        try:
            logger.info(f"📋 Consultando informações do associado {cpf_cnpj}")
            spark = self._get_spark()
            
            # Consulta para obter informações básicas do associado
            sql_info = f"""
            SELECT 
                nome_associado,
                tipo_pessoa,
                renda_mensal,
                Codigo_conglomerado_economico,
                nome_grupo_economico,
                cpf_conjuge,
                nome_pessoa_conjuge
            FROM sicredi_coop_0914.bases_bi.perfil_associado
            WHERE num_cpf_cnpj = '{cpf_cnpj}'
            """
            
            # Executar com retry
            resultado = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_info).toPandas()
            )
            
            if resultado.empty:
                logger.warning(f"⚠️ Nenhuma informação encontrada para o associado {cpf_cnpj}")
                return None
            
            # Converter DataFrame para dicionário
            info = resultado.iloc[0].to_dict()
            
            # Tratar valores nulos
            for key, value in info.items():
                if pd.isna(value) or pd.isnull(value):
                    info[key] = None
            
            logger.info(f"✅ Informações do associado {cpf_cnpj} obtidas com sucesso")
            return info
            
        except Exception as e:
            logger.error(f"❌ Erro ao obter informações do associado: {str(e)}")
            return None
    
    def verificar_grupo_economico(self, cpf_cnpj: str) -> Optional[str]:
        """
        Verifica se o CPF/CNPJ pertence a algum grupo econômico
        
        Args:
            cpf_cnpj: CPF ou CNPJ do associado
            
        Returns:
            str: Código do grupo econômico ou None se não pertencer a nenhum grupo
        """
        try:
            logger.info(f"🔍 Verificando grupo econômico para {cpf_cnpj}")
            spark = self._get_spark()
            
            # Consulta para verificar se o CPF/CNPJ pertence a um grupo econômico
            sql_grupo = f"""
            SELECT DISTINCT Codigo_conglomerado_economico, nome_grupo_economico
            FROM sicredi_coop_0914.bases_bi.perfil_associado
            WHERE num_cpf_cnpj = '{cpf_cnpj}'
            AND Codigo_conglomerado_economico IS NOT NULL
            AND Codigo_conglomerado_economico <> ''
            LIMIT 1
            """
            
            # Executar com retry
            resultado = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_grupo).toPandas()
            )
            
            if not resultado.empty and pd.notna(resultado['Codigo_conglomerado_economico'].iloc[0]):
                codigo_grupo = resultado['Codigo_conglomerado_economico'].iloc[0]
                nome_grupo = resultado['nome_grupo_economico'].iloc[0]
                logger.info(f"✅ Grupo econômico encontrado: {codigo_grupo} - {nome_grupo}")
                return codigo_grupo
            else:
                logger.info(f"ℹ️ Nenhum grupo econômico encontrado para {cpf_cnpj}")
                return None
                
        except Exception as e:
            logger.error(f"❌ Erro ao verificar grupo econômico: {str(e)}")
            return None
    
    def analisar_credito_conjuge(self, cpf_conjuge: str, nome_conjuge: str) -> Dict[str, Any]:
        """
        Realiza uma análise do histórico de crédito do cônjuge do associado principal.
        
        Args:
            cpf_conjuge: CPF do cônjuge
            nome_conjuge: Nome do cônjuge
            
        Returns:
            Dict: Dados estruturados da análise do histórico de crédito do cônjuge
        """
        start_time = time.time()
        try:
            logger.info(f"🔍 Analisando histórico de crédito do cônjuge: {nome_conjuge} (CPF: {cpf_conjuge})")
            
            # Executar as consultas SQL para o cônjuge
            resultados = self.executar_consultas_sql(cpf_conjuge)
            
            # Verificar se há dados retornados
            if not resultados["perfil_associado"].empty and not resultados["situacao_atual"].empty:
                # Estruturar os dados
                logger.info(f"🔄 Estruturando dados do histórico de crédito do cônjuge {cpf_conjuge}")
                dados_estruturados = self.estruturar_dados(resultados)
                
                # Adicionar informações do cônjuge
                dados_estruturados["cpf"] = cpf_conjuge
                dados_estruturados["nome"] = nome_conjuge
                
                elapsed = time.time() - start_time
                logger.info(f"✅ Análise do histórico de crédito do cônjuge concluída em {elapsed:.2f}s")
                
                return {
                    "status": "success",
                    "dados": dados_estruturados
                }
            else:
                logger.warning(f"⚠️ Não foram encontrados dados de histórico de crédito para o cônjuge {cpf_conjuge}")
                return {
                    "status": "no_data",
                    "message": f"Não foram encontrados dados de histórico de crédito para o cônjuge {cpf_conjuge}"
                }
                
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"❌ Erro ao analisar histórico de crédito do cônjuge após {elapsed:.2f}s: {str(e)}")
            return {
                "status": "error",
                "message": f"Erro ao analisar histórico de crédito do cônjuge {cpf_conjuge}: {str(e)}"
            }
    
    def analisar_grupo_economico(self, cod_grupo: str, cpf_cnpj_principal: str) -> Dict[str, Any]:
        """
        Realiza uma análise do grupo econômico
        
        Args:
            cod_grupo: Código do grupo econômico
            cpf_cnpj_principal: CPF/CNPJ do associado principal
            
        Returns:
            Dict: Dados estruturados da análise do grupo econômico
        """
        start_time = time.time()
        try:
            logger.info(f"🏢 Analisando grupo econômico {cod_grupo}")
            spark = self._get_spark()
            
            # Consulta para obter os membros do grupo econômico
            sql_membros = f"""
            SELECT DISTINCT num_cpf_cnpj, nome_associado, tipo_pessoa
            FROM sicredi_coop_0914.bases_bi.perfil_associado
            WHERE Codigo_conglomerado_economico = '{cod_grupo}'
            AND num_cpf_cnpj <> '{cpf_cnpj_principal}'
            """
            
            # Executar com retry
            membros_df = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_membros).toPandas()
            )
            
            membros = []
            if not membros_df.empty:
                for _, row in membros_df.iterrows():
                    membros.append({
                        "cpf_cnpj": row["num_cpf_cnpj"],
                        "nome": row["nome_associado"],
                        "tipo_pessoa": row["tipo_pessoa"]
                    })
            
            logger.info(f"👥 Grupo econômico {cod_grupo} possui {len(membros)} membros adicionais")
            
            # Consulta para obter dados consolidados do grupo econômico
            sql_grupo_resumo = f"""
            WITH membros_grupo AS (
                SELECT num_cpf_cnpj
                FROM sicredi_coop_0914.bases_bi.perfil_associado
                WHERE Codigo_conglomerado_economico = '{cod_grupo}'
            ),
            
            dados_credito AS (
                SELECT 
                    ic.cpf_cnpj,
                    ic.ano_mes,
                    SUM(ic.saldo_atual) AS saldo_total,
                    SUM(ic.saldo_venc_atual) AS saldo_vencido,
                    SUM(ic.prov_atual) AS provisao_total,
                    COUNT(DISTINCT ic.titulo) AS qtd_operacoes
                FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade ic
                JOIN membros_grupo mg ON ic.cpf_cnpj = mg.num_cpf_cnpj
                WHERE ic.ano_mes = (SELECT MAX(ano_mes) FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade)
                GROUP BY ic.cpf_cnpj, ic.ano_mes
            )
            
            SELECT 
                COUNT(DISTINCT cpf_cnpj) AS qtd_membros,
                SUM(saldo_total) AS saldo_total_grupo,
                SUM(saldo_vencido) AS saldo_vencido_grupo,
                SUM(provisao_total) AS provisao_total_grupo,
                AVG(saldo_total) AS saldo_medio_membros,
                SUM(qtd_operacoes) AS total_operacoes
            FROM dados_credito
            """
            
            # Executar com retry
            grupo_resumo = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_grupo_resumo).toPandas()
            )
            
            # Consulta para obter a distribuição por tipo de produto do grupo
            sql_tipo_produto_grupo = f"""
            WITH membros_grupo AS (
                SELECT num_cpf_cnpj
                FROM sicredi_coop_0914.bases_bi.perfil_associado
                WHERE Codigo_conglomerado_economico = '{cod_grupo}'
            )
            
            SELECT 
                tipo_produto,
                SUM(saldo_atual) AS saldo_atual,
                ROUND((SUM(saldo_atual) / SUM(SUM(saldo_atual)) OVER ()) * 100, 2) AS percentual,
                COUNT(DISTINCT titulo) AS qtd_operacoes
            FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade ic
            JOIN membros_grupo mg ON ic.cpf_cnpj = mg.num_cpf_cnpj
            WHERE ic.ano_mes = (SELECT MAX(ano_mes) FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade)
            GROUP BY tipo_produto
            ORDER BY saldo_atual DESC
            """
            
            # Executar com retry
            tipo_produto_grupo = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_tipo_produto_grupo).toPandas()
            )
            
            # Estruturar os dados do grupo
            if not grupo_resumo.empty:
                gr = grupo_resumo.iloc[0]
                
                dados_grupo = {
                    "cod_grupo": cod_grupo,
                    "membros_info": membros,
                    "qtd_membros": self.safe_int(gr["qtd_membros"]),
                    "saldo_total_grupo": self.safe_float(gr["saldo_total_grupo"]),
                    "saldo_vencido_grupo": self.safe_float(gr["saldo_vencido_grupo"]),
                    "provisao_total_grupo": self.safe_float(gr["provisao_total_grupo"]),
                    "saldo_medio_membros": self.safe_float(gr["saldo_medio_membros"]),
                    "total_operacoes": self.safe_int(gr["total_operacoes"]),
                    "distribuicao_tipo_produto": []
                }
                
                # Adicionar distribuição por tipo de produto do grupo
                for _, row in tipo_produto_grupo.iterrows():
                    dados_grupo["distribuicao_tipo_produto"].append({
                        "tipo_produto": row["tipo_produto"],
                        "saldo_atual": self.safe_float(row["saldo_atual"]),
                        "percentual": self.safe_float(row["percentual"]),
                        "qtd_operacoes": self.safe_int(row["qtd_operacoes"])
                    })
                
                elapsed = time.time() - start_time
                logger.info(f"✅ Análise do grupo econômico concluída em {elapsed:.2f}s")
                
                return {
                    "status": "success",
                    "dados": dados_grupo
                }
            else:
                logger.warning(f"⚠️ Não foram encontrados dados consolidados do grupo econômico {cod_grupo}")
                return {
                    "status": "no_data",
                    "message": f"Não foram encontrados dados consolidados do grupo econômico {cod_grupo}",
                    "dados": {
                        "cod_grupo": cod_grupo,
                        "membros_info": membros,
                        "qtd_membros": len(membros)
                    }
                }
                
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"❌ Erro ao analisar grupo econômico após {elapsed:.2f}s: {str(e)}")
            return {
                "status": "error",
                "message": f"Erro ao analisar grupo econômico {cod_grupo}: {str(e)}"
            }
    
    def executar_consultas_sql(self, cpf_cnpj: str) -> Dict[str, pd.DataFrame]:
        """
        Executa as consultas SQL principais e retorna os resultados
        
        Args:
            cpf_cnpj: CPF ou CNPJ do associado (apenas números)
            
        Returns:
            Dict: Dicionário contendo os DataFrames com os resultados das consultas
        """
        start_time = time.time()
        logger.info(f"📊 Iniciando execução de consultas SQL para {cpf_cnpj}")
        
        # Verificar se os dados já estão em cache
        cache_key = f"sql_{cpf_cnpj}"
        if cache_key in self.cache_credito:
            logger.info(f"🔄 Usando resultados SQL em cache para {cpf_cnpj}")
            return self.cache_credito[cache_key]
        
        # SQL para obter o perfil do associado
        sql_perfil_associado = f"""
        SELECT DISTINCT
            cpf_cnpj,
            tipo_pessoa,
            segmento_assoc,
            subsegmento,
            desc_atividade,
            tempo_relacionamento,
            cod_agencia,
            cod_carteira
        FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade
        WHERE cpf_cnpj = '{cpf_cnpj}'
        AND ano_mes = (SELECT MAX(ano_mes) FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade WHERE cpf_cnpj = '{cpf_cnpj}')
        LIMIT 1
        """
        
        # SQL para obter a situação atual
        sql_situacao_atual = f"""
        SELECT 
            ano_mes,
            SUM(saldo_atual) AS saldo_total,
            SUM(saldo_venc_atual) AS saldo_vencido,
            SUM(prov_atual) AS provisao_total,
            CASE WHEN SUM(saldo_atual) > 0 THEN 
                ROUND((SUM(prov_atual) / SUM(saldo_atual)) * 100, 2)
            ELSE 0 END AS percentual_provisao,
            MAX(fx_risco_at) AS faixa_risco,
            FIRST(estagio_at) AS estagio_predominante,
            COUNT(DISTINCT titulo) AS qtd_operacoes
        FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade
        WHERE cpf_cnpj = '{cpf_cnpj}'
        AND ano_mes = (SELECT MAX(ano_mes) FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade WHERE cpf_cnpj = '{cpf_cnpj}')
        GROUP BY ano_mes
        """
        
        # SQL para obter a evolução da carteira
        sql_evolucao_carteira = f"""
        WITH meses_recentes AS (
            SELECT DISTINCT ano_mes
            FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade
            WHERE cpf_cnpj = '{cpf_cnpj}'
            ORDER BY ano_mes DESC
            LIMIT 12
        )
        
        SELECT 
            ec.ano_mes,
            SUM(ec.saldo_atual) AS saldo_total,
            SUM(ec.saldo_venc_atual) AS saldo_vencido,
            SUM(ec.prov_atual) AS provisao_total,
            MAX(ec.fx_risco_at) AS faixa_risco
        FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade ec
        JOIN meses_recentes m ON ec.ano_mes = m.ano_mes
        WHERE ec.cpf_cnpj = '{cpf_cnpj}'
        GROUP BY ec.ano_mes
        ORDER BY ec.ano_mes DESC
        """
        
        # SQL para obter a distribuição por tipo de produto
        sql_distribuicao_tipo_produto = f"""
        SELECT 
            tipo_produto,
            SUM(saldo_atual) AS saldo_atual,
            ROUND((SUM(saldo_atual) / SUM(SUM(saldo_atual)) OVER ()) * 100, 2) AS percentual,
            SUM(prov_atual) AS provisao_atual,
            COUNT(DISTINCT titulo) AS qtd_operacoes
        FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade
        WHERE cpf_cnpj = '{cpf_cnpj}'
        AND ano_mes = (SELECT MAX(ano_mes) FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade WHERE cpf_cnpj = '{cpf_cnpj}')
        GROUP BY tipo_produto
        """
        
        # SQL para obter a distribuição por vencimento
        sql_distribuicao_vencimento = f"""
        SELECT 
            SUM(vncer_000_a_090) AS ate_90_dias,
            SUM(vncer_091_a_360) AS de_91_a_360_dias,
            SUM(vncer_361_mais) AS acima_361_dias,
            ROUND((SUM(vncer_000_a_090) / NULLIF(SUM(vncer_000_a_090) + SUM(vncer_091_a_360) + SUM(vncer_361_mais), 0)) * 100, 2) AS percentual_curto_prazo,
            ROUND((SUM(vncer_091_a_360) / NULLIF(SUM(vncer_000_a_090) + SUM(vncer_091_a_360) + SUM(vncer_361_mais), 0)) * 100, 2) AS percentual_medio_prazo,
            ROUND((SUM(vncer_361_mais) / NULLIF(SUM(vncer_000_a_090) + SUM(vncer_091_a_360) + SUM(vncer_361_mais), 0)) * 100, 2) AS percentual_longo_prazo
        FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade
        WHERE cpf_cnpj = '{cpf_cnpj}'
        AND ano_mes = (SELECT MAX(ano_mes) FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade WHERE cpf_cnpj = '{cpf_cnpj}')
        """
        
        # SQL para obter a evolução do rating
        sql_evolucao_rating = f"""
        WITH meses_recentes AS (
            SELECT DISTINCT ano_mes
            FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade
            WHERE cpf_cnpj = '{cpf_cnpj}'
            ORDER BY ano_mes DESC
            LIMIT 6
        )
        
        SELECT 
            er.ano_mes,
            MAX(er.rating_asso_at) AS rating_predominante,
            MAX(er.fx_risco_at) AS faixa_risco,
            COUNT(DISTINCT CASE WHEN er.analise_pe = 'MELHOROU PE' THEN er.titulo END) AS qtd_operacoes_melhoraram,
            COUNT(DISTINCT CASE WHEN er.analise_pe = 'PIOROU PE' THEN er.titulo END) AS qtd_operacoes_pioraram,
            COUNT(DISTINCT CASE WHEN er.analise_pe LIKE 'MANTEVE%' THEN er.titulo END) AS qtd_operacoes_mantiveram
        FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade er
        JOIN meses_recentes m ON er.ano_mes = m.ano_mes
        WHERE er.cpf_cnpj = '{cpf_cnpj}'
        GROUP BY er.ano_mes
        ORDER BY er.ano_mes DESC
        """
        
        # SQL para obter a análise de sazonalidade de pagamentos
        sql_sazonalidade_pagamentos = f"""
        WITH PagamentosMensaisPorAno AS (
            SELECT 
                SUBSTRING(CAST(ano_mes AS VARCHAR(10)), 5, 2) AS mes,
                SUM(CASE WHEN saldo_ant > saldo_atual THEN saldo_ant - saldo_atual ELSE 0 END) AS pagamentos,
                SUM(CASE WHEN saldo_atual > saldo_ant THEN saldo_atual - saldo_ant ELSE 0 END) AS novos_debitos
            FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade
            WHERE cpf_cnpj = '{cpf_cnpj}'
            GROUP BY SUBSTRING(CAST(ano_mes AS VARCHAR(10)), 5, 2)
        )
        
        SELECT 
            mes,
            AVG(pagamentos) AS media_pagamentos_mensal,
            AVG(novos_debitos) AS media_novos_debitos_mensal,
            AVG(pagamentos - novos_debitos) AS media_amortizacao_liquida
        FROM PagamentosMensaisPorAno
        GROUP BY mes
        ORDER BY mes
        """
        
        # SQL para obter análise de concentração de risco por operação
        sql_concentracao_risco = f"""
        SELECT 
            titulo,
            prod_grupo_1,
            prod_grupo_2,
            saldo_atual,
            ROUND((saldo_atual / SUM(saldo_atual) OVER ()) * 100, 2) AS percentual_carteira,
            prov_atual,
            ROUND((prov_atual / NULLIF(saldo_atual, 0)) * 100, 4) AS percentual_provisao,
            fx_risco_at,
            estagio_at,
            dias_ate_prejuizo,
            vncer_000_a_090,
            vncer_091_a_360,
            vncer_361_mais
        FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade
        WHERE cpf_cnpj = '{cpf_cnpj}'
          AND ano_mes = (SELECT MAX(ano_mes) FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade WHERE cpf_cnpj = '{cpf_cnpj}')
          AND saldo_atual > 0
        ORDER BY saldo_atual DESC
        """
        
        # SQL para obter análise de capacidade de pagamento
        sql_capacidade_pagamento = f"""
        WITH FluxoPagamentos AS (
            SELECT
                ano_mes,
                SUM(vncer_000_a_090) AS pagamentos_90dias,
                SUM(vncer_091_a_360) AS pagamentos_360dias,
                SUM(vncer_361_mais) AS pagamentos_longo_prazo,
                SUM(vncer_000_a_090 + vncer_091_a_360 + vncer_361_mais) AS pagamentos_totais
            FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade
            WHERE cpf_cnpj = '{cpf_cnpj}'
            GROUP BY ano_mes
        )
        
        SELECT
            ano_mes,
            pagamentos_90dias,
            pagamentos_90dias / 3 AS media_mensal_proximos_3meses,
            CASE 
                WHEN LAG(pagamentos_totais) OVER (ORDER BY ano_mes) > 0 
                THEN ROUND(((pagamentos_totais - LAG(pagamentos_totais) OVER (ORDER BY ano_mes)) / 
                      LAG(pagamentos_totais) OVER (ORDER BY ano_mes)) * 100, 2)
                ELSE 0
            END AS variacao_percentual_fluxo
        FROM FluxoPagamentos
        ORDER BY ano_mes DESC
        LIMIT 12
        """
        
        # SQL para obter análise de evolução de estágios IFRS 9
        sql_evolucao_estagios = f"""
        WITH EstagioPorMes AS (
            SELECT 
                ano_mes,
                SUM(CASE WHEN estagio_at = 1 THEN saldo_atual ELSE 0 END) AS saldo_estagio1,
                SUM(CASE WHEN estagio_at = 2 THEN saldo_atual ELSE 0 END) AS saldo_estagio2,
                SUM(CASE WHEN estagio_at = 3 THEN saldo_atual ELSE 0 END) AS saldo_estagio3,
                SUM(saldo_atual) AS saldo_total
            FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade
            WHERE cpf_cnpj = '{cpf_cnpj}'
            GROUP BY ano_mes
        )
        
        SELECT 
            ano_mes,
            saldo_estagio1,
            saldo_estagio2,
            saldo_estagio3,
            ROUND((saldo_estagio1 / NULLIF(saldo_total, 0)) * 100, 2) AS perc_estagio1,
            ROUND((saldo_estagio2 / NULLIF(saldo_total, 0)) * 100, 2) AS perc_estagio2,
            ROUND((saldo_estagio3 / NULLIF(saldo_total, 0)) * 100, 2) AS perc_estagio3
        FROM EstagioPorMes
        ORDER BY ano_mes DESC
        LIMIT 12
        """
        
        # SQL para obter análise de tendência de pagamentos
        sql_tendencia_pagamentos = f"""
        WITH PagamentosMensais AS (
            SELECT 
                ano_mes,
                titulo,
                saldo_atual,
                saldo_ant,
                saldo_ant - saldo_atual AS pagamento_mensal,
                CASE WHEN saldo_ant > 0 
                     THEN ((saldo_ant - saldo_atual) / saldo_ant) * 100
                     ELSE 0 END AS percentual_pagamento
            FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade
            WHERE cpf_cnpj = '{cpf_cnpj}'
              AND saldo_ant > 0
        )
        
        SELECT 
            ano_mes,
            SUM(pagamento_mensal) AS total_pagamentos,
            AVG(percentual_pagamento) AS media_percentual_pagamento,
            COUNT(CASE WHEN pagamento_mensal > 0 THEN 1 END) AS operacoes_com_pagamento,
            COUNT(CASE WHEN pagamento_mensal <= 0 THEN 1 END) AS operacoes_sem_pagamento,
            ROUND((COUNT(CASE WHEN pagamento_mensal > 0 THEN 1 END) / COUNT(*)) * 100, 2) AS percentual_operacoes_com_pagamento
        FROM PagamentosMensais
        GROUP BY ano_mes
        ORDER BY ano_mes DESC
        LIMIT 12
        """
        
        # SQL para obter histórico de inadimplência
        sql_historico_inadimplencia = f"""
        SELECT 
            ano_mes,
            COUNT(DISTINCT titulo) AS total_operacoes,
            COUNT(DISTINCT CASE WHEN fx_atraso_atual = 'EM DIA' THEN titulo END) AS operacoes_em_dia,
            COUNT(DISTINCT CASE WHEN fx_atraso_atual <> 'EM DIA' THEN titulo END) AS operacoes_em_atraso,
            ROUND((COUNT(DISTINCT CASE WHEN fx_atraso_atual = 'EM DIA' THEN titulo END) / 
                   COUNT(DISTINCT titulo)) * 100, 2) AS percentual_operacoes_em_dia,
            MAX(atraso_atual) AS maior_atraso,
            SUM(CASE WHEN atraso_atual > 0 THEN saldo_atual ELSE 0 END) AS saldo_em_atraso,
            SUM(saldo_over90_atual) AS saldo_over90
        FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade
        WHERE cpf_cnpj = '{cpf_cnpj}'
        GROUP BY ano_mes
        ORDER BY ano_mes DESC
        LIMIT 12
        """
        
        # SQL para obter evolução de provisões
        sql_evolucao_provisoes = f"""
        SELECT 
            ano_mes,
            SUM(prov_atual) AS provisao_total,
            SUM(prov_ant) AS provisao_anterior,
            SUM(prov_atual) - SUM(prov_ant) AS variacao_provisao,
            ROUND(((SUM(prov_atual) - SUM(prov_ant)) / NULLIF(SUM(prov_ant), 0)) * 100, 2) AS variacao_percentual,
            COUNT(DISTINCT CASE WHEN analise_pdd = 'MELHOROU' THEN titulo END) AS operacoes_melhoraram,
            COUNT(DISTINCT CASE WHEN analise_pdd = 'PIOROU' THEN titulo END) AS operacoes_pioraram,
            COUNT(DISTINCT CASE WHEN analise_pdd = 'MANTEVE' THEN titulo END) AS operacoes_mantiveram
        FROM sicredi_coop_0914.denodo_datasets.indicadores_risco_credito_qualidade
        WHERE cpf_cnpj = '{cpf_cnpj}'
        GROUP BY ano_mes
        ORDER BY ano_mes DESC
        LIMIT 12
        """
        
        # Inicializar o SparkSession
        spark = self._get_spark()
        
        try:
            logger.info("📊 Executando consulta de perfil do associado")
            perfil_associado = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_perfil_associado).toPandas()
            )
            
            logger.info("📊 Executando consulta de situação atual")
            situacao_atual = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_situacao_atual).toPandas()
            )
            
            logger.info("📊 Executando consulta de evolução da carteira")
            evolucao_carteira = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_evolucao_carteira).toPandas()
            )
            
            logger.info("📊 Executando consulta de distribuição por tipo de produto")
            distribuicao_tipo_produto = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_distribuicao_tipo_produto).toPandas()
            )
            
            logger.info("📊 Executando consulta de distribuição por vencimento")
            distribuicao_vencimento = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_distribuicao_vencimento).toPandas()
            )
            
            logger.info("📊 Executando consulta de evolução do rating")
            evolucao_rating = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_evolucao_rating).toPandas()
            )
            
            logger.info("📊 Executando consulta de sazonalidade de pagamentos")
            sazonalidade_pagamentos = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_sazonalidade_pagamentos).toPandas()
            )
            
            logger.info("📊 Executando consulta de concentração de risco")
            concentracao_risco = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_concentracao_risco).toPandas()
            )
            
            logger.info("📊 Executando consulta de capacidade de pagamento")
            capacidade_pagamento = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_capacidade_pagamento).toPandas()
            )
            
            logger.info("📊 Executando consulta de evolução de estágios")
            evolucao_estagios = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_evolucao_estagios).toPandas()
            )
            
            logger.info("📊 Executando consulta de tendência de pagamentos")
            tendencia_pagamentos = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_tendencia_pagamentos).toPandas()
            )
            
            logger.info("📊 Executando consulta de histórico de inadimplência")
            historico_inadimplencia = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_historico_inadimplencia).toPandas()
            )
            
            logger.info("📊 Executando consulta de evolução de provisões")
            evolucao_provisoes = SparkSessionManager.execute_with_retry(
                lambda: spark.sql(sql_evolucao_provisoes).toPandas()
            )
            
            resultados = {
                "perfil_associado": perfil_associado,
                "situacao_atual": situacao_atual,
                "evolucao_carteira": evolucao_carteira,
                "distribuicao_tipo_produto": distribuicao_tipo_produto,
                "distribuicao_vencimento": distribuicao_vencimento,
                "evolucao_rating": evolucao_rating,
                "sazonalidade_pagamentos": sazonalidade_pagamentos,
                "concentracao_risco": concentracao_risco,
                "capacidade_pagamento": capacidade_pagamento,
                "evolucao_estagios": evolucao_estagios,
                "tendencia_pagamentos": tendencia_pagamentos,
                "historico_inadimplencia": historico_inadimplencia,
                "evolucao_provisoes": evolucao_provisoes
            }
            
            # Verificar resultados
            if not perfil_associado.empty:
                logger.info(f"👤 Perfil do associado: dados obtidos")
            else:
                logger.warning("⚠️ Consulta de perfil do associado não retornou dados")
                
            if not situacao_atual.empty:
                logger.info(f"📊 Situação atual: saldo total R$ {situacao_atual['saldo_total'].iloc[0]:,.2f}")
            else:
                logger.warning("⚠️ Consulta de situação atual não retornou dados")
            
            # Armazenar no cache
            self.cache_credito[cache_key] = resultados
            
            elapsed = time.time() - start_time
            logger.info(f"✅ Consultas SQL executadas com sucesso em {elapsed:.2f}s")
            
            return resultados
            
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"❌ Erro ao executar consultas SQL após {elapsed:.2f}s: {str(e)}")
            
            # Tentar reiniciar a sessão Spark
            logger.warning("🔄 Tentando reiniciar a sessão Spark após erro")
            SparkSessionManager.reset()
            self.spark = SparkSessionManager.get_or_create()
            
            # Tentar novamente as consultas
            logger.info("🔄 Executando consultas novamente após reinicialização do Spark")
            try:
                perfil_associado = self.spark.sql(sql_perfil_associado).toPandas()
                situacao_atual = self.spark.sql(sql_situacao_atual).toPandas()
                evolucao_carteira = self.spark.sql(sql_evolucao_carteira).toPandas()
                distribuicao_tipo_produto = self.spark.sql(sql_distribuicao_tipo_produto).toPandas()
                distribuicao_vencimento = self.spark.sql(sql_distribuicao_vencimento).toPandas()
                evolucao_rating = self.spark.sql(sql_evolucao_rating).toPandas()
                sazonalidade_pagamentos = self.spark.sql(sql_sazonalidade_pagamentos).toPandas()
                concentracao_risco = self.spark.sql(sql_concentracao_risco).toPandas()
                capacidade_pagamento = self.spark.sql(sql_capacidade_pagamento).toPandas()
                evolucao_estagios = self.spark.sql(sql_evolucao_estagios).toPandas()
                tendencia_pagamentos = self.spark.sql(sql_tendencia_pagamentos).toPandas()
                historico_inadimplencia = self.spark.sql(sql_historico_inadimplencia).toPandas()
                evolucao_provisoes = self.spark.sql(sql_evolucao_provisoes).toPandas()
                
                resultados = {
                    "perfil_associado": perfil_associado,
                    "situacao_atual": situacao_atual,
                    "evolucao_carteira": evolucao_carteira,
                    "distribuicao_tipo_produto": distribuicao_tipo_produto,
                    "distribuicao_vencimento": distribuicao_vencimento,
                    "evolucao_rating": evolucao_rating,
                    "sazonalidade_pagamentos": sazonalidade_pagamentos,
                    "concentracao_risco": concentracao_risco,
                    "capacidade_pagamento": capacidade_pagamento,
                    "evolucao_estagios": evolucao_estagios,
                    "tendencia_pagamentos": tendencia_pagamentos,
                    "historico_inadimplencia": historico_inadimplencia,
                    "evolucao_provisoes": evolucao_provisoes
                }
                
                elapsed_retry = time.time() - start_time
                logger.info(f"✅ Consultas SQL executadas com sucesso após retry em {elapsed_retry:.2f}s")
                return resultados
            except Exception as e2:
                elapsed_retry = time.time() - start_time
                logger.error(f"❌ Falha definitiva nas consultas SQL após {elapsed_retry:.2f}s: {str(e2)}")
                return {
                    "perfil_associado": pd.DataFrame(),
                    "situacao_atual": pd.DataFrame(),
                    "evolucao_carteira": pd.DataFrame(),
                    "distribuicao_tipo_produto": pd.DataFrame(),
                    "distribuicao_vencimento": pd.DataFrame(),
                    "evolucao_rating": pd.DataFrame(),
                    "sazonalidade_pagamentos": pd.DataFrame(),
                    "concentracao_risco": pd.DataFrame(),
                    "capacidade_pagamento": pd.DataFrame(),
                    "evolucao_estagios": pd.DataFrame(),
                    "tendencia_pagamentos": pd.DataFrame(),
                    "historico_inadimplencia": pd.DataFrame(),
                    "evolucao_provisoes": pd.DataFrame()
                }
    
    def estruturar_dados(self, resultados: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """
        Estrutura os dados para envio ao modelo LLM
        
        Args:
            resultados: Dicionário contendo os DataFrames com os resultados das consultas
            
        Returns:
            Dict: Dados estruturados para análise
        """
        start_time = time.time()
        logger.info("🔄 Estruturando dados para análise")
        
        dados_estruturados = {
            "perfil_associado": {},
            "situacao_atual": {},
            "evolucao_carteira": [],
            "distribuicao_tipo_produto": [],
            "distribuicao_vencimento": {},
            "evolucao_rating": [],
            "sazonalidade_pagamentos": [],
            "concentracao_risco": [],
            "capacidade_pagamento": [],
            "evolucao_estagios": [],
            "tendencia_pagamentos": [],
            "historico_inadimplencia": [],
            "evolucao_provisoes": [],
            "resumo_estatistico": {}
        }
        
        # Processar perfil do associado
        if not resultados["perfil_associado"].empty:
            pa = resultados["perfil_associado"].iloc[0]
            dados_estruturados["perfil_associado"] = {
                "cpf_cnpj": pa["cpf_cnpj"],
                "tipo_pessoa": pa["tipo_pessoa"],
                "segmento_assoc": pa["segmento_assoc"],
                "subsegmento": pa["subsegmento"],
                "desc_atividade": pa["desc_atividade"],
                "tempo_relacionamento": pa["tempo_relacionamento"],
                "cod_agencia": pa["cod_agencia"],
                "cod_carteira": pa["cod_carteira"]
            }
        
        # Processar situação atual
        if not resultados["situacao_atual"].empty:
            sa = resultados["situacao_atual"].iloc[0]
            dados_estruturados["situacao_atual"] = {
                "ano_mes": self.safe_int(sa["ano_mes"]),
                "saldo_total": self.safe_float(sa["saldo_total"]),
                "saldo_vencido": self.safe_float(sa["saldo_vencido"]) if sa["saldo_vencido"] > 0 else 0,
                "provisao_total": self.safe_float(sa["provisao_total"]),
                "percentual_provisao": self.safe_float(sa["percentual_provisao"]),
                "faixa_risco": sa["faixa_risco"],
                "estagio_predominante": self.safe_float(sa["estagio_predominante"]),
                "qtd_operacoes": self.safe_int(sa["qtd_operacoes"])
            }
        
        # Processar evolução da carteira
        for _, row in resultados["evolucao_carteira"].iterrows():
            dados_estruturados["evolucao_carteira"].append({
                "ano_mes": self.safe_int(row["ano_mes"]),
                "saldo_total": self.safe_float(row["saldo_total"]),
                "saldo_vencido": self.safe_float(row["saldo_vencido"]) if row["saldo_vencido"] > 0 else 0,
                "provisao_total": self.safe_float(row["provisao_total"]),
                "faixa_risco": row["faixa_risco"]
            })
        
        # Processar distribuição por tipo de produto
        for _, row in resultados["distribuicao_tipo_produto"].iterrows():
            dados_estruturados["distribuicao_tipo_produto"].append({
                "tipo_produto": row["tipo_produto"],
                "saldo_atual": self.safe_float(row["saldo_atual"]),
                "percentual": self.safe_float(row["percentual"]),
                "provisao_atual": self.safe_float(row["provisao_atual"]),
                "qtd_operacoes": self.safe_int(row["qtd_operacoes"])
            })
        
        # Processar distribuição por vencimento
        if not resultados["distribuicao_vencimento"].empty:
            dv = resultados["distribuicao_vencimento"].iloc[0]
            dados_estruturados["distribuicao_vencimento"] = {
                "ate_90_dias": self.safe_float(dv["ate_90_dias"]),
                "de_91_a_360_dias": self.safe_float(dv["de_91_a_360_dias"]),
                "acima_361_dias": self.safe_float(dv["acima_361_dias"]),
                "percentual_curto_prazo": self.safe_float(dv["percentual_curto_prazo"]),
                "percentual_medio_prazo": self.safe_float(dv["percentual_medio_prazo"]),
                "percentual_longo_prazo": self.safe_float(dv["percentual_longo_prazo"])
            }
        
        # Processar evolução do rating
        for _, row in resultados["evolucao_rating"].iterrows():
            dados_estruturados["evolucao_rating"].append({
                "ano_mes": self.safe_int(row["ano_mes"]),
                "rating_predominante": row["rating_predominante"] if pd.notna(row["rating_predominante"]) else "",
                "faixa_risco": row["faixa_risco"] if pd.notna(row["faixa_risco"]) else "",
                "qtd_operacoes_melhoraram": self.safe_int(row["qtd_operacoes_melhoraram"]),
                "qtd_operacoes_pioraram": self.safe_int(row["qtd_operacoes_pioraram"]),
                "qtd_operacoes_mantiveram": self.safe_int(row["qtd_operacoes_mantiveram"])
            })
        
        # Processar sazonalidade de pagamentos
        for _, row in resultados["sazonalidade_pagamentos"].iterrows():
            dados_estruturados["sazonalidade_pagamentos"].append({
                "mes": row["mes"],
                "media_pagamentos_mensal": self.safe_float(row["media_pagamentos_mensal"]),
                "media_novos_debitos_mensal": self.safe_float(row["media_novos_debitos_mensal"]),
                "media_amortizacao_liquida": self.safe_float(row["media_amortizacao_liquida"])
            })
        
        # Processar concentração de risco
        for _, row in resultados["concentracao_risco"].iterrows():
            dados_estruturados["concentracao_risco"].append({
                "titulo": row["titulo"],
                "prod_grupo_1": row["prod_grupo_1"],
                "prod_grupo_2": row["prod_grupo_2"],
                "saldo_atual": self.safe_float(row["saldo_atual"]),
                "percentual_carteira": self.safe_float(row["percentual_carteira"]),
                "prov_atual": self.safe_float(row["prov_atual"]),
                "percentual_provisao": self.safe_float(row["percentual_provisao"]) if pd.notna(row["percentual_provisao"]) else 0,
                "fx_risco_at": row["fx_risco_at"],
                "estagio_at": self.safe_float(row["estagio_at"]) if pd.notna(row["estagio_at"]) else 0,
                "dias_ate_prejuizo": self.safe_float(row["dias_ate_prejuizo"]) if pd.notna(row["dias_ate_prejuizo"]) else 0,
                "vncer_000_a_090": self.safe_float(row["vncer_000_a_090"]) if pd.notna(row["vncer_000_a_090"]) else 0,
                "vncer_091_a_360": self.safe_float(row["vncer_091_a_360"]) if pd.notna(row["vncer_091_a_360"]) else 0,
                "vncer_361_mais": self.safe_float(row["vncer_361_mais"]) if pd.notna(row["vncer_361_mais"]) else 0
            })
        
        # Processar capacidade de pagamento
        for _, row in resultados["capacidade_pagamento"].iterrows():
            dados_estruturados["capacidade_pagamento"].append({
                "ano_mes": self.safe_int(row["ano_mes"]),
                "pagamentos_90dias": self.safe_float(row["pagamentos_90dias"]) if pd.notna(row["pagamentos_90dias"]) else 0,
                "media_mensal_proximos_3meses": self.safe_float(row["media_mensal_proximos_3meses"]) if pd.notna(row["media_mensal_proximos_3meses"]) else 0,
                "variacao_percentual_fluxo": self.safe_float(row["variacao_percentual_fluxo"]) if pd.notna(row["variacao_percentual_fluxo"]) else 0
            })
        
        # Processar evolução de estágios
        for _, row in resultados["evolucao_estagios"].iterrows():
            dados_estruturados["evolucao_estagios"].append({
                "ano_mes": self.safe_int(row["ano_mes"]),
                "saldo_estagio1": self.safe_float(row["saldo_estagio1"]) if pd.notna(row["saldo_estagio1"]) else 0,
                "saldo_estagio2": self.safe_float(row["saldo_estagio2"]) if pd.notna(row["saldo_estagio2"]) else 0,
                "saldo_estagio3": self.safe_float(row["saldo_estagio3"]) if pd.notna(row["saldo_estagio3"]) else 0,
                "perc_estagio1": self.safe_float(row["perc_estagio1"]) if pd.notna(row["perc_estagio1"]) else 0,
                "perc_estagio2": self.safe_float(row["perc_estagio2"]) if pd.notna(row["perc_estagio2"]) else 0,
                "perc_estagio3": self.safe_float(row["perc_estagio3"]) if pd.notna(row["perc_estagio3"]) else 0
            })
        
        # Processar tendência de pagamentos
        for _, row in resultados["tendencia_pagamentos"].iterrows():
            dados_estruturados["tendencia_pagamentos"].append({
                "ano_mes": self.safe_int(row["ano_mes"]),
                "total_pagamentos": self.safe_float(row["total_pagamentos"]) if pd.notna(row["total_pagamentos"]) else 0,
                "media_percentual_pagamento": self.safe_float(row["media_percentual_pagamento"]) if pd.notna(row["media_percentual_pagamento"]) else 0,
                "operacoes_com_pagamento": self.safe_int(row["operacoes_com_pagamento"]) if pd.notna(row["operacoes_com_pagamento"]) else 0,
                "operacoes_sem_pagamento": self.safe_int(row["operacoes_sem_pagamento"]) if pd.notna(row["operacoes_sem_pagamento"]) else 0,
                "percentual_operacoes_com_pagamento": self.safe_float(row["percentual_operacoes_com_pagamento"]) if pd.notna(row["percentual_operacoes_com_pagamento"]) else 0
            })
        
        # Processar histórico de inadimplência
        for _, row in resultados["historico_inadimplencia"].iterrows():
            dados_estruturados["historico_inadimplencia"].append({
                "ano_mes": self.safe_int(row["ano_mes"]),
                "total_operacoes": self.safe_int(row["total_operacoes"]),
                "operacoes_em_dia": self.safe_int(row["operacoes_em_dia"]),
                "operacoes_em_atraso": self.safe_int(row["operacoes_em_atraso"]),
                "percentual_operacoes_em_dia": self.safe_float(row["percentual_operacoes_em_dia"]),
                "maior_atraso": self.safe_float(row["maior_atraso"]) if pd.notna(row["maior_atraso"]) else 0,
                "saldo_em_atraso": self.safe_float(row["saldo_em_atraso"]) if pd.notna(row["saldo_em_atraso"]) else 0,
                "saldo_over90": self.safe_float(row["saldo_over90"]) if pd.notna(row["saldo_over90"]) else 0
            })
        
        # Processar evolução de provisões
        for _, row in resultados["evolucao_provisoes"].iterrows():
            dados_estruturados["evolucao_provisoes"].append({
                "ano_mes": self.safe_int(row["ano_mes"]),
                "provisao_total": self.safe_float(row["provisao_total"]),
                "provisao_anterior": self.safe_float(row["provisao_anterior"]),
                "variacao_provisao": self.safe_float(row["variacao_provisao"]),
                "variacao_percentual": self.safe_float(row["variacao_percentual"]) if pd.notna(row["variacao_percentual"]) else 0,
                "operacoes_melhoraram": self.safe_int(row["operacoes_melhoraram"]),
                "operacoes_pioraram": self.safe_int(row["operacoes_pioraram"]),
                "operacoes_mantiveram": self.safe_int(row["operacoes_mantiveram"])
            })
        
        # Calcular estatísticas adicionais
        logger.info("🧮 Calculando estatísticas adicionais")
        dados_estruturados["resumo_estatistico"] = self.calcular_estatisticas_adicionais(dados_estruturados)
        
        elapsed = time.time() - start_time
        logger.info(f"✅ Estruturação de dados concluída em {elapsed:.2f}s")
        
        return dados_estruturados
    
    def calcular_estatisticas_adicionais(self, dados: Dict[str, Any]) -> Dict[str, Any]:
        """
        Calcula estatísticas adicionais para enriquecer a análise
        
        Args:
            dados: Dados estruturados das consultas
            
        Returns:
            Dict: Estatísticas adicionais calculadas
        """
        start_time = time.time()
        logger.info("🧮 Iniciando cálculo de estatísticas adicionais")
        resumo = {}
        
        # Se não houver dados suficientes, retorna um resumo vazio
        if not dados["situacao_atual"] or not dados["evolucao_carteira"]:
            logger.warning("⚠️ Dados insuficientes para calcular estatísticas adicionais")
            return resumo
        
        # Análise de concentração da carteira
        if dados["concentracao_risco"]:
            maior_operacao = dados["concentracao_risco"][0]  # Já está ordenado por saldo_atual DESC
            resumo["maior_operacao"] = maior_operacao["titulo"]
            resumo["concentracao_maior_operacao"] = maior_operacao["percentual_carteira"]
            
            # Classificação da concentração
            if maior_operacao["percentual_carteira"] > 50:
                resumo["nivel_concentracao"] = "Muito alta"
            elif maior_operacao["percentual_carteira"] > 30:
                resumo["nivel_concentracao"] = "Alta"
            elif maior_operacao["percentual_carteira"] > 20:
                resumo["nivel_concentracao"] = "Moderada"
            else:
                resumo["nivel_concentracao"] = "Baixa"
            
            logger.info(f"📊 Concentração: {resumo.get('nivel_concentracao', 'N/A')} ({maior_operacao['percentual_carteira']}%)")
        
        # Análise de sazonalidade
        if dados["sazonalidade_pagamentos"]:
            # Identificar meses com maior amortização líquida
            meses_positivos = [item for item in dados["sazonalidade_pagamentos"] if item["media_amortizacao_liquida"] > 0]
            meses_negativos = [item for item in dados["sazonalidade_pagamentos"] if item["media_amortizacao_liquida"] < 0]
            
            if meses_positivos:
                mes_maior_amortizacao = max(meses_positivos, key=lambda x: x["media_amortizacao_liquida"])
                resumo["mes_maior_amortizacao"] = mes_maior_amortizacao["mes"]
                resumo["valor_maior_amortizacao"] = mes_maior_amortizacao["media_amortizacao_liquida"]
                logger.info(f"💰 Mês com maior amortização: {mes_maior_amortizacao['mes']} (R$ {mes_maior_amortizacao['media_amortizacao_liquida']:,.2f})")
            
            if meses_negativos:
                mes_maior_endividamento = min(meses_negativos, key=lambda x: x["media_amortizacao_liquida"])
                resumo["mes_maior_endividamento"] = mes_maior_endividamento["mes"]
                resumo["valor_maior_endividamento"] = mes_maior_endividamento["media_amortizacao_liquida"]
                logger.info(f"💸 Mês com maior endividamento: {mes_maior_endividamento['mes']} (R$ {mes_maior_endividamento['media_amortizacao_liquida']:,.2f})")
            
            # Classificação da sazonalidade
            if meses_positivos and meses_negativos:
                amplitude = abs(max([item["media_amortizacao_liquida"] for item in meses_positivos]) - 
                               min([item["media_amortizacao_liquida"] for item in meses_negativos]))
                media_saldo = dados["situacao_atual"]["saldo_total"] / 12  # Estimativa de média mensal
                
                if amplitude > media_saldo * 0.5:
                    resumo["nivel_sazonalidade"] = "Alta"
                elif amplitude > media_saldo * 0.2:
                    resumo["nivel_sazonalidade"] = "Moderada"
                else:
                    resumo["nivel_sazonalidade"] = "Baixa"
                
                logger.info(f"📈 Sazonalidade: {resumo.get('nivel_sazonalidade', 'N/A')} (amplitude: R$ {amplitude:,.2f})")
            else:
                resumo["nivel_sazonalidade"] = "Não identificada"
                logger.info("📈 Sazonalidade: Não identificada")
        
        # Análise de perfil de risco
        if dados["evolucao_rating"] and len(dados["evolucao_rating"]) >= 2:
            rating_atual = dados["evolucao_rating"][0]["faixa_risco"]
            rating_anterior = dados["evolucao_rating"][1]["faixa_risco"]
            
            # Verificar se houve melhora ou piora no rating
            if "BAIXÍSSIMO" in rating_atual and "BAIXÍSSIMO" not in rating_anterior:
                resumo["tendencia_rating"] = "Melhora significativa"
            elif "BAIXO" in rating_atual and ("MÉDIO" in rating_anterior or "ALTO" in rating_anterior):
                resumo["tendencia_rating"] = "Melhora moderada"
            elif "MÉDIO" in rating_atual and "ALTO" in rating_anterior:
                resumo["tendencia_rating"] = "Melhora leve"
            elif "ALTO" in rating_atual and ("MÉDIO" in rating_anterior or "BAIXO" in rating_anterior):
                resumo["tendencia_rating"] = "Piora moderada"
            elif "ALTO" in rating_atual and "BAIXÍSSIMO" in rating_anterior:
                resumo["tendencia_rating"] = "Piora significativa"
            else:
                resumo["tendencia_rating"] = "Estável"
            
            logger.info(f"⭐ Tendência de rating: {resumo.get('tendencia_rating', 'N/A')} (atual: {rating_atual}, anterior: {rating_anterior})")
        
        # Análise de capacidade de pagamento
        if dados["capacidade_pagamento"] and dados["distribuicao_vencimento"]:
            pagamentos_90dias = dados["capacidade_pagamento"][0]["pagamentos_90dias"]
            media_mensal = dados["capacidade_pagamento"][0]["media_mensal_proximos_3meses"]
            
            # Estimar capacidade de pagamento com base no histórico
            if dados["tendencia_pagamentos"] and len(dados["tendencia_pagamentos"]) >= 3:
                media_pagamentos_3m = sum([item["total_pagamentos"] for item in dados["tendencia_pagamentos"][:3]]) / 3
                
                if media_pagamentos_3m > 0:
                    if media_mensal > media_pagamentos_3m * 1.5:
                        resumo["pressao_pagamento_curto_prazo"] = "Alta"
                    elif media_mensal > media_pagamentos_3m:
                        resumo["pressao_pagamento_curto_prazo"] = "Moderada"
                    else:
                        resumo["pressao_pagamento_curto_prazo"] = "Baixa"
                    
                    logger.info(f"💵 Pressão de pagamento: {resumo.get('pressao_pagamento_curto_prazo', 'N/A')} (média mensal próximos 3 meses: R$ {media_mensal:,.2f}, média histórica: R$ {media_pagamentos_3m:,.2f})")
                else:
                    resumo["pressao_pagamento_curto_prazo"] = "Não determinada"
                    logger.info("💵 Pressão de pagamento: Não determinada")
        
        # Análise de inadimplência
        if dados["historico_inadimplencia"] and len(dados["historico_inadimplencia"]) >= 6:
            # Verificar se houve inadimplência nos últimos 6 meses
            inadimplencia_recente = any(item["operacoes_em_atraso"] > 0 for item in dados["historico_inadimplencia"][:6])
            
            if inadimplencia_recente:
                resumo["historico_inadimplencia"] = "Com ocorrências recentes"
                logger.info("⚠️ Histórico de inadimplência: Com ocorrências recentes")
            else:
                resumo["historico_inadimplencia"] = "Sem ocorrências recentes"
                logger.info("✅ Histórico de inadimplência: Sem ocorrências recentes")
        
        # Análise de estágios IFRS 9
        if dados["evolucao_estagios"] and len(dados["evolucao_estagios"]) >= 2:
            estagio_atual = dados["evolucao_estagios"][0]
            estagio_anterior = dados["evolucao_estagios"][1]
            
            # Verificar migração entre estágios
            if estagio_atual["perc_estagio1"] < estagio_anterior["perc_estagio1"]:
                resumo["tendencia_estagio"] = "Deterioração"
                logger.info(f"⬇️ Tendência de estágio: Deterioração (E1: {estagio_atual['perc_estagio1']}% vs {estagio_anterior['perc_estagio1']}%)")
            elif estagio_atual["perc_estagio1"] > estagio_anterior["perc_estagio1"]:
                resumo["tendencia_estagio"] = "Melhoria"
                logger.info(f"⬆️ Tendência de estágio: Melhoria (E1: {estagio_atual['perc_estagio1']}% vs {estagio_anterior['perc_estagio1']}%)")
            else:
                resumo["tendencia_estagio"] = "Estável"
                logger.info(f"➡️ Tendência de estágio: Estável (E1: {estagio_atual['perc_estagio1']}%)")
        
        # Análise de distribuição de vencimentos
        if dados["distribuicao_vencimento"]:
            dv = dados["distribuicao_vencimento"]
            
            # Classificar o perfil de vencimentos
            if dv["percentual_curto_prazo"] > 50:
                resumo["perfil_vencimentos"] = "Concentrado no curto prazo"
            elif dv["percentual_longo_prazo"] > 60:
                resumo["perfil_vencimentos"] = "Concentrado no longo prazo"
            else:
                resumo["perfil_vencimentos"] = "Equilibrado"
            
            logger.info(f"📅 Perfil de vencimentos: {resumo.get('perfil_vencimentos', 'N/A')} (CP: {dv['percentual_curto_prazo']}%, MP: {dv['percentual_medio_prazo']}%, LP: {dv['percentual_longo_prazo']}%)")
        
        elapsed = time.time() - start_time
        logger.info(f"✅ Cálculo de estatísticas adicionais concluído em {elapsed:.2f}s")
        
        return resumo
    
    def gerar_analise_llm(self, dados_estruturados: Dict[str, Any]) -> str:
        """
        Envia os dados estruturados para o modelo LLM e retorna a análise
        
        Args:
            dados_estruturados: Dados estruturados para análise
            
        Returns:
            str: Análise gerada pelo modelo LLM
        """
        start_time = time.time()
        logger.info("🧠 Iniciando geração de análise com modelo LLM")
        
        # Formatar valores monetários
        def formatar_moeda(valor):
            if valor is None or valor == 0:
                return "R$ 0,00"
            return f"R$ {valor:,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")
        
        # Formatar percentuais
        def formatar_percentual(valor):
            if valor is None:
                return "0,00%"
            return f"{valor:.2f}%".replace(".", ",")
        
        # Obter nome do associado e CPF/CNPJ para o cabeçalho
        nome_associado = "Não informado"
        cpf_cnpj = dados_estruturados["perfil_associado"].get("cpf_cnpj", "")
        
        if "info_associado" in dados_estruturados and dados_estruturados["info_associado"].get("nome"):
            nome_associado = dados_estruturados["info_associado"].get("nome")
            logger.info(f"👤 Gerando análise para: {nome_associado} ({cpf_cnpj})")
        
        # Construir o prompt para análise técnica do histórico de crédito
        logger.info("📝 Construindo prompt para o modelo LLM")
        prompt = f"""
        # ANÁLISE TÉCNICA DO HISTÓRICO DE CRÉDITO

        ## ASSOCIADO: {nome_associado} - CPF/CNPJ: {cpf_cnpj}

        Você é um analista financeiro especializado em análise de crédito e comportamento financeiro de associados de cooperativas de crédito. Foi solicitado que você elabore uma análise técnica focada exclusivamente no histórico de crédito do associado, analisando seu comportamento de pagamento, evolução da carteira, concentração de risco e outros indicadores relevantes.

        ## PERFIL DO ASSOCIADO

        **CPF/CNPJ:** {dados_estruturados["perfil_associado"]["cpf_cnpj"]}  
        **Nome do Associado:** {nome_associado}  
        **Tipo de Pessoa:** {dados_estruturados["perfil_associado"]["tipo_pessoa"]}  
        **Segmento:** {dados_estruturados["perfil_associado"]["segmento_assoc"]}  
        **Subsegmento:** {dados_estruturados["perfil_associado"]["subsegmento"]}  
        **Atividade:** {dados_estruturados["perfil_associado"]["desc_atividade"]}  
        **Tempo de Relacionamento:** {dados_estruturados["perfil_associado"]["tempo_relacionamento"]}  

        ## SITUAÇÃO ATUAL

        **Data de referência:** {dados_estruturados["situacao_atual"]["ano_mes"]}  
        **Saldo Total:** {formatar_moeda(dados_estruturados["situacao_atual"]["saldo_total"])}  
        **Saldo Vencido:** {formatar_moeda(dados_estruturados["situacao_atual"]["saldo_vencido"])}  
        **Provisão Total:** {formatar_moeda(dados_estruturados["situacao_atual"]["provisao_total"])}  
        **Percentual de Provisão:** {formatar_percentual(dados_estruturados["situacao_atual"]["percentual_provisao"])}  
        **Faixa de Risco:** {dados_estruturados["situacao_atual"]["faixa_risco"]}  
        **Estágio Predominante:** {dados_estruturados["situacao_atual"]["estagio_predominante"]}  
        **Quantidade de Operações:** {dados_estruturados["situacao_atual"]["qtd_operacoes"]}  

        ## EVOLUÇÃO DA CARTEIRA

        """
        
        # Adicionar tabela de evolução da carteira
        prompt += """
        | Mês/Ano | Saldo Total | Saldo Vencido | Provisão Total | Faixa de Risco |
        |---------|-------------|---------------|----------------|----------------|
        """
        
        # Limitar a 6 meses para não sobrecarregar o prompt
        for item in dados_estruturados["evolucao_carteira"][:6]:
            ano_mes = str(item["ano_mes"])
            mes = ano_mes[-2:]
            ano = ano_mes[:-2]
            data_formatada = f"{mes}/{ano}"
            
            prompt += f"| {data_formatada} | {formatar_moeda(item['saldo_total'])} | {formatar_moeda(item['saldo_vencido'])} | {formatar_moeda(item['provisao_total'])} | {item['faixa_risco']} |\n"
        
        # Adicionar distribuição por tipo de produto
        prompt += """

        ## DISTRIBUIÇÃO POR TIPO DE PRODUTO

        | Tipo de Produto | Saldo Atual | Percentual | Provisão Atual | Qtd. Operações |
        |----------------|-------------|------------|----------------|----------------|
        """
        
        for item in dados_estruturados["distribuicao_tipo_produto"]:
            prompt += f"| {item['tipo_produto']} | {formatar_moeda(item['saldo_atual'])} | {formatar_percentual(item['percentual'])} | {formatar_moeda(item['provisao_atual'])} | {item['qtd_operacoes']} |\n"
        
        # Adicionar distribuição por vencimento
        dv = dados_estruturados["distribuicao_vencimento"]
        prompt += f"""

        ## DISTRIBUIÇÃO POR VENCIMENTO

        | Prazo | Valor | Percentual |
        |-------|-------|------------|
        | Curto Prazo (até 90 dias) | {formatar_moeda(dv['ate_90_dias'])} | {formatar_percentual(dv['percentual_curto_prazo'])} |
        | Médio Prazo (91 a 360 dias) | {formatar_moeda(dv['de_91_a_360_dias'])} | {formatar_percentual(dv['percentual_medio_prazo'])} |
        | Longo Prazo (acima de 361 dias) | {formatar_moeda(dv['acima_361_dias'])} | {formatar_percentual(dv['percentual_longo_prazo'])} |
        """
        
        # Adicionar concentração de risco (top 3 operações)
        prompt += """

        ## CONCENTRAÇÃO DE RISCO (Maiores operações)

        | Título | Produto | Saldo Atual | % Carteira | Provisão | Faixa de Risco | Estágio |
        |--------|---------|-------------|------------|----------|----------------|---------|
        """
        
        for item in dados_estruturados["concentracao_risco"][:3]:
            produto = f"{item['prod_grupo_1']} - {item['prod_grupo_2']}"
            prompt += f"| {item['titulo']} | {produto} | {formatar_moeda(item['saldo_atual'])} | {formatar_percentual(item['percentual_carteira'])} | {formatar_moeda(item['prov_atual'])} | {item['fx_risco_at']} | {item['estagio_at']} |\n"
        
        # Adicionar histórico de inadimplência (últimos 3 meses)
        prompt += """

        ## HISTÓRICO DE INADIMPLÊNCIA (Últimos 3 meses)

        | Mês/Ano | % Operações em Dia | Operações em Atraso | Saldo em Atraso | Maior Atraso |
        |---------|---------------------|---------------------|-----------------|--------------|
        """
        
        for item in dados_estruturados["historico_inadimplencia"][:3]:
            ano_mes = str(item["ano_mes"])
            mes = ano_mes[-2:]
            ano = ano_mes[:-2]
            data_formatada = f"{mes}/{ano}"
            
            prompt += f"| {data_formatada} | {formatar_percentual(item['percentual_operacoes_em_dia'])} | {item['operacoes_em_atraso']} | {formatar_moeda(item['saldo_em_atraso'])} | {item['maior_atraso']} dias |\n"
        
        # Adicionar evolução de estágios IFRS 9 (últimos 3 meses)
        prompt += """

        ## EVOLUÇÃO DE ESTÁGIOS IFRS 9 (Últimos 3 meses)

        | Mês/Ano | % Estágio 1 | % Estágio 2 | % Estágio 3 |
        |---------|-------------|-------------|-------------|
        """
        
        for item in dados_estruturados["evolucao_estagios"][:3]:
            ano_mes = str(item["ano_mes"])
            mes = ano_mes[-2:]
            ano = ano_mes[:-2]
            data_formatada = f"{mes}/{ano}"
            
            prompt += f"| {data_formatada} | {formatar_percentual(item['perc_estagio1'])} | {formatar_percentual(item['perc_estagio2'])} | {formatar_percentual(item['perc_estagio3'])} |\n"
        
        # Adicionar sazonalidade de pagamentos
        prompt += """

        ## SAZONALIDADE DE PAGAMENTOS

        | Mês | Média Pagamentos | Média Novos Débitos | Média Amortização Líquida |
        |-----|------------------|---------------------|---------------------------|
        """
        
        # Mapear números de meses para nomes
        nomes_meses = {
            '01': 'Janeiro', '02': 'Fevereiro', '03': 'Março', '04': 'Abril',
            '05': 'Maio', '06': 'Junho', '07': 'Julho', '08': 'Agosto',
            '09': 'Setembro', '10': 'Outubro', '11': 'Novembro', '12': 'Dezembro'
        }
        
        for item in dados_estruturados["sazonalidade_pagamentos"]:
            mes_num = item["mes"]
            mes_nome = nomes_meses.get(mes_num, mes_num)
            
            prompt += f"| {mes_nome} | {formatar_moeda(item['media_pagamentos_mensal'])} | {formatar_moeda(item['media_novos_debitos_mensal'])} | {formatar_moeda(item['media_amortizacao_liquida'])} |\n"
        
        # Adicionar resumo estatístico
        prompt += """

        ## RESUMO ESTATÍSTICO

        """
        
        for chave, valor in dados_estruturados["resumo_estatistico"].items():
            chave_formatada = chave.replace("_", " ").title()
            prompt += f"**{chave_formatada}:** {valor}  \n"
        
        # Adicionar informações do cônjuge, se disponíveis
        if "analises_relacionadas" in dados_estruturados and "conjuge" in dados_estruturados["analises_relacionadas"]:
            conjuge = dados_estruturados["analises_relacionadas"]["conjuge"]
            if conjuge["status"] == "success" and "dados" in conjuge:
                try:
                    dados_conjuge = conjuge["dados"]
                    logger.info(f"👨‍👩‍👧‍👦 Adicionando análise do cônjuge ao prompt")
                    prompt += f"""

            ## ANÁLISE COMPARATIVA - CÔNJUGE

            **Nome:** {dados_conjuge.get("nome", "Não informado")}  
            **CPF:** {dados_conjuge.get("cpf", "Não informado")}

            ### Endividamento do Cônjuge

            **Saldo Total:** {formatar_moeda(dados_conjuge["situacao_atual"].get("saldo_total", 0))}  
            **Saldo Vencido:** {formatar_moeda(dados_conjuge["situacao_atual"].get("saldo_vencido", 0))}  
            **Provisão Total:** {formatar_moeda(dados_conjuge["situacao_atual"].get("provisao_total", 0))}  
            **Faixa de Risco:** {dados_conjuge["situacao_atual"].get("faixa_risco", "Não informado")}  
            **Quantidade de Operações:** {dados_conjuge["situacao_atual"].get("qtd_operacoes", 0)}  

            ### Principais Produtos do Cônjuge
            """
                    # Adicionar até 3 principais produtos do cônjuge
                    for i, item in enumerate(dados_conjuge.get("distribuicao_tipo_produto", [])[:3]):
                        prompt += f"""
            {i+1}. {item.get('tipo_produto', 'Não informado')}: {formatar_moeda(item.get('saldo_atual', 0))} ({formatar_percentual(item.get('percentual', 0))})"""
                except Exception as e:
                    logger.warning(f"⚠️ Erro ao processar dados do cônjuge para o prompt: {str(e)}")
                    prompt += f"""

            ## ANÁLISE COMPARATIVA - CÔNJUGE

            **Nome:** {conjuge.get("nome", "Não informado")}  
            **CPF:** {conjuge.get("cpf", "Não informado")}

            Não foi possível processar os dados detalhados do cônjuge.
            """
        
        # Adicionar informações do grupo econômico, se disponíveis
        if "analises_relacionadas" in dados_estruturados and "grupo_economico" in dados_estruturados["analises_relacionadas"]:
            grupo = dados_estruturados["analises_relacionadas"]["grupo_economico"]
            if grupo["status"] == "success" and "dados" in grupo:
                try:
                    dados_grupo = grupo["dados"]
                    logger.info(f"🏢 Adicionando análise do grupo econômico ao prompt")
                    prompt += f"""

            ## ANÁLISE DO GRUPO ECONÔMICO

            **Código do Grupo:** {dados_grupo["cod_grupo"]}  
            **Quantidade de Membros:** {dados_grupo["qtd_membros"]}  
            **Saldo Total do Grupo:** {formatar_moeda(dados_grupo["saldo_total_grupo"])}  
            **Saldo Vencido do Grupo:** {formatar_moeda(dados_grupo["saldo_vencido_grupo"])}  
            **Provisão Total do Grupo:** {formatar_moeda(dados_grupo["provisao_total_grupo"])}  
            **Saldo Médio por Membro:** {formatar_moeda(dados_grupo["saldo_medio_membros"])}  
            **Total de Operações no Grupo:** {dados_grupo["total_operacoes"]}  

            ### Distribuição por Tipo de Produto do Grupo

            | Tipo de Produto | Saldo Atual | Percentual | Qtd. Operações |
            |----------------|-------------|------------|----------------|
            """
                    
                    # Adicionar distribuição por tipo de produto do grupo em formato de tabela
                    for item in dados_grupo["distribuicao_tipo_produto"][:5]:
                        prompt += f"| {item['tipo_produto']} | {formatar_moeda(item['saldo_atual'])} | {formatar_percentual(item['percentual'])} | {item['qtd_operacoes']} |\n"
                    
                    # Adicionar lista de membros do grupo
                    if "membros_info" in dados_grupo and len(dados_grupo["membros_info"]) > 0:
                        prompt += """
                        
            ### Membros do Grupo Econômico
            """
                        
                        for i, membro in enumerate(dados_grupo["membros_info"][:5]):
                            if membro["cpf_cnpj"] != dados_estruturados["perfil_associado"]["cpf_cnpj"]:
                                prompt += f"""
            {i+1}. {membro['nome']} ({membro['cpf_cnpj']}) - {membro['tipo_pessoa']}"""
                except Exception as e:
                    logger.warning(f"⚠️ Erro ao processar dados do grupo econômico para o prompt: {str(e)}")
                    prompt += f"""

            ## ANÁLISE DO GRUPO ECONÔMICO

            **Código do Grupo:** {grupo["dados"].get("cod_grupo", "Não informado")}

            Não foi possível processar os dados detalhados do grupo econômico.
            """
        
        # Adicionar solicitação de análise técnica focada no histórico de crédito
        prompt += """

        # SOLICITAÇÃO DE ANÁLISE TÉCNICA DO HISTÓRICO DE CRÉDITO

        Com base nos dados apresentados acima, elabore uma análise técnica detalhada focada exclusivamente no histórico de crédito do associado. Sua análise deve ser estruturada da seguinte forma:

        ## 1. INTRODUÇÃO
        
        Breve introdução identificando o associado pelo nome e CPF/CNPJ e explicando que esta é uma análise focada exclusivamente no histórico de crédito com a cooperativa.

        ## 2. PERFIL DO ASSOCIADO E RELACIONAMENTO

        - Análise do perfil do associado com base nos dados disponíveis
        - Avaliação do tempo de relacionamento com a cooperativa
        - Identificação do segmento e subsegmento do associado
        - Relevância do associado para a cooperativa

        ## 3. SITUAÇÃO ATUAL DA CARTEIRA

        - Análise detalhada da composição atual da carteira
        - Avaliação do nível de risco e estágio predominante
        - Interpretação do percentual de provisão
        - Análise da distribuição por tipo de produto
        - Avaliação da concentração de risco nas principais operações

        ## 4. EVOLUÇÃO HISTÓRICA DA CARTEIRA

        - Análise da evolução do saldo total ao longo do tempo
        - Identificação de tendências de crescimento ou redução
        - Avaliação da evolução do risco e provisões
        - Análise da evolução dos estágios IFRS 9
        - Identificação de padrões cíclicos ou sazonais

        ## 5. COMPORTAMENTO DE PAGAMENTO

        - Análise do histórico de inadimplência
        - Avaliação da pontualidade nos pagamentos
        - Identificação de padrões sazonais de pagamento
        - Análise da capacidade de pagamento
        - Avaliação da distribuição por vencimento e seu impacto no fluxo de caixa

        ## 6. INDICADORES DE ALERTA E OPORTUNIDADES

        - Identificação de sinais de alerta no comportamento de crédito
        - Avaliação de oportunidades para melhorar o relacionamento
        - Recomendações para gestão do risco
        - Sugestões de produtos adequados ao perfil do associado
        """
        
        # Adicionar seções para análise do cônjuge e grupo econômico, se aplicável
        if ("analises_relacionadas" in dados_estruturados and 
            ("conjuge" in dados_estruturados["analises_relacionadas"] and dados_estruturados["analises_relacionadas"]["conjuge"].get("status") == "success" or
             "grupo_economico" in dados_estruturados["analises_relacionadas"] and dados_estruturados["analises_relacionadas"]["grupo_economico"].get("status") == "success")):
            
            prompt += """

        ## 7. ANÁLISES COMPLEMENTARES
        """
            
            if "conjuge" in dados_estruturados["analises_relacionadas"] and dados_estruturados["analises_relacionadas"]["conjuge"].get("status") == "success":
                prompt += """

        ### 7.1 Análise Resumida do Cônjuge
        - Breve análise da situação do cônjuge
        - Comparação com o perfil do associado principal
        - Identificação de padrões comuns ou divergentes
        - Avaliação do risco conjunto
        """
            
            if "grupo_economico" in dados_estruturados["analises_relacionadas"] and dados_estruturados["analises_relacionadas"]["grupo_economico"].get("status") == "success":
                prompt += """

        ### 7.2 Análise Resumida do Grupo Econômico
        - Breve análise da situação do grupo econômico
        - Relevância do associado principal dentro do grupo
        - Avaliação do risco do grupo como um todo
        - Identificação de oportunidades no grupo
        """
            
            # Adicionar seção para análise consolidada
            prompt += """

        ## 8. ANÁLISE CONSOLIDADA
        - Visão integrada considerando o associado, cônjuge e/ou grupo econômico
        - Avaliação de riscos sistêmicos e interconexões
        - Identificação de vulnerabilidades compartilhadas
        - Avaliação do risco de contágio financeiro entre os membros relacionados
        """
            
            # Renumerar a conclusão
            prompt += """

        ## 9. CONCLUSÃO
        - Síntese técnica do perfil de crédito do associado
        - Avaliação objetiva dos principais riscos e oportunidades identificados
        - Perspectivas futuras com base nas tendências observadas
        """
        else:
            # Se não houver análises complementares, manter a numeração original
            prompt += """

        ## 7. CONCLUSÃO
        - Síntese técnica do perfil de crédito do associado
        - Avaliação objetiva dos principais riscos e oportunidades identificados
        - Perspectivas futuras com base nas tendências observadas
        """
        
        # Finalizar o prompt com instruções adicionais
        prompt += """

        ---

        **Importante:**

        1. Mantenha o foco exclusivamente na análise técnica do histórico de crédito, sem abordar aspectos que não estejam evidenciados nos dados apresentados.
        
        2. Utilize linguagem técnica apropriada para análise de crédito, com foco em dados quantitativos e padrões objetivos.
        
        3. Apresente dados quantitativos sempre que possível, incluindo percentuais, valores e comparações objetivas.
        
        4. Identifique padrões e correlações entre diferentes aspectos do comportamento financeiro.
        
        5. Organize sua análise em seções bem delimitadas, utilizando formatação adequada para facilitar a consulta.
        
        6. Evite fazer suposições sobre o perfil do associado que não estejam diretamente evidenciadas nos dados apresentados.
        
        7. Lembre-se que esta análise é uma skill específica de um agente de IA analista de crédito, focada exclusivamente na análise do histórico de crédito. Outras skills complementares analisarão outros aspectos como SCR e perfil sociodemográfico do associado.
        """
        
        # Implementar mecanismo de retry com backoff exponencial
        max_retries = self.max_retries
        retry_delay = 10  # segundos
        
        logger.info(f"🤖 Enviando prompt para o modelo LLM (tamanho: {len(prompt)} caracteres)")
        
        for attempt in range(max_retries):
            try:
                # Registrar tentativa
                logger.info(f"🔄 Tentativa {attempt+1}/{max_retries} de chamada ao modelo LLM")
                
                # Monitorar recursos antes da chamada
                resource_monitor.check_resources(force=True)
                
                # Registrar início da chamada
                call_start = time.time()
                
                # Chamar o modelo usando a API OpenAI configurada para Databricks
                response = self.openai_client.chat.completions.create(
                    model="databricks-claude-3-7-sonnet",
                    messages=[
                        {"role": "system", "content": "Você é um analista financeiro especializado em análise de crédito e comportamento financeiro de associados de cooperativas de crédito. Sua análise deve ser técnica, detalhada e baseada em evidências, com foco exclusivo no histórico de crédito, sem abordar aspectos que não estejam evidenciados nos dados apresentados."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.0,
                    max_tokens=8000
                )
                
                # Registrar tempo de resposta
                call_duration = time.time() - call_start
                logger.info(f"✅ Resposta do modelo LLM recebida em {call_duration:.2f}s")
                
                # Extrair e retornar a resposta
                analise = response.choices[0].message.content
                
                # Registrar estatísticas da resposta
                logger.info(f"📊 Análise gerada com {len(analise)} caracteres")
                
                # Tempo total de geração
                elapsed = time.time() - start_time
                logger.info(f"✅ Análise LLM concluída em {elapsed:.2f}s")
                
                return analise
                
            except Exception as e:
                if "timeout" in str(e).lower() and attempt < max_retries - 1:
                    # Se for timeout e não for a última tentativa, esperar e tentar novamente
                    logger.warning(f"⚠️ Tentativa {attempt+1} falhou com timeout. Tentando novamente em {retry_delay} segundos...")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # Backoff exponencial
                else:
                    # Se for outro erro ou a última tentativa, tentar com um prompt mais curto
                    logger.error(f"❌ Erro na chamada ao modelo LLM: {str(e)}")
                    logger.warning("⚠️ Tentando com prompt reduzido como fallback")
                    
                    try:
                        # Criar uma versão reduzida do prompt
                        prompt_reduzido = prompt.split("# SOLICITAÇÃO DE ANÁLISE TÉCNICA DO HISTÓRICO DE CRÉDITO")[0] + """
                        
                        # SOLICITAÇÃO DE ANÁLISE TÉCNICA DO HISTÓRICO DE CRÉDITO
                        
                        Com base nos dados apresentados acima, elabore uma análise técnica focada exclusivamente no histórico de crédito do associado, abordando:
                        
                        1. Introdução: Identificando o associado pelo nome e CPF/CNPJ
                        2. Perfil do Associado: Análise do perfil e relacionamento com a cooperativa
                        3. Situação Atual: Análise da composição atual da carteira e nível de risco
                        4. Evolução Histórica: Análise da evolução do saldo, risco e provisões
                        5. Comportamento de Pagamento: Análise do histórico de inadimplência e sazonalidade
                        6. Indicadores de Alerta: Identificação de sinais de alerta e oportunidades
                        7. Análises Complementares: Breve análise do cônjuge e/ou grupo econômico (se aplicável)
                        8. Conclusão: Síntese técnica do perfil de crédito
                        
                        Mantenha o foco nos dados técnicos do histórico de crédito, sem abordar aspectos que não estejam evidenciados nos dados apresentados.
                        """
                        
                        logger.info("🔄 Tentando modelo alternativo com prompt reduzido")
                        response = self.openai_client.chat.completions.create(
                            model="databricks-llama-4-maverick",
                            messages=[
                                {"role": "system", "content": "Você é um analista financeiro especializado em análise de crédito e comportamento financeiro de associados de cooperativas de crédito."},
                                {"role": "user", "content": prompt_reduzido}
                            ],
                            temperature=0.0,
                            max_tokens=8000
                        )
                        
                        analise = response.choices[0].message.content
                        logger.info("✅ Análise gerada com modelo alternativo")
                        return analise
                        
                    except Exception as e2:
                        logger.error(f"❌ Erro no modelo de fallback: {str(e2)}")
                        # Em caso de falha total, retornar uma análise básica com os dados principais
                        nome_associado = dados_estruturados.get("info_associado", {}).get("nome", "Associado")
                        cpf_cnpj = dados_estruturados["perfil_associado"].get("cpf_cnpj", "")
                        saldo_total = formatar_moeda(dados_estruturados["situacao_atual"].get("saldo_total", 0))
                        faixa_risco = dados_estruturados["situacao_atual"].get("faixa_risco", "Não disponível")
                        
                        logger.warning("⚠️ Gerando análise básica de emergência")
                        return f"""
                        # ANÁLISE TÉCNICA DO HISTÓRICO DE CRÉDITO - {nome_associado} (CPF/CNPJ: {cpf_cnpj})
                        
                        ## ANÁLISE BÁSICA DE EMERGÊNCIA
                        
                        Não foi possível gerar uma análise completa devido a limitações técnicas. Abaixo estão os principais indicadores do histórico de crédito:
                        
                        - Saldo Total: {saldo_total}
                        - Faixa de Risco: {faixa_risco}
                        - Quantidade de Operações: {dados_estruturados["situacao_atual"].get("qtd_operacoes", 0)}
                        - Percentual de Provisão: {formatar_percentual(dados_estruturados["situacao_atual"].get("percentual_provisao", 0))}
                        
                        ## Principais Produtos
                        
                        {', '.join([f"{item['tipo_produto']}: {formatar_percentual(item['percentual'])}" for item in dados_estruturados["distribuicao_tipo_produto"][:3]])}
                        
                        ## Indicadores de Alerta
                        
                        {', '.join([f"{k.replace('_', ' ').title()}: {v}" for k, v in dados_estruturados["resumo_estatistico"].items()][:5])}
                        
                        Esta é uma análise técnica focada exclusivamente no histórico de crédito do associado com a cooperativa.
                        """
        
        # Se todas as tentativas falharem
        logger.critical("❌ Todas as tentativas de geração de análise falharam")
        return "Erro ao gerar análise com o modelo LLM: Todas as tentativas falharam."

# Função para uso em notebooks Databricks
def analisar_historico_credito_associado(cpf_cnpj: str) -> Dict[str, Any]:
    """
    Função de conveniência para análise do histórico de crédito de um associado.
    
    Args:
        cpf_cnpj: CPF ou CNPJ do associado
        
    Returns:
        Dict: Dicionário com os resultados da análise
    """
    logger.info(f"🚀 Iniciando análise do histórico de crédito para {cpf_cnpj} via função de conveniência")
    analisador = AnalisadorCredito()
    resultado = analisador.analisar_historico_credito_associado(cpf_cnpj)
    logger.info(f"✅ Análise concluída com status: {resultado.get('status', 'desconhecido')}")
    return resultado

# Função principal para teste da análise de histórico de crédito
def main():
    """
    Função principal para teste da análise de histórico de crédito
    """
    logger.info("🚀 Iniciando execução principal do AnalisadorCredito")
    
    # Obter o CPF/CNPJ do widget (para teste interativo)
    try:
        cpf_cnpj = dbutils.widgets.get("cpf_cnpj")
        logger.info(f"📋 CPF/CNPJ obtido do widget: {cpf_cnpj}")
    except:
        # Para testes diretos sem widget
        cpf_cnpj = "07333946126"  # CPF/CNPJ de exemplo
        logger.info(f"📋 Usando CPF/CNPJ de exemplo: {cpf_cnpj}")
    
    # Realizar a análise
    start_time = time.time()
    analisador = AnalisadorCredito()
    resultado = analisador.analisar_historico_credito_associado(cpf_cnpj)
    elapsed = time.time() - start_time
    
    # Exibir o resultado
    if resultado["status"] == "success":
        # Verificar se há análises relacionadas
        tem_conjuge = "analises_relacionadas" in resultado["dados"] and "conjuge" in resultado["dados"]["analises_relacionadas"]
        tem_grupo = "analises_relacionadas" in resultado["dados"] and "grupo_economico" in resultado["dados"]["analises_relacionadas"]
        
        logger.info(f"✅ Análise concluída com sucesso em {elapsed:.2f}s")
        logger.info(f"👨‍👩‍👧‍👦 Análise inclui dados do cônjuge: {'Sim' if tem_conjuge else 'Não'}")
        logger.info(f"🏢 Análise inclui dados do grupo econômico: {'Sim' if tem_grupo else 'Não'}")
        logger.info(f"📊 Foram gerados {len(resultado.get('graficos', []))} gráficos")
        
        # Exibir a análise formatada
        try:
            # Criar HTML com análise e gráficos
            html_output = f"""
            <h2>Análise Técnica do Histórico de Crédito - {cpf_cnpj}</h2>
            {'<p><strong>Análise inclui dados do cônjuge</strong></p>' if tem_conjuge else ''}
            {'<p><strong>Análise inclui dados do grupo econômico</strong></p>' if tem_grupo else ''}
            
            <div style='white-space: pre-wrap; font-family: Arial, sans-serif; line-height: 1.6; max-width: 1200px; margin: 0 auto;'>
                {resultado['analise']}
            </div>
            
            <h3>Gráficos Gerados</h3>
            <div style='display: flex; flex-wrap: wrap; gap: 20px;'>
            """
            
            # Adicionar gráficos ao HTML
            for grafico in resultado.get("graficos_base64", []):
                html_output += f"""
                <div style='margin-bottom: 30px; width: 100%;'>
                    <h4>{grafico['titulo']}</h4>
                    <img src="data:image/png;base64,{grafico['base64']}" style='max-width: 100%; height: auto;'>
                    <p><em>{grafico['descricao']}</em></p>
                </div>
                """
            
            html_output += "</div>"
            
            displayHTML(html_output)
            logger.info("📄 Análise e gráficos exibidos com sucesso na interface HTML")
        except:
            # Fallback para ambientes sem displayHTML
            print(f"Análise Técnica do Histórico de Crédito - {cpf_cnpj}")
            print(f"Status: {resultado['status']}")
            print(resultado['analise'])
            print(f"\nForam gerados {len(resultado.get('graficos', []))} gráficos no diretório: {resultado.get('graficos', [{}])[0].get('caminho', '').rsplit('/', 1)[0] if resultado.get('graficos') else ''}")
            logger.info("📄 Análise exibida como texto no console")
    else:
        # Exibir mensagem de erro
        try:
            displayHTML(f"<h2>Erro na Análise de Histórico de Crédito</h2><div>{resultado['message']}</div>")
            logger.error(f"❌ Erro na análise: {resultado['message']}")
        except:
            print(f"Erro na Análise de Histórico de Crédito: {resultado['message']}")
            logger.error(f"❌ Erro na análise: {resultado['message']}")

# Se o script for executado diretamente (não importado)
if __name__ == "__main__":
    logger.info("🏁 Executando AnalisadorCredito como script principal")
    main()
}

PIPELINE FINAL ATUAL{
# Arquivo: pipeline_analise_credito_v5.py
# Pipeline avançado para orquestração de análises de crédito com suporte aprimorado para PF e PJ
import os
import sys
import time
import json
import re
import logging
import traceback
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Union
import concurrent.futures
import base64
import io
from openai import OpenAI
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # Backend não-interativo para ambientes sem display

# Importar os módulos de análise
from analise_perfil import AnalisadorPerfilAssociado
from analise_carteira_credito import AnalisadorCredito
from analise_scr import AnalisadorSCR

# Tentar importar bibliotecas para geração de PDF
try:
    import pdfkit
    has_pdfkit = True
except ImportError:
    has_pdfkit = False
    print("AVISO: pdfkit não está instalado. Os relatórios serão salvos apenas como HTML.")
    print("Para instalar pdfkit, execute: %pip install pdfkit")
    print("Para instalar wkhtmltopdf (necessário para pdfkit), execute: %sh apt-get update && apt-get install -y wkhtmltopdf")

from io import BytesIO

# Configuração de logging avançada
def setup_logging(level=logging.INFO):
    """Configura o sistema de logging com formatação avançada"""
    logger = logging.getLogger("PipelineCredito")
    logger.setLevel(level)
    
    # Limpar handlers existentes
    if logger.handlers:
        logger.handlers = []
    
    # Handler para console
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(level)
    
    # Formatação detalhada
    log_format = '%(asctime)s [%(levelname)s] %(name)s:%(lineno)d - %(message)s'
    formatter = logging.Formatter(log_format)
    console_handler.setFormatter(formatter)
    
    logger.addHandler(console_handler)
    
    # Handler para arquivo
    try:
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        file_handler = logging.FileHandler(
            f"logs/pipeline_credito_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        )
        file_handler.setLevel(level)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
    except:
        pass  # Ignora se não puder criar arquivo de log
    
    return logger

# Inicializar logger
logger = setup_logging()

class PipelineAnaliseCredito:
    """
    Pipeline avançado para orquestração de análises de crédito integradas.
    Combina análises de perfil, carteira e SCR para gerar um relatório completo.
    Suporta análises diferenciadas para PF e PJ.
    """
    
    def __init__(self, output_dir: Optional[str] = None):
        """
        Inicializa o pipeline com configurações e analisadores.
        
        Args:
            output_dir: Diretório para salvar relatórios. Se None, usa diretório padrão.
        """
        logger.info("🚀 Inicializando Pipeline de Análise de Crédito CeleiroGPT 5.0")
        
        # Configurar diretório de saída
        if output_dir is None:
            self.output_dir = Path(f"/dbfs/FileStore/analises_credito/{datetime.now().strftime('%Y%m%d')}")
        else:
            self.output_dir = Path(output_dir)
            
        # Criar diretório se não existir
        os.makedirs(self.output_dir, exist_ok=True)
        
        # Inicializar analisadores
        self.analisador_perfil = AnalisadorPerfilAssociado()
        self.analisador_carteira = AnalisadorCredito()
        self.analisador_scr = AnalisadorSCR()
        
        # Configurar cliente OpenAI para análise consolidada
        self.openai_client = OpenAI(
            api_key='dapie6330b0d1f7ccef0e70f3bdd28b1e2a2',
            base_url="https://sicredi-coop-0914.cloud.databricks.com/serving-endpoints",
            timeout=180.0
        )
        
        # Armazenar resultados das análises
        self.resultados = {}
        
        # Configurações de timeout
        self.timeout_analise = 300  # 5 minutos por análise individual
        self.max_retries = 2  # Número de tentativas para cada análise
        
        # Configurações de cores para relatórios
        self.cores = {
            'primaria': '#006341',  # Verde Sicredi
            'secundaria': '#F9B000',  # Amarelo Sicredi
            'terciaria': '#F0F7F4',  # Verde muito claro
            'cinza': '#E4E4E4',  # Cinza claro
            'texto': '#333333',  # Quase preto
            'alerta': '#E74C3C',  # Vermelho
            'sucesso': '#2ECC71',  # Verde
            'neutro': '#3498DB'   # Azul
        }
        
        logger.info(f"✅ Pipeline inicializado. Diretório de saída: {self.output_dir}")
    
    def consultar_tabela_processos(self) -> pd.DataFrame:
        """
        Busca processos com status NOVO na tabela de processos.
        
        Returns:
            DataFrame com os processos a serem analisados
        """
        try:
            logger.info(f"Buscando processos novos na tabela de processos")
            
            # Usar o SparkSession do analisador de carteira
            spark = self.analisador_carteira._get_spark()
            
            # Verificar se a tabela existe
            tabela_processos = "sicredi_coop_0914.bases_modelosllm.tb_processos_analises_credito"
            tabela_existe = spark.sql(f"""
                SHOW TABLES FROM sicredi_coop_0914.bases_modelosllm 
                LIKE 'tb_processos_analises_credito'
            """).count() > 0
            
            if not tabela_existe:
                logger.error(f"A tabela {tabela_processos} não existe!")
                return pd.DataFrame()
            
            # Buscar os processos com status NOVO
            df_spark = spark.sql(f"""
                SELECT * FROM {tabela_processos}
                WHERE status_analise = 'NOVO'
                ORDER BY data_criacao ASC
                LIMIT 10
            """)
            
            result_df = df_spark.toPandas()
            logger.info(f"Encontrados {len(result_df)} processos para análise")
            
            return result_df
            
        except Exception as e:
            logger.error(f"Erro ao buscar processos: {str(e)}")
            logger.error(traceback.format_exc())
            return pd.DataFrame()
    
    def atualizar_status_processo(self, numero_processo: int, novo_status: str, 
                                 parecer: Optional[str] = None, 
                                 link_pdf: Optional[str] = None):
        """
        Atualiza o status do processo na tabela de processos.
        
        Args:
            numero_processo: Número do processo a atualizar
            novo_status: Novo status (EM_ANDAMENTO, ANALISADO, ERRO_ANALISE)
            parecer: Parecer técnico (opcional)
            link_pdf: Link para o PDF gerado (opcional)
        """
        try:
            # Usar o SparkSession do analisador de carteira
            spark = self.analisador_carteira._get_spark()
            
            # Construir a query de atualização
            update_query = f"""
                UPDATE sicredi_coop_0914.bases_modelosllm.tb_processos_analises_credito
                SET status_analise = '{novo_status}',
                    data_status = current_timestamp()
            """
            
            if parecer:
                # Escapar aspas simples para evitar problemas de SQL injection
                parecer_escaped = parecer.replace("'", "''")
                update_query += f", parecer = '{parecer_escaped}'"
            
            if link_pdf:
                update_query += f", link_pdf = '{link_pdf}'"
            
            update_query += f" WHERE numero_processo = {numero_processo}"
            
            # Executar a atualização
            spark.sql(update_query)
            logger.info(f"Status do processo {numero_processo} atualizado para {novo_status}")
            
        except Exception as e:
            logger.error(f"Erro ao atualizar status do processo {numero_processo}: {str(e)}")
            logger.error(traceback.format_exc())
    
    def salvar_analises(self, numero_processo: int, cpf_cnpj: str,
                       analise_perfil: str, analise_carteira: str,
                       analise_scr: str, analise_final: str):
        """
        Salva todas as análises na tabela de análises feitas.
        
        Args:
            numero_processo: Número do processo
            cpf_cnpj: CPF/CNPJ do associado
            analise_perfil: Texto da análise de perfil
            analise_carteira: Texto da análise de carteira
            analise_scr: Texto da análise de SCR
            analise_final: Texto da análise final consolidada
        """
        try:
            # Usar o SparkSession do analisador de carteira
            spark = self.analisador_carteira._get_spark()
            
            # Escapar aspas simples para evitar problemas de SQL injection
            analise_perfil_escaped = analise_perfil.replace("'", "''")
            analise_carteira_escaped = analise_carteira.replace("'", "''")
            analise_scr_escaped = analise_scr.replace("'", "''")
            analise_final_escaped = analise_final.replace("'", "''")
            
            # Verificar se já existe registro para este processo
            tabela_analises = "sicredi_coop_0914.bases_modelosllm.tb_analises_feitas"
            existe = spark.sql(f"""
                SELECT COUNT(*) as count FROM {tabela_analises}
                WHERE numero_processo = {numero_processo}
            """).collect()[0]['count'] > 0
            
            if existe:
                # Atualizar registro existente
                spark.sql(f"""
                    UPDATE {tabela_analises}
                    SET analise_perfil = '{analise_perfil_escaped}',
                        analise_carteira = '{analise_carteira_escaped}',
                        analise_scr = '{analise_scr_escaped}',
                        analise_final = '{analise_final_escaped}',
                        data_analise = current_timestamp()
                    WHERE numero_processo = {numero_processo}
                """)
            else:
                # Inserir novo registro
                spark.sql(f"""
                    INSERT INTO {tabela_analises}
                    (numero_processo, cpf_cnpj, analise_perfil, analise_carteira, 
                     analise_scr, analise_final, data_analise)
                    VALUES (
                        {numero_processo}, 
                        '{cpf_cnpj}', 
                        '{analise_perfil_escaped}',
                        '{analise_carteira_escaped}', 
                        '{analise_scr_escaped}',
                        '{analise_final_escaped}', 
                        current_timestamp()
                    )
                """)
            
            logger.info(f"Análises salvas para processo {numero_processo}")
            
        except Exception as e:
            logger.error(f"Erro ao salvar análises: {str(e)}")
            logger.error(traceback.format_exc())
    
    def identificar_tipo_pessoa(self, cpf_cnpj: str) -> str:
        """
        Identifica se o documento é CPF (pessoa física) ou CNPJ (pessoa jurídica)
        
        Args:
            cpf_cnpj: Número do CPF ou CNPJ
            
        Returns:
            str: 'PF' para pessoa física ou 'PJ' para pessoa jurídica
        """
        # Remover caracteres não numéricos
        documento = re.sub(r'\D', '', cpf_cnpj)
        
        # Verificar o comprimento do documento
        if len(documento) <= 11:
            return 'PF'
        else:
            return 'PJ'
    
    def obter_instrucoes_produto_pj(self, proposta: str, renda_mensal: float) -> str:
        """
        Obtém instruções de análise para pessoa jurídica baseadas no tipo de produto e faixa de faturamento
        
        Args:
            proposta: Descrição da proposta
            renda_mensal: Faturamento mensal do associado PJ
            
        Returns:
            str: Instruções específicas para análise do produto para PJ
        """
        # Identificar o tipo de produto
        tem_cartao = "cartão" in proposta.lower()
        tem_cheque = "cheque" in proposta.lower()
        
        # Calcular faturamento anual
        faturamento_anual = renda_mensal * 12
        
        # Determinar a faixa de faturamento e percentuais
        if faturamento_anual <= 81000:
            faixa_faturamento = "até R$ 81.000,00"
            limite_cheque = 1   # 1% do faturamento anual
            limite_cartao = 3   # 3% do faturamento anual
        elif 81000.01 <= faturamento_anual <= 360000:
            faixa_faturamento = "até R$ 360.000,00"
            limite_cheque = 2   # 2% do faturamento anual
            limite_cartao = 4   # 4% do faturamento anual
        elif 360000.01 <= faturamento_anual <= 1000000:
            faixa_faturamento = "entre R$ 360.000,01 e R$ 1.000.000,00"
            limite_cheque = 3   # 3% do faturamento anual
            limite_cartao = 5   # 5% do faturamento anual
        elif 1000000.01 <= faturamento_anual <= 6000000:
            faixa_faturamento = "entre R$ 1.000.000,01 e R$ 6.000.000,00"
            limite_cheque = 1.5   # 1,5% do faturamento anual
            limite_cartao = 3.5   # 3,5% do faturamento anual
        else:  # acima de 6.000.000,01
            faixa_faturamento = "acima de R$ 6.000.000,01"
            limite_cheque = 1   # 1% do faturamento anual
            limite_cartao = 2   # 2% do faturamento anual
        
        # Montar as instruções
        instrucoes = f"""
INSTRUÇÕES PARA ANÁLISE DE CHEQUE E CARTÃO - PESSOA JURÍDICA:

Faixa de Faturamento Anual: {faixa_faturamento} com faturamento anual estimado de: R$ {faturamento_anual:,.2f}
Faturamento mensal: R$ {renda_mensal:,.2f}

"""
        
        if tem_cartao and tem_cheque:
            instrucoes += f"""
Para esta faixa de faturamento, o limite solicitado para cartão de crédito deve estar enquadrado dentro dos {limite_cartao}% do faturamento anual da empresa.
O limite de cheque especial deve estar enquadrado dentro dos {limite_cheque}% do faturamento anual da empresa.

Verifique se o limite total solicitado (cartão + cheque) está adequado ao percentual do faturamento anual da empresa.
"""
        elif tem_cartao:
            instrucoes += f"""
Para esta faixa de faturamento, o limite solicitado para cartão de crédito deve estar enquadrado dentro dos {limite_cartao}% do faturamento anual da empresa.
"""
        elif tem_cheque:
            instrucoes += f"""
Para esta faixa de faturamento, o limite de cheque especial deve estar enquadrado dentro dos {limite_cheque}% do faturamento anual da empresa.
"""
        
        instrucoes += """
IMPORTANTE: Avalie também o histórico de crédito, comprometimento atual, perfil de risco e outros fatores que possam influenciar na capacidade de pagamento da empresa.
"""
        
        return instrucoes
    
    def obter_instrucoes_produto_pj(self, proposta: str, renda_mensal: float) -> str:
        """
        Obtém instruções de análise para pessoa jurídica baseadas no tipo de produto e faixa de faturamento
        
        Args:
            proposta: Descrição da proposta
            faturamento_mensal: Faturamento mensal do associado PJ
            
        Returns:
            str: Instruções específicas para análise do produto para PJ
        """
        # Identificar o tipo de produto
        tem_cartao = "cartão" in proposta.lower()
        tem_cheque = "cheque" in proposta.lower()
        
        # Calcular faturamento anual
        faturamento_anual = renda_mensal * 12
        
        # Determinar a faixa de faturamento e percentuais
        if faturamento_anual <= 81000:
            faixa_faturamento = "até R$ 81.000,00"
            limite_cheque = 1   # 1% do faturamento anual
            limite_cartao = 3   # 3% do faturamento anual
        elif 81000.01 <= faturamento_anual <= 360000:
            faixa_faturamento = "até R$ 360.000,00"
            limite_cheque = 2   # 2% do faturamento anual
            limite_cartao = 4   # 4% do faturamento anual
        elif 360000.01 <= faturamento_anual <= 1000000:
            faixa_faturamento = "entre R$ 360.000,01 e R$ 1.000.000,00"
            limite_cheque = 3   # 3% do faturamento anual
            limite_cartao = 5   # 5% do faturamento anual
        elif 1000000.01 <= faturamento_anual <= 6000000:
            faixa_faturamento = "entre R$ 1.000.000,01 e R$ 6.000.000,00"
            limite_cheque = 1.5   # 1,5% do faturamento anual
            limite_cartao = 3.5   # 3,5% do faturamento anual
        else:  # acima de 6.000.000,01
            faixa_faturamento = "acima de R$ 6.000.000,01"
            limite_cheque = 1   # 1% do faturamento anual
            limite_cartao = 2   # 2% do faturamento anual
        
        # Montar as instruções
        instrucoes = f"""
INSTRUÇÕES PARA ANÁLISE DE CHEQUE E CARTÃO - PESSOA JURÍDICA:

Faixa de Faturamento Anual: {faixa_faturamento} com faturamento anual estimado de: R$ {faturamento_anual:,.2f}
Faturamento mensal: R$ {renda_mensal:,.2f}

"""
        
        if tem_cartao and tem_cheque:
            instrucoes += f"""
Para esta faixa de faturamento, o limite solicitado para cartão de crédito deve estar enquadrado dentro dos {limite_cartao}% do faturamento anual da empresa.
O limite de cheque especial deve estar enquadrado dentro dos {limite_cheque}% do faturamento anual da empresa.

Verifique se o limite total solicitado (cartão + cheque) está adequado ao percentual do faturamento anual da empresa.
"""
        elif tem_cartao:
            instrucoes += f"""
Para esta faixa de faturamento, o limite solicitado para cartão de crédito deve estar enquadrado dentro dos {limite_cartao}% do faturamento anual da empresa.
"""
        elif tem_cheque:
            instrucoes += f"""
Para esta faixa de faturamento, o limite de cheque especial deve estar enquadrado dentro dos {limite_cheque}% do faturamento anual da empresa.
"""
        
        instrucoes += """
IMPORTANTE: Avalie também o histórico de crédito, comprometimento atual, perfil de risco e outros fatores que possam influenciar na capacidade de pagamento da empresa.
"""
        
        return instrucoes
    
    def executar_analise_completa(self, cpf_cnpj: str, proposta: str, 
                                 numero_processo: int, cpf_avalista: Optional[str] = None) -> Dict[str, Any]:
        """
        Executa uma análise completa para um CPF/CNPJ, integrando perfil, carteira e SCR.
        Identifica automaticamente se é PF ou PJ e aplica regras específicas.
        
        Args:
            cpf_cnpj: CPF ou CNPJ do associado
            proposta: Descrição da proposta de crédito
            numero_processo: Número do processo de análise
            cpf_avalista: CPF do avalista, se houver
            
        Returns:
            Dict: Resultado completo da análise
        """
        start_time = time.time()
        logger.info(f"🔍 Iniciando análise completa para CPF/CNPJ: {cpf_cnpj}")
        
        try:
            # Identificar se é PF ou PJ
            tipo_pessoa = self.identificar_tipo_pessoa(cpf_cnpj)
            logger.info(f"👤 Tipo de pessoa identificado: {tipo_pessoa}")
            
            # Atualizar status para EM ANDAMENTO
            self.atualizar_status_processo(numero_processo, 'EM_ANDAMENTO')
            
            # Criar diretório específico para este processo
            processo_dir = self.output_dir / f"processo_{numero_processo}"
            os.makedirs(processo_dir, exist_ok=True)
            
            # Executar as três análises em paralelo com tratamento de erros
            resultados_analises = {}
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                # Submeter as três análises para execução paralela
                future_perfil = executor.submit(self._executar_analise_perfil, cpf_cnpj)
                future_carteira = executor.submit(self._executar_analise_carteira, cpf_cnpj)
                future_scr = executor.submit(self._executar_analise_scr, cpf_cnpj)
                
                # Coletar resultados com timeout
                try:
                    resultados_analises['perfil'] = future_perfil.result(timeout=self.timeout_analise)
                except Exception as e:
                    logger.error(f"Erro ou timeout na análise de perfil: {str(e)}")
                    resultados_analises['perfil'] = {
                        "status": "error",
                        "message": f"Erro na análise de perfil: {str(e)}",
                        "analise": "Não foi possível completar a análise de perfil."
                    }
                
                try:
                    resultados_analises['carteira'] = future_carteira.result(timeout=self.timeout_analise)
                except Exception as e:
                    logger.error(f"Erro ou timeout na análise de carteira: {str(e)}")
                    resultados_analises['carteira'] = {
                        "status": "error",
                        "message": f"Erro na análise de carteira: {str(e)}",
                        "analise": "Não foi possível completar a análise de carteira."
                    }
                
                try:
                    resultados_analises['scr'] = future_scr.result(timeout=self.timeout_analise)
                except Exception as e:
                    logger.error(f"Erro ou timeout na análise de SCR: {str(e)}")
                    resultados_analises['scr'] = {
                        "status": "error",
                        "message": f"Erro na análise de SCR: {str(e)}",
                        "analise": "Não foi possível completar a análise de SCR."
                    }
            
            # Verificar se todas as análises falharam
            if (resultados_analises['perfil'].get('status') == 'error' and 
                resultados_analises['carteira'].get('status') == 'error' and 
                resultados_analises['scr'].get('status') == 'error'):
                
                logger.error(f"Todas as análises falharam para {cpf_cnpj}")
                self.atualizar_status_processo(
                    numero_processo, 
                    'ERRO_ANALISE', 
                    "Não foi possível completar nenhuma das análises necessárias."
                )
                
                return {
                    "status": "error",
                    "message": "Todas as análises falharam",
                    "resultados": resultados_analises
                }
            
            # Extrair textos das análises (usar mensagem de erro se alguma falhou)
            texto_analise_perfil = resultados_analises['perfil'].get('analise', "Análise de perfil não disponível")
            texto_analise_carteira = resultados_analises['carteira'].get('analise', "Análise de carteira não disponível")
            texto_analise_scr = resultados_analises['scr'].get('analise', "Análise de SCR não disponível")
            
            # Extrair dados para o relatório
            dados_perfil = resultados_analises['perfil'].get('dados', {})
            dados_carteira = resultados_analises['carteira'].get('dados', {})
            dados_scr = resultados_analises['scr'].get('dados', {})
            
            # Obter valor de renda/faturamento mensal para análise do produto
            valor_mensal = 0.0
            if "info_associado" in dados_carteira and dados_carteira["info_associado"].get("renda_mensal"):
                valor_mensal = float(dados_carteira["info_associado"].get("renda_mensal", 0))
            
            # Obter instruções específicas para o produto com base no tipo de pessoa
            if tipo_pessoa == 'PJ':
                instrucoes_produto = self.obter_instrucoes_produto_pj(proposta, valor_mensal)
            else:  # PF
                instrucoes_produto = self.obter_instrucoes_produto_pf(proposta, valor_mensal)
            
            # Extrair gráficos (se disponíveis)
            graficos = []
            if 'graficos_base64' in resultados_analises['carteira']:
                graficos.extend(resultados_analises['carteira']['graficos_base64'])
            if 'graficos_base64' in resultados_analises['scr']:
                graficos.extend(resultados_analises['scr'].get('graficos_base64', []))
            
            # Gerar análise final consolidada
            logger.info("🧠 Gerando análise final consolidada")
            analise_final, parecer = self.gerar_analise_consolidada(
                texto_analise_perfil,
                texto_analise_carteira,
                texto_analise_scr,
                proposta,
                cpf_cnpj,
                tipo_pessoa,
                cpf_avalista,
                instrucoes_produto
            )
            
            # Salvar todas as análises na tabela
            self.salvar_analises(
                numero_processo,
                cpf_cnpj,
                texto_analise_perfil,
                texto_analise_carteira,
                texto_analise_scr,
                analise_final
            )
            
            # Obter nome do associado, se disponível
            nome_associado = "Não informado"
            if "info_associado" in dados_carteira and dados_carteira["info_associado"].get("nome"):
                nome_associado = dados_carteira["info_associado"].get("nome")
            elif "nome_associado" in dados_perfil:
                nome_associado = dados_perfil.get("nome_associado")
            
            # Gerar relatório PDF com o template HTML aprimorado
            logger.info("📄 Gerando relatório com template HTML aprimorado")
            link_pdf = self.gerar_relatorio_pdf(
                numero_processo,
                cpf_cnpj,
                nome_associado,
                proposta,
                tipo_pessoa,
                texto_analise_perfil,
                texto_analise_carteira,
                texto_analise_scr,
                analise_final,
                parecer,
                graficos,
                dados_perfil,
                dados_carteira,
                dados_scr,
                processo_dir
            )
            
            # Atualizar status para ANALISADO
            self.atualizar_status_processo(numero_processo, 'ANALISADO', parecer, link_pdf)
            
            # Calcular tempo total
            elapsed = time.time() - start_time
            logger.info(f"✅ Análise completa concluída em {elapsed:.2f}s")
            
            # Armazenar resultado para referência futura
            resultado_final = {
                "status": "success",
                "numero_processo": numero_processo,
                "cpf_cnpj": cpf_cnpj,
                "tipo_pessoa": tipo_pessoa,
                "tempo_processamento": f"{elapsed:.2f}s",
                "analise_final": analise_final,
                "parecer": parecer,
                "link_pdf": link_pdf,
                "resultados_individuais": resultados_analises
            }
            
            self.resultados[numero_processo] = resultado_final
            return resultado_final
            
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"❌ Erro na análise completa após {elapsed:.2f}s: {str(e)}")
            logger.error(traceback.format_exc())
            
            # Atualizar status para ERRO_ANALISE
            self.atualizar_status_processo(
                numero_processo, 
                'ERRO_ANALISE', 
                f"Erro durante a análise: {str(e)}"
            )
            
            return {
                "status": "error",
                "numero_processo": numero_processo,
                "cpf_cnpj": cpf_cnpj,
                "message": f"Erro na análise: {str(e)}",
                "tempo_processamento": f"{elapsed:.2f}s"
            }
    
    def _executar_analise_perfil(self, cpf_cnpj: str) -> Dict[str, Any]:
        """
        Executa a análise de perfil com tratamento de erros e retries.
        
        Args:
            cpf_cnpj: CPF ou CNPJ do associado
            
        Returns:
            Dict: Resultado da análise de perfil
        """
        logger.info(f"🔍 Iniciando análise de perfil para {cpf_cnpj}")
        
        for attempt in range(self.max_retries):
            try:
                resultado = self.analisador_perfil.analisar_perfil_associado(cpf_cnpj)
                logger.info(f"✅ Análise de perfil concluída com sucesso")
                return resultado
            except Exception as e:
                logger.warning(f"⚠️ Tentativa {attempt+1} falhou: {str(e)}")
                if attempt < self.max_retries - 1:
                    logger.info(f"🔄 Tentando novamente análise de perfil...")
                    time.sleep(2)  # Pequena pausa antes de tentar novamente
        
        logger.error(f"❌ Todas as tentativas de análise de perfil falharam")
        return {
            "status": "error",
            "message": "Todas as tentativas de análise de perfil falharam",
            "analise": "Não foi possível completar a análise de perfil após múltiplas tentativas."
        }
    
    def _executar_analise_carteira(self, cpf_cnpj: str) -> Dict[str, Any]:
        """
        Executa a análise de carteira com tratamento de erros e retries.
        
        Args:
            cpf_cnpj: CPF ou CNPJ do associado
            
        Returns:
            Dict: Resultado da análise de carteira
        """
        logger.info(f"🔍 Iniciando análise de carteira para {cpf_cnpj}")
        
        for attempt in range(self.max_retries):
            try:
                resultado = self.analisador_carteira.analisar_historico_credito_associado(cpf_cnpj)
                logger.info(f"✅ Análise de carteira concluída com sucesso")
                return resultado
            except Exception as e:
                logger.warning(f"⚠️ Tentativa {attempt+1} falhou: {str(e)}")
                if attempt < self.max_retries - 1:
                    logger.info(f"🔄 Tentando novamente análise de carteira...")
                    time.sleep(2)  # Pequena pausa antes de tentar novamente
        
        logger.error(f"❌ Todas as tentativas de análise de carteira falharam")
        return {
            "status": "error",
            "message": "Todas as tentativas de análise de carteira falharam",
            "analise": "Não foi possível completar a análise de carteira após múltiplas tentativas."
        }
    
    def _executar_analise_scr(self, cpf_cnpj: str) -> Dict[str, Any]:
        """
        Executa a análise de SCR com tratamento de erros e retries.
        
        Args:
            cpf_cnpj: CPF ou CNPJ do associado
            
        Returns:
            Dict: Resultado da análise de SCR
        """
        logger.info(f"🔍 Iniciando análise de SCR para {cpf_cnpj}")
        
        for attempt in range(self.max_retries):
            try:
                resultado = self.analisador_scr.analisar_scr_associado(cpf_cnpj)
                logger.info(f"✅ Análise de SCR concluída com sucesso")
                return resultado
            except Exception as e:
                logger.warning(f"⚠️ Tentativa {attempt+1} falhou: {str(e)}")
                if attempt < self.max_retries - 1:
                    logger.info(f"🔄 Tentando novamente análise de SCR...")
                    time.sleep(2)  # Pequena pausa antes de tentar novamente
        
        logger.error(f"❌ Todas as tentativas de análise de SCR falharam")
        return {
            "status": "error",
            "message": "Todas as tentativas de análise de SCR falharam",
            "analise": "Não foi possível completar a análise de SCR após múltiplas tentativas."
        }
    
    def gerar_analise_consolidada(self, analise_perfil: str, analise_carteira: str, 
                                analise_scr: str, proposta: str, 
                                cpf_cnpj: str, tipo_pessoa: str,
                                cpf_avalista: Optional[str] = None,
                                instrucoes_produto: Optional[str] = None) -> Tuple[str, str]:
        """
        Gera uma análise consolidada a partir das três análises individuais.
        
        Args:
            analise_perfil: Texto da análise de perfil
            analise_carteira: Texto da análise de carteira
            analise_scr: Texto da análise de SCR
            proposta: Descrição da proposta
            cpf_cnpj: CPF/CNPJ do associado
            tipo_pessoa: Tipo de pessoa ('PF' ou 'PJ')
            cpf_avalista: CPF do avalista (opcional)
            instrucoes_produto: Instruções específicas para análise do produto
            
        Returns:
            Tuple[str, str]: Análise completa e parecer resumido
        """
        logger.info(f"🧠 Gerando análise consolidada para {cpf_cnpj} ({tipo_pessoa})")
        
        # Extrair valores da proposta para análise mais precisa
        valores = re.findall(r'R?\$?\s?(\d{1,3}(?:\.\d{3})*(?:,\d{2})?)', proposta)
        valores_numericos = []
        
        for valor in valores:
            # Converter para formato numérico
            valor_limpo = valor.replace('.', '').replace(',', '.')
            try:
                valor_numerico = float(valor_limpo)
                valores_numericos.append(valor_numerico)
            except ValueError:
                continue
        
        # Tentar identificar o tipo de produto
        tipo_produto = "não especificado"
        if "cartão" in proposta.lower():
            tipo_produto = "cartão de crédito"
        elif "cheque" in proposta.lower():
            tipo_produto = "cheque especial"
        elif "empréstimo" in proposta.lower() or "emprestimo" in proposta.lower():
            tipo_produto = "empréstimo pessoal"
        elif "financiamento" in proposta.lower():
            tipo_produto = "financiamento"
        
        # Construir prompt para o modelo com base no tipo de pessoa
        prompt_base = f"""
Você é um analista de crédito sênior do Sicredi com mais de 20 anos de experiência. Sua tarefa é analisar e consolidar as três análises detalhadas fornecidas (perfil do associado, carteira de crédito e SCR) e emitir um parecer técnico sobre a proposta de crédito.

TIPO DE PESSOA: {'PESSOA JURÍDICA (PJ)' if tipo_pessoa == 'PJ' else 'PESSOA FÍSICA (PF)'}

PROPOSTA SOLICITADA:
{proposta}

ANÁLISE DE PERFIL DO ASSOCIADO:
{analise_perfil}

ANÁLISE DE CARTEIRA DE CRÉDITO:
{analise_carteira}

ANÁLISE SCR (SISTEMA DE INFORMAÇÕES DE CRÉDITO):
{analise_scr}

{"AVALISTA: " + cpf_avalista if cpf_avalista else "SEM AVALISTA"}

INSTRUÇÕES ESPECÍFICAS PARA ANÁLISE DESTE PRODUTO:
{instrucoes_produto if instrucoes_produto else "Sem instruções específicas para este produto."}

Com base em todas essas informações, realize uma análise consolidada estruturada nos seguintes tópicos:

1. SÍNTESE DO PERFIL FINANCEIRO DO ASSOCIADO
- Resumo conciso do perfil financeiro, patrimonial e comportamental
- Histórico de relacionamento com a cooperativa
- Principais indicadores financeiros (renda/faturamento, patrimônio, comprometimento)
- Classificação de risco e score de crédito

2. ANÁLISE DE CAPACIDADE DE PAGAMENTO
- Cálculo detalhado da capacidade de pagamento atual
- Impacto da nova operação no comprometimento de renda/fluxo de caixa
- Projeção de fluxo de caixa considerando todas as obrigações
- Análise de sazonalidade de renda/faturamento (se aplicável)
- Indicadores de liquidez e solvência

3. ANÁLISE DE RISCO CONSOLIDADA
- Avaliação quantitativa e qualitativa dos riscos identificados
- Principais fatores de risco identificados e sua ponderação
- Análise de tendências de comportamento financeiro
- Comparativo com perfis similares (benchmark)
- Matriz de risco com probabilidade e impacto

4. ANÁLISE DA PROPOSTA
- Adequação da proposta ao perfil e necessidade do associado
- Verificação de enquadramento nas políticas e normas
- Análise de custo-benefício para o associado e para a cooperativa
- Alternativas que poderiam ser mais adequadas (se aplicável)
- Simulação de cenários (otimista, realista, pessimista)

5. MITIGADORES DE RISCO
- Garantias oferecidas e sua suficiência
- Avalista/fiador (se houver) e sua capacidade financeira
- Seguros e proteções associados ao produto
- Estratégias adicionais para mitigação de riscos identificados
- Plano de contingência em caso de inadimplência

6. PARECER TÉCNICO FUNDAMENTADO
- Decisão clara: APROVADO, APROVADO COM RESTRIÇÕES, ou REPROVADO
- Justificativa detalhada com base em fatos e dados
- Condicionantes específicas (se aprovado com restrições)
- Recomendações para monitoramento futuro
- Validade da análise e gatilhos para reavaliação

7. OPORTUNIDADES ADICIONAIS
- Produtos complementares que poderiam beneficiar o associado
- Estratégias de educação financeira personalizadas
- Recomendações para melhorar o perfil financeiro
- Próximos passos para o associado e para a cooperativa
- Plano de relacionamento de longo prazo

8. PARECER FINAL FORMATADO
"""

        # Adicionar instruções específicas para o parecer final com base no tipo de pessoa
        if tipo_pessoa == 'PJ':
            prompt_base += """
Forneça um parágrafo no seguinte formato para PJ:
"Limite solicitado para [produto] (R$ XX.XXX,XX - percentual de XX%) está [enquadrado/não enquadrado] dentro dos XX% do faturamento anual da empresa. Representando a porcentagem total de XX% do faturamento anual. [Adicione observações relevantes sobre a decisão]. [Adicione recomendações específicas se necessário]."
"""
        else:  # PF
            prompt_base += """
Forneça um parágrafo no seguinte formato para PF:
"Limite solicitado para [produto] (R$ XX.XXX,XX - percentual de XX%) está [enquadrado/não enquadrado] dentro dos XX% da renda bruta mensal do associado. Representando a porcentagem total de XX% da renda mensal bruta do associado. [Adicione observações relevantes sobre a decisão]. [Adicione recomendações específicas se necessário]."
"""

        prompt_base += """
Seja objetivo, técnico e baseie todas as conclusões nos dados apresentados. Utilize linguagem formal e precisa. Inclua valores numéricos sempre que possível para fundamentar a análise.

IMPORTANTE: Certifique-se de que cada seção (SÍNTESE DO PERFIL, CAPACIDADE DE PAGAMENTO, ANÁLISE DE RISCO, ANÁLISE DA PROPOSTA) esteja claramente delimitada e estruturada para facilitar a leitura e compreensão.
"""

        try:
            # Chamar o modelo para gerar a análise consolidada
            response = self.openai_client.chat.completions.create(
                model="databricks-claude-3-7-sonnet",
                messages=[
                    {
                        "role": "system", 
                        "content": f"Você é um analista de crédito sênior do Sicredi com mais de 20 anos de experiência. Sua análise deve ser técnica, precisa e baseada em dados. Você deve proteger os interesses da cooperativa mantendo uma visão equilibrada que também considere o desenvolvimento do associado. Você está analisando um {'PESSOA JURÍDICA' if tipo_pessoa == 'PJ' else 'PESSOA FÍSICA'}."
                    },
                    {"role": "user", "content": prompt_base}
                ],
                temperature=0.1,
                max_tokens=8000
            )
            
            analise_completa = response.choices[0].message.content
            
            # Extrair o parecer final formatado (última parte da análise)
            linhas = analise_completa.split('\n')
            parecer_final = ""
            
            # Procurar pelo parágrafo que começa com "Limite solicitado"
            for i, linha in enumerate(linhas):
                if "Limite solicitado" in linha or "PARECER FINAL" in linha.upper():
                    # Pegar essa linha e as próximas até encontrar uma linha vazia
                    parecer_final = linha
                    for j in range(i+1, len(linhas)):
                        if linhas[j].strip():
                            parecer_final += " " + linhas[j].strip()
                        else:
                            break
                    break
            
            # Se não encontrou o formato específico, extrair a decisão do parecer técnico
            if not parecer_final:
                for i, linha in enumerate(linhas):
                    if any(decisao in linha.upper() for decisao in ["APROVADO", "REPROVADO", "DEFERIDO", "INDEFERIDO"]):
                        parecer_final = linha.strip()
                        # Incluir algumas linhas adicionais para contexto
                        for j in range(i+1, min(i+4, len(linhas))):
                            if linhas[j].strip():
                                parecer_final += " " + linhas[j].strip()
                        break
            
            # Se ainda não encontrou, usar um trecho da conclusão
            if not parecer_final:
                for i, linha in enumerate(linhas):
                    if "CONCLUSÃO" in linha.upper() or "PARECER" in linha.upper():
                        for j in range(i+1, min(i+10, len(linhas))):
                            if linhas[j].strip() and len(linhas[j]) > 30:  # Pegar uma linha substantiva
                                parecer_final = linhas[j].strip()
                                break
                        if parecer_final:
                            break
            
            # Se ainda não encontrou, usar o último parágrafo substantivo
            if not parecer_final:
                for linha in reversed(linhas):
                    if linha.strip() and len(linha) > 50:  # Um parágrafo substantivo
                        parecer_final = linha.strip()
                        break
            
            logger.info(f"✅ Análise consolidada gerada com sucesso")
            return analise_completa, parecer_final
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar análise consolidada: {str(e)}")
            # Criar uma análise básica de fallback
            analise_fallback = f"""
# ANÁLISE CONSOLIDADA DE CRÉDITO - FALLBACK

## SÍNTESE DO PERFIL FINANCEIRO DO ASSOCIADO
Não foi possível gerar uma análise consolidada completa devido a um erro técnico: {str(e)}

## PARECER TÉCNICO
Recomenda-se uma análise manual detalhada por um analista humano, considerando as análises individuais disponíveis.

## ANÁLISES INDIVIDUAIS DISPONÍVEIS
- Análise de Perfil: {'Disponível' if len(analise_perfil) > 50 else 'Não disponível ou incompleta'}
- Análise de Carteira: {'Disponível' if len(analise_carteira) > 50 else 'Não disponível ou incompleta'}
- Análise de SCR: {'Disponível' if len(analise_scr) > 50 else 'Não disponível ou incompleta'}
"""
            
            parecer_fallback = "ANÁLISE MANUAL REQUERIDA - Não foi possível gerar uma análise automática completa."
            return analise_fallback, parecer_fallback

    def gerar_relatorio_html(self, numero_processo: int, cpf_cnpj: str, nome_associado: str, proposta: str, 
                           tipo_pessoa: str, analise_perfil: str, analise_carteira: str, analise_scr: str, 
                           analise_final: str, parecer: str, graficos: List[Dict], 
                           dados_perfil: Dict, dados_carteira: Dict, dados_scr: Dict) -> str:
        """
        Gera um relatório HTML estruturado e estilizado para análise de crédito.
        
        Args:
            numero_processo: Número do processo
            cpf_cnpj: CPF/CNPJ do associado
            nome_associado: Nome do associado
            proposta: Descrição da proposta
            tipo_pessoa: Tipo de pessoa ('PF' ou 'PJ')
            analise_perfil: Texto da análise de perfil
            analise_carteira: Texto da análise de carteira
            analise_scr: Texto da análise de SCR
            analise_final: Texto da análise consolidada
            parecer: Parecer final resumido
            graficos: Lista de dicionários com gráficos em base64
            dados_perfil: Dados estruturados do perfil
            dados_carteira: Dados estruturados da carteira
            dados_scr: Dados estruturados do SCR
            
        Returns:
            str: HTML formatado do relatório
        """
        # Determinar o status do parecer para aplicar a cor correta
        status_class = "status-neutro"
        status_icon = "✓"
        
        if "APROVADO COM RESTRIÇÕES" in parecer.upper():
            status_class = "status-atencao"
            status_icon = "⚠️"
        elif any(termo in parecer.upper() for termo in ["REPROVADO", "INDEFERIDO", "NÃO APROVADO"]):
            status_class = "status-negativo"
            status_icon = "✕"
        elif "APROVADO" in parecer.upper():
            status_class = "status-positivo"
            status_icon = "✓"
        
        # Obter data atual formatada
        from datetime import datetime
        data_atual = datetime.now().strftime("%d/%m/%Y %H:%M:%S")
        
        # Extrair dados para indicadores
        valor_mensal = "Não informado"
        if "info_associado" in dados_carteira and dados_carteira["info_associado"].get("renda_mensal"):
            valor_mensal_float = float(dados_carteira["info_associado"].get("renda_mensal", 0))
            valor_mensal = f"R$ {valor_mensal_float:,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")
        
        # Determinar o rótulo correto com base no tipo de pessoa
        rotulo_valor = "Renda Mensal" if tipo_pessoa == "PF" else "Faturamento Mensal"
        
        # Preparar gráficos para exibição
        graficos_html = ""
        for grafico in graficos[:4]:  # Limitar a 4 gráficos
            graficos_html += f"""
            <div class="grafico-container">
                <h3 class="grafico-titulo">{grafico.get('titulo', 'Gráfico')}</h3>
                <div class="grafico-imagem">
                    <img src="data:image/png;base64,{grafico.get('base64', '')}" alt="{grafico.get('titulo', 'Gráfico')}">
                </div>
                <p class="grafico-descricao">{grafico.get('descricao', '')}</p>
            </div>
            """
        
        # Extrair seções da análise final de forma mais precisa
        import re
        
        # Função para extrair seções da análise final com melhor precisão
        def extrair_secao(texto, titulo, titulo_seguinte=None):
            # Padrão para encontrar a seção específica
            if titulo_seguinte:
                padrao = re.compile(f"{re.escape(titulo)}.*?(?={re.escape(titulo_seguinte)})", re.DOTALL)
            else:
                padrao = re.compile(f"{re.escape(titulo)}.*?(?=\n\n\d+\.|\n\n[A-Z]{{2,}}|\Z)", re.DOTALL)
            
            resultado = padrao.search(texto)
            if resultado:
                # Remover o título da seção do conteúdo extraído
                conteudo = resultado.group(0).replace(titulo, "", 1).strip()
                return conteudo
            return "Informação não disponível."
        
        # Lista de títulos de seções na ordem em que aparecem
        titulos_secoes = [
            "1. SÍNTESE DO PERFIL FINANCEIRO DO ASSOCIADO",
            "2. ANÁLISE DE CAPACIDADE DE PAGAMENTO",
            "3. ANÁLISE DE RISCO CONSOLIDADA",
            "4. ANÁLISE DA PROPOSTA",
            "5. MITIGADORES DE RISCO",
            "6. PARECER TÉCNICO FUNDAMENTADO",
            "7. OPORTUNIDADES ADICIONAIS"
        ]
        
        # Extrair seções principais com base nos títulos sequenciais
        secoes = {}
        for i, titulo in enumerate(titulos_secoes):
            titulo_seguinte = titulos_secoes[i+1] if i+1 < len(titulos_secoes) else None
            secoes[titulo] = extrair_secao(analise_final, titulo, titulo_seguinte)
        
        # Extrair fatores de risco (usando expressões regulares para encontrar pontos importantes)
        fatores_risco = []
        padrao_risco = re.compile(r"(?:risco|impacto|alerta|preocupante|crítico|deterioração|elevado|significativo).*?(?:\.|$)", re.IGNORECASE)
        riscos_encontrados = padrao_risco.findall(secoes.get("3. ANÁLISE DE RISCO CONSOLIDADA", ""))
        
        for risco in riscos_encontrados[:3]:  # Limitar a 3 fatores de risco
            if len(risco) > 20:  # Filtrar frases muito curtas
                fatores_risco.append(risco.strip())
        
        # Se não encontrou riscos específicos, usar um padrão genérico
        if not fatores_risco:
            fatores_risco = ["Análise de risco detalhada disponível na seção completa."]
        
        # Construir HTML dos fatores de risco
        fatores_risco_html = ""
        for fator in fatores_risco:
            fatores_risco_html += f"<li>{fator}</li>"
        
        # Template HTML completo com CSS embutido
        html_template = f"""
        <!DOCTYPE html>
        <html lang="pt-BR">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Análise de Crédito - {nome_associado}</title>
            <style>
                /* Estilos base */
                body {{
                    font-family: Arial, Helvetica, sans-serif;
                    margin: 0;
                    padding: 0;
                    background-color: #f9f9f9;
                    color: #333;
                    line-height: 1.6;
                }}
                
                .container {{
                    max-width: 1200px;
                    margin: 0 auto;
                    background: #fff;
                    box-shadow: 0 0 10px rgba(0,0,0,0.1);
                }}
                
                /* Cabeçalho */
                .cabecalho {{
                    background-color: #006341; /* Verde Sicredi */
                    color: white;
                    padding: 20px;
                    display: flex;
                    align-items: center;
                    justify-content: space-between;
                    border-bottom: 5px solid #F9B000; /* Amarelo Sicredi */
                }}
                
                .logo-container {{
                    display: flex;
                    align-items: center;
                }}
                
                .logo {{
                    font-size: 28px;
                    font-weight: bold;
                    color: white;
                    margin-right: 20px;
                }}
                
                .titulo {{
                    flex-grow: 1;
                    text-align: center;
                }}
                
                .titulo h1 {{
                    margin: 0;
                    font-size: 24px;
                    text-transform: uppercase;
                }}
                
                .titulo h2 {{
                    margin: 5px 0 0;
                    font-size: 16px;
                    font-weight: normal;
                    opacity: 0.9;
                }}
                
                /* Informações do processo */
                .info-processo {{
                    background-color: #f5f5f5;
                    padding: 15px 20px;
                    display: grid;
                    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
                    gap: 15px;
                }}
                
                .info-item {{
                    margin-bottom: 10px;
                }}
                
                .info-label {{
                    font-size: 12px;
                    color: #666;
                    text-transform: uppercase;
                    margin-bottom: 5px;
                    font-weight: bold;
                }}
                
                .info-valor {{
                    font-size: 16px;
                    font-weight: bold;
                }}
                
                /* Proposta */
                .secao {{
                    padding: 20px;
                    margin-bottom: 20px;
                }}
                
                .secao-titulo {{
                    color: #006341;
                    border-bottom: 2px solid #F9B000;
                    padding-bottom: 10px;
                    margin-bottom: 20px;
                    font-size: 20px;
                }}
                
                /* Parecer */
                .parecer {{
                    padding: 20px;
                    margin: 20px;
                    border-radius: 5px;
                    position: relative;
                }}
                
                .status-positivo {{
                    background-color: rgba(46, 204, 113, 0.15);
                    border-left: 5px solid #2ecc71;
                }}
                
                .status-atencao {{
                    background-color: rgba(241, 196, 15, 0.15);
                    border-left: 5px solid #f1c40f;
                }}
                
                .status-negativo {{
                    background-color: rgba(231, 76, 60, 0.15);
                    border-left: 5px solid #e74c3c;
                }}
                
                .status-neutro {{
                    background-color: rgba(52, 152, 219, 0.15);
                    border-left: 5px solid #3498db;
                }}
                
                .parecer-titulo {{
                    font-size: 18px;
                    margin-bottom: 15px;
                    display: flex;
                    align-items: center;
                }}
                
                .parecer-icone {{
                    margin-right: 10px;
                    font-size: 24px;
                }}
                
                .parecer-conteudo {{
                    font-size: 16px;
                    line-height: 1.6;
                }}
                
                /* Gráficos */
                .graficos-grid {{
                    display: grid;
                    grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
                    gap: 20px;
                    margin-bottom: 20px;
                }}
                
                .grafico-container {{
                    background: white;
                    border-radius: 5px;
                    box-shadow: 0 2px 5px rgba(0,0,0,0.1);
                    padding: 15px;
                }}
                
                .grafico-titulo {{
                    color: #006341;
                    margin-top: 0;
                    margin-bottom: 15px;
                    font-size: 16px;
                }}
                
                .grafico-imagem img {{
                    width: 100%;
                    height: auto;
                    border-radius: 3px;
                }}
                
                .grafico-descricao {{
                    margin-top: 10px;
                    font-size: 14px;
                    color: #666;
                }}
                
                /* Análise consolidada */
                .analise-consolidada {{
                    background: white;
                    border-radius: 5px;
                    box-shadow: 0 2px 5px rgba(0,0,0,0.1);
                    padding: 20px;
                    margin-bottom: 20px;
                }}
                
                .fatores-risco {{
                    background-color: #fff8e1;
                    border-left: 5px solid #ffc107;
                    padding: 15px;
                    margin-bottom: 20px;
                }}
                
                .fatores-risco h3 {{
                    margin-top: 0;
                    color: #e65100;
                    font-size: 16px;
                }}
                
                .fatores-risco ul {{
                    margin: 10px 0 0;
                    padding-left: 20px;
                }}
                
                .fatores-risco li {{
                    margin-bottom: 10px;
                }}
                
                /* Abas */
                .abas {{
                    display: flex;
                    border-bottom: 1px solid #ddd;
                    margin-bottom: 20px;
                    flex-wrap: wrap;
                }}
                
                .aba {{
                    padding: 10px 20px;
                    cursor: pointer;
                    border-bottom: 3px solid transparent;
                    font-weight: bold;
                    margin-bottom: -1px;
                }}
                
                .aba.ativa {{
                    border-bottom: 3px solid #F9B000;
                    color: #006341;
                }}
                
                .conteudo-aba {{
                    display: none;
                    padding: 20px 0;
                }}
                
                .conteudo-aba.ativo {{
                    display: block;
                }}
                
                .conteudo-aba h3 {{
                    color: #006341;
                    margin-top: 0;
                    margin-bottom: 15px;
                    font-size: 18px;
                }}
                
                /* Análises detalhadas */
                .analise-detalhada {{
                    background: white;
                    border-radius: 5px;
                    box-shadow: 0 2px 5px rgba(0,0,0,0.1);
                    padding: 20px;
                    margin-bottom: 20px;
                }}
                
                .analise-texto {{
                    white-space: pre-line;
                    line-height: 1.7;
                    font-size: 14px;
                }}
                
                /* Rodapé */
                .rodape {{
                    background-color: #006341;
                    color: white;
                    padding: 20px;
                    text-align: center;
                    font-size: 12px;
                    opacity: 0.9;
                }}
                
                /* Utilitários */
                .texto-centro {{
                    text-align: center;
                }}
                
                .mb-20 {{
                    margin-bottom: 20px;
                }}
                
                /* Responsividade */
                @media (max-width: 768px) {{
                    .graficos-grid {{
                        grid-template-columns: 1fr;
                    }}
                    
                    .info-processo {{
                        grid-template-columns: 1fr;
                    }}
                    
                    .cabecalho {{
                        flex-direction: column;
                        text-align: center;
                    }}
                    
                    .aba {{
                        padding: 8px 12px;
                        font-size: 14px;
                    }}
                }}
            </style>
        </head>
        <body>
            <div class="container">
                <!-- Cabeçalho -->
                <header class="cabecalho">
                    <div class="logo-container">
                        <div class="logo">SICREDI</div>
                    </div>
                    <div class="titulo">
                        <h1>Análise de Crédito</h1>
                        <h2>Relatório Técnico - {'Pessoa Jurídica' if tipo_pessoa == 'PJ' else 'Pessoa Física'}</h2>
                    </div>
                </header>
                
                <!-- Informações do processo -->
                <section class="info-processo">
                    <div class="info-item">
                        <div class="info-label">Número do Processo</div>
                        <div class="info-valor">{numero_processo}</div>
                    </div>
                    <div class="info-item">
                        <div class="info-label">CPF/CNPJ</div>
                        <div class="info-valor">{cpf_cnpj}</div>
                    </div>
                    <div class="info-item">
                        <div class="info-label">Nome do Associado</div>
                        <div class="info-valor">{nome_associado}</div>
                    </div>
                    <div class="info-item">
                        <div class="info-label">{rotulo_valor}</div>
                        <div class="info-valor">{valor_mensal}</div>
                    </div>
                    <div class="info-item">
                        <div class="info-label">Data da Análise</div>
                        <div class="info-valor">{data_atual}</div>
                    </div>
                </section>
                
                <!-- Proposta -->
                <section class="secao">
                    <h2 class="secao-titulo">Proposta</h2>
                    <div class="analise-consolidada">
                        <p>{proposta}</p>
                    </div>
                </section>
                
                <!-- Parecer Final -->
                <section class="parecer {status_class}">
                    <h2 class="parecer-titulo">
                        <span class="parecer-icone">{status_icon}</span>
                        Parecer Final
                    </h2>
                    <div class="parecer-conteudo">
                        {parecer}
                    </div>
                </section>
                
                <!-- Análise Consolidada -->
                <section class="secao">
                    <h2 class="secao-titulo">Análise Consolidada</h2>
                    
                    <!-- Fatores de risco -->
                    <div class="fatores-risco">
                        <h3>Fatores de Risco Identificados:</h3>
                        <ul>
                            {fatores_risco_html}
                        </ul>
                    </div>
                    
                    <!-- Abas de análise -->
                    <div class="abas">
                        <div class="aba ativa" data-aba="sintese">Síntese do Perfil</div>
                        <div class="aba" data-aba="capacidade">Capacidade de Pagamento</div>
                        <div class="aba" data-aba="risco">Análise de Risco</div>
                        <div class="aba" data-aba="proposta">Análise da Proposta</div>
                    </div>
                    
                    <div class="conteudo-aba ativo" id="sintese">
                        <div class="analise-consolidada">
                            <h3>Síntese do Perfil Financeiro do Associado</h3>
                            <div class="analise-texto">{secoes.get("1. SÍNTESE DO PERFIL FINANCEIRO DO ASSOCIADO", "Informação não disponível.")}</div>
                        </div>
                    </div>
                    
                    <div class="conteudo-aba" id="capacidade">
                        <div class="analise-consolidada">
                            <h3>Análise de Capacidade de Pagamento</h3>
                            <div class="analise-texto">{secoes.get("2. ANÁLISE DE CAPACIDADE DE PAGAMENTO", "Informação não disponível.")}</div>
                        </div>
                    </div>
                    
                    <div class="conteudo-aba" id="risco">
                        <div class="analise-consolidada">
                            <h3>Análise de Risco Consolidada</h3>
                            <div class="analise-texto">{secoes.get("3. ANÁLISE DE RISCO CONSOLIDADA", "Informação não disponível.")}</div>
                        </div>
                    </div>
                    
                    <div class="conteudo-aba" id="proposta">
                        <div class="analise-consolidada">
                            <h3>Análise da Proposta</h3>
                            <div class="analise-texto">{secoes.get("4. ANÁLISE DA PROPOSTA", "Informação não disponível.")}</div>
                        </div>
                    </div>
                </section>
                
                <!-- Gráficos -->
                <section class="secao">
                    <h2 class="secao-titulo">Gráficos de Análise</h2>
                    <div class="graficos-grid">
                        {graficos_html}
                    </div>
                </section>
                
                <!-- Análises Detalhadas -->
                <section class="secao">
                    <h2 class="secao-titulo">Análises Detalhadas</h2>
                    <p class="mb-20">As análises detalhadas a seguir fornecem informações específicas sobre cada aspecto avaliado.</p>
                    
                    <div class="abas">
                        <div class="aba ativa" data-aba="perfil">Perfil do Associado</div>
                        <div class="aba" data-aba="carteira">Carteira de Crédito</div>
                        <div class="aba" data-aba="scr">Análise SCR</div>
                    </div>
                    
                    <div class="conteudo-aba ativo" id="perfil">
                        <div class="analise-detalhada">
                            <h3>Análise de Perfil do Associado</h3>
                            <div class="analise-texto">{analise_perfil}</div>
                        </div>
                    </div>
                    
                    <div class="conteudo-aba" id="carteira">
                        <div class="analise-detalhada">
                            <h3>Análise de Carteira de Crédito</h3>
                            <div class="analise-texto">{analise_carteira}</div>
                        </div>
                    </div>
                    
                    <div class="conteudo-aba" id="scr">
                        <div class="analise-detalhada">
                            <h3>Análise SCR</h3>
                            <div class="analise-texto">{analise_scr}</div>
                        </div>
                    </div>
                </section>
                
                <!-- Rodapé -->
                <footer class="rodape">
                    Este documento é confidencial e de uso exclusivo do Sicredi. A análise foi realizada automaticamente pelo Sistema de Análise de Crédito CeleiroGPT 5.0 em {data_atual}.
                </footer>
            </div>
            
            <script>
                // Script para funcionalidade das abas
                document.addEventListener('DOMContentLoaded', function() {{
                    // Função para alternar entre abas
                    function configurarAbas(container) {{
                        const abas = container.querySelectorAll('.aba');
                        
                        abas.forEach(aba => {{
                            aba.addEventListener('click', function() {{
                                // Remover classe ativa de todas as abas
                                abas.forEach(a => a.classList.remove('ativa'));
                                
                                // Adicionar classe ativa à aba clicada
                                this.classList.add('ativa');
                                
                                // Identificar qual conteúdo mostrar
                                const idConteudo = this.getAttribute('data-aba');
                                
                                // Esconder todos os conteúdos
                                const conteudos = document.querySelectorAll('.conteudo-aba');
                                conteudos.forEach(c => c.classList.remove('ativo'));
                                
                                // Mostrar o conteúdo correspondente
                                document.getElementById(idConteudo).classList.add('ativo');
                            }});
                        }});
                    }}
                    
                    // Configurar todas as seções com abas
                    const secoes = document.querySelectorAll('.secao');
                    secoes.forEach(secao => {{
                        const abasContainer = secao.querySelector('.abas');
                        if (abasContainer) {{
                            configurarAbas(secao);
                        }}
                    }});
                }});
            </script>
        </body>
        </html>
        """
        
        return html_template
    
    def gerar_relatorio_pdf(self, numero_processo: int, cpf_cnpj: str, nome_associado: str, proposta: str,
                          tipo_pessoa: str, analise_perfil: str, analise_carteira: str, analise_scr: str,
                          analise_final: str, parecer: str, graficos: List[Dict],
                          dados_perfil: Dict, dados_carteira: Dict, dados_scr: Dict,
                          diretorio: Path) -> str:
        """
        Gera um relatório PDF profissional com todas as análises e gráficos.
        
        Args:
            numero_processo: Número do processo
            cpf_cnpj: CPF/CNPJ do associado
            nome_associado: Nome do associado
            proposta: Descrição da proposta
            tipo_pessoa: Tipo de pessoa ('PF' ou 'PJ')
            analise_perfil: Texto da análise de perfil
            analise_carteira: Texto da análise de carteira
            analise_scr: Texto da análise de SCR
            analise_final: Texto da análise consolidada
            parecer: Parecer final resumido
            graficos: Lista de gráficos em base64
            dados_perfil: Dados estruturados do perfil
            dados_carteira: Dados estruturados da carteira
            dados_scr: Dados estruturados do SCR
            diretorio: Diretório para salvar o PDF
            
        Returns:
            str: Link para o PDF gerado
        """
        try:
            # Nome do arquivo
            filename = f"analise_credito_{numero_processo}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            filepath = diretorio / filename
            
            # Gerar HTML usando o template aprimorado
            html_content = self.gerar_relatorio_html(
                numero_processo=numero_processo,
                cpf_cnpj=cpf_cnpj,
                nome_associado=nome_associado,
                proposta=proposta,
                tipo_pessoa=tipo_pessoa,
                analise_perfil=analise_perfil,
                analise_carteira=analise_carteira,
                analise_scr=analise_scr,
                analise_final=analise_final,
                parecer=parecer,
                graficos=graficos,
                dados_perfil=dados_perfil,
                dados_carteira=dados_carteira,
                dados_scr=dados_scr
            )
            
            # Salvar o HTML
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(html_content)
            
            # Verificar se temos pdfkit disponível
            if has_pdfkit:
                try:
                    # Nome do arquivo PDF
                    pdf_filename = f"analise_credito_{numero_processo}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
                    pdf_filepath = diretorio / pdf_filename
                    
                    # Configurações para o PDF
                    opcoes = {
                        'page-size': 'A4',
                        'margin-top': '10mm',
                        'margin-right': '10mm',
                        'margin-bottom': '10mm',
                        'margin-left': '10mm',
                        'encoding': "UTF-8",
                        'enable-local-file-access': None,
                        'enable-javascript': None,
                        'javascript-delay': '1000',  # Esperar 1s para o JavaScript executar
                        'no-stop-slow-scripts': None
                    }
                    
                    # Gerar o PDF a partir do HTML
                    pdfkit.from_file(str(filepath), str(pdf_filepath), options=opcoes)
                    
                    # Usar o arquivo PDF como resultado
                    result_filename = pdf_filename
                    result_filepath = pdf_filepath
                    logger.info(f"✅ Relatório PDF gerado com sucesso: {pdf_filepath}")
                except Exception as e:
                    logger.warning(f"⚠️ Erro ao gerar PDF, usando HTML: {str(e)}")
                    result_filename = filename
                    result_filepath = filepath
            else:
                logger.info(f"ℹ️ pdfkit não disponível, usando HTML: {filepath}")
                result_filename = filename
                result_filepath = filepath
            
            # Retornar o link DBFS para acesso
            dbfs_link = f"/FileStore/analises_credito/{datetime.now().strftime('%Y%m%d')}/{result_filename}"
            
            logger.info(f"✅ Relatório gerado com sucesso: {result_filepath}")
            return dbfs_link
            
        except Exception as e:
            logger.error(f"❌ Erro ao gerar relatório: {str(e)}")
            logger.error(traceback.format_exc())
            return ""
    
    def _extrair_resumo(self, texto: str, tamanho_max: int = 1000) -> str:
        """
        Extrai um resumo do texto, mantendo parágrafos completos até o limite de tamanho.
        
        Args:
            texto: Texto completo
            tamanho_max: Tamanho máximo do resumo em caracteres
            
        Returns:
            str: Resumo do texto
        """
        if not texto or len(texto) <= tamanho_max:
            return texto
        
        # Dividir em parágrafos
        paragrafos = texto.split('\n\n')
        
        # Filtrar parágrafos vazios ou muito curtos
        paragrafos = [p for p in paragrafos if len(p.strip()) > 30]
        
        # Selecionar parágrafos até atingir o tamanho máximo
        resumo = []
        tamanho_atual = 0
        
        for p in paragrafos:
            if tamanho_atual + len(p) <= tamanho_max:
                resumo.append(p)
                tamanho_atual += len(p)
            else:
                break
        
        # Se não conseguiu incluir nenhum parágrafo completo, usar o início do texto
        if not resumo:
            return texto[:tamanho_max] + "..."
        
        # Adicionar indicação de que há mais conteúdo
        if tamanho_atual < len(texto):
            resumo.append("...")
        
        return '\n\n'.join(resumo)
    
    def processar_lote(self, max_processos: int = 10) -> List[Dict[str, Any]]:
        """
        Processa um lote de processos pendentes.
        
        Args:
            max_processos: Número máximo de processos a processar
            
        Returns:
            List: Lista com resultados dos processos analisados
        """
        logger.info(f"🔄 Iniciando processamento de lote (máx: {max_processos} processos)")
        
        # Buscar processos pendentes
        processos_df = self.consultar_tabela_processos()
        
        if processos_df.empty:
            logger.info("ℹ️ Nenhum processo pendente encontrado")
            return []
        
        # Limitar ao número máximo de processos
        processos_df = processos_df.head(max_processos)
        
        resultados = []
        
        # Processar cada processo
        for idx, processo in processos_df.iterrows():
            logger.info(f"🔄 Processando processo {idx+1}/{len(processos_df)}: {processo['numero_processo']}")
            
            try:
                cpf_cnpj = processo['cpf_cnpj']
                proposta = processo['proposta']
                numero_processo = processo['numero_processo']
                cpf_avalista = processo.get('cpf_avalista', None)
                
                # Executar análise completa
                resultado = self.executar_analise_completa(
                    cpf_cnpj, 
                    proposta, 
                    numero_processo, 
                    cpf_avalista
                )
                
                resultados.append(resultado)
                
                # Pequena pausa entre processos
                if idx < len(processos_df) - 1:
                    time.sleep(2)
                    
            except Exception as e:
                logger.error(f"❌ Erro ao processar processo {processo['numero_processo']}: {str(e)}")
                logger.error(traceback.format_exc())
                
                # Atualizar status para ERRO_ANALISE
                self.atualizar_status_processo(
                    processo['numero_processo'], 
                    'ERRO_ANALISE', 
                    f"Erro durante o processamento: {str(e)}"
                )
                
                resultados.append({
                    "status": "error",
                    "numero_processo": processo['numero_processo'],
                    "cpf_cnpj": processo['cpf_cnpj'],
                    "message": f"Erro no processamento: {str(e)}"
                })
        
        logger.info(f"✅ Processamento de lote concluído. {len(resultados)} processos processados.")
        return resultados
    
    def executar_pipeline(self, modo_continuo: bool = False, intervalo_segundos: int = 300):
        """
        Executa o pipeline em modo contínuo ou uma única vez.
        
        Args:
            modo_continuo: Se True, executa em loop contínuo
            intervalo_segundos: Intervalo entre verificações em modo contínuo
        """
        logger.info(f"🚀 Iniciando pipeline de análise de crédito. Modo contínuo: {modo_continuo}")
        
        try:
            if modo_continuo:
                while True:
                    logger.info(f"🔄 Verificando processos pendentes")
                    self.processar_lote()
                    
                    logger.info(f"💤 Aguardando {intervalo_segundos} segundos até próxima verificação")
                    time.sleep(intervalo_segundos)
            else:
                # Executar uma única vez
                self.processar_lote()
                logger.info("✅ Pipeline executado com sucesso")
                
        except KeyboardInterrupt:
            logger.info("⛔ Pipeline interrompido pelo usuário")
        except Exception as e:
            logger.error(f"❌ Erro na execução do pipeline: {str(e)}")
            logger.error(traceback.format_exc())

# Função para uso em notebooks Databricks
def executar_analise_credito(cpf_cnpj: str, proposta: str, 
                           numero_processo: int = None, 
                           cpf_avalista: str = None,
                           output_dir: str = None) -> Dict[str, Any]:
    """
    Função de conveniência para executar uma análise de crédito completa.
    
    Args:
        cpf_cnpj: CPF ou CNPJ do associado
        proposta: Descrição da proposta
        numero_processo: Número do processo (opcional, será gerado se não fornecido)
        cpf_avalista: CPF do avalista (opcional)
        output_dir: Diretório para salvar relatórios (opcional)
        
    Returns:
        Dict: Resultado da análise
    """
    # Gerar número de processo se não fornecido
    if numero_processo is None:
        numero_processo = int(time.time())
    
    logger.info(f"🚀 Iniciando análise de crédito para {cpf_cnpj} (Processo: {numero_processo})")
    
    # Inicializar o pipeline
    pipeline = PipelineAnaliseCredito(output_dir=output_dir)
    
    # Executar a análise
    resultado = pipeline.executar_analise_completa(
        cpf_cnpj, 
        proposta, 
        numero_processo, 
        cpf_avalista
    )
    
    logger.info(f"✅ Análise concluída com status: {resultado.get('status', 'desconhecido')}")
    return resultado

def main():
    """
    Função principal para execução do pipeline como script.
    """
    # Verificar se está em ambiente notebook Databricks
    import sys
    is_notebook = 'ipykernel' in sys.modules
    
    if is_notebook:
        # Executar em modo notebook sem processar argumentos
        logger.info("Executando em ambiente notebook")
        pipeline = PipelineAnaliseCredito()
        pipeline.processar_lote()
    else:
        # Executar como script com argumentos
        import argparse
        
        parser = argparse.ArgumentParser(description='Pipeline de Análise de Crédito CeleiroGPT 5.0')
        parser.add_argument('--modo', choices=['unico', 'continuo'], default='unico',
                           help='Modo de execução: único ou contínuo')
        parser.add_argument('--intervalo', type=int, default=300,
                           help='Intervalo entre verificações em modo contínuo (segundos)')
        parser.add_argument('--output', type=str, default=None,
                           help='Diretório para salvar relatórios')
        parser.add_argument('--cpf_cnpj', type=str, default=None,
                           help='CPF/CNPJ específico para análise única')
        parser.add_argument('--proposta', type=str, default=None,
                           help='Proposta para análise única')
        
        args = parser.parse_args()
        
        # Inicializar o pipeline
        pipeline = PipelineAnaliseCredito(output_dir=args.output)
        
        # Verificar se é uma análise específica
        if args.cpf_cnpj and args.proposta:
            logger.info(f"🔍 Executando análise específica para {args.cpf_cnpj}")
            numero_processo = int(time.time())
            resultado = pipeline.executar_analise_completa(
                args.cpf_cnpj,
                args.proposta,
                numero_processo
            )
            logger.info(f"✅ Análise concluída com status: {resultado.get('status', 'desconhecido')}")
        else:
            # Executar o pipeline no modo especificado
            pipeline.executar_pipeline(
                modo_continuo=(args.modo == 'continuo'),
                intervalo_segundos=args.intervalo
            )

if __name__ == "__main__":
    # Verificar se está em ambiente notebook Databricks
    import sys
    is_notebook = 'ipykernel' in sys.modules
    
    if is_notebook:
        # Em ambiente notebook, executar processamento de lote
        logger.info("Script carregado em ambiente notebook. Iniciando processamento automático.")
        
        # Tentar instalar pdfkit se necessário
        try:
            import pdfkit
        except ImportError:
            print("Instalando pdfkit...")
            import subprocess
            subprocess.check_call([sys.executable, "-m", "pip", "install", "pdfkit"])
            try:
                import pdfkit
                print("pdfkit instalado com sucesso!")
                has_pdfkit = True
            except ImportError:
                print("Falha ao instalar pdfkit. Os relatórios serão salvos apenas como HTML.")
                has_pdfkit = False
        
        # Iniciar o pipeline
        pipeline = PipelineAnaliseCredito()
        pipeline.processar_lote()
    else:
        # Em ambiente de script, executar normalmente
        main()

}

Prompt Elaborado para Reconstrução de Código de Análise de Perfil do Associado
Contexto e Objetivo
Solicito a reconstrução completa e aprimoramento de um código Python existente destinado à análise de perfil de associados financeiros. O código atual implementa um sistema de análise que extrai dados de associados de uma base de dados, processa estas informações e gera relatórios analíticos detalhados utilizando modelos de linguagem.
Código Atual e Funcionalidades
O código atual é uma implementação robusta de um analisador de perfil de associados que:
Utiliza a biblioteca PySpark para conexão e consulta a bancos de dados
Implementa um gerenciador de sessões Spark com mecanismos de retry e tratamento de erros
Extrai dados detalhados de associados (pessoas físicas e jurídicas) de tabelas específicas
Realiza análises paralelas de cônjuges, sócios e grupos econômicos quando aplicável
Formata e estrutura os dados para análise
Calcula métricas adicionais para enriquecer a análise
Utiliza a API da OpenAI para gerar análises textuais detalhadas
Implementa mecanismos de cache, timeout e retry para otimizar o desempenho
Gera análises consolidadas considerando todos os aspectos do associado
Especificações Técnicas Detalhadas
O código deve ser reconstruído mantendo as seguintes estruturas e funcionalidades:
Classe SparkSessionManager
Gerenciamento singleton da sessão Spark
Mecanismos de recuperação automática em caso de falhas
Configurações otimizadas para consultas de dados
Classe AnalisadorPerfilAssociado
Método principal analisar_perfil_associado(cpf_cnpj) que orquestra todo o processo
Extração de dados do associado via SQL
Análise de cônjuges para pessoas físicas
Análise de sócios para pessoas jurídicas
Análise de grupos econômicos quando aplicável
Formatação detalhada dos dados para o modelo de linguagem
Cálculo de métricas financeiras adicionais
Geração de análises textuais utilizando modelos LLM
Consolidação de todas as análises em um resultado final
Integrações
OpenAI API para geração de análises textuais
MLflow para logging de experimentos
Logging detalhado de operações e erros
Tratamento de Erros e Resiliência
Mecanismos de retry para chamadas à API
Tratamento de timeouts em análises secundárias
Cache para evitar consultas repetidas
Fallbacks para cenários de falha
Requisitos Específicos
O código deve manter todas as funcionalidades existentes, incluindo:
Análise de perfil principal
Análise de cônjuges (para PF)
Análise de sócios (para PJ)
Análise de grupos econômicos
Geração de análises textuais via LLM
Consolidação de resultados
A estrutura de classes e métodos deve ser preservada para manter compatibilidade com sistemas existentes
O código deve incluir tratamento abrangente de erros e logging detalhado
Deve-se manter os mecanismos de otimização como cache e configurações Spark
As consultas SQL devem ser preservadas conforme implementação original
Considerações Adicionais
O código será executado em ambiente Databricks
É essencial manter a compatibilidade com as tabelas e estruturas de dados existentes
A performance é crítica, especialmente para análises em lote
O código deve ser bem documentado e seguir as melhores práticas de Python
Por favor, reconstrua o código completo mantendo todas estas características e funcionalidades, garantindo que a nova implementação seja robusta, eficiente e bem estruturada.
Prompt Elaborado para Reconstrução de Código de Análise de SCR (Sistema de Informações de Crédito)
Contexto e Objetivo
Solicito a reconstrução completa e aprimoramento de um código Python existente destinado à análise do Sistema de Informações de Crédito (SCR) de associados financeiros. O código atual implementa um sistema de análise que extrai dados do SCR, processa estas informações e gera relatórios analíticos detalhados utilizando modelos de linguagem e visualizações gráficas.
Código Atual e Funcionalidades
O código atual é uma implementação robusta de um analisador de SCR que:
Utiliza a biblioteca PySpark para conexão e consulta a bancos de dados
Implementa um gerenciador de sessões Spark com mecanismos de retry e tratamento de erros
Monitora recursos do sistema e do Spark durante a execução
Extrai dados detalhados do SCR de associados de tabelas específicas
Realiza análises paralelas de cônjuges e grupos econômicos quando aplicável
Formata e estrutura os dados para análise
Calcula estatísticas adicionais para enriquecer a análise
Gera visualizações gráficas informativas sobre os dados do SCR
Utiliza a API da OpenAI para gerar análises textuais detalhadas
Implementa mecanismos de cache, timeout e retry para otimizar o desempenho
Especificações Técnicas Detalhadas
O código deve ser reconstruído mantendo as seguintes estruturas e funcionalidades:
Classes de Logging e Monitoramento
ColoredFormatter para formatação de logs com cores
ResourceMonitor para monitoramento de recursos do sistema e Spark
Classe SparkSessionManager
Gerenciamento singleton da sessão Spark
Mecanismos de recuperação automática em caso de falhas
Configurações otimizadas para consultas de dados
Método execute_with_retry para execução resiliente de consultas
Classe GeradorGraficos
Geração de múltiplos tipos de gráficos informativos:
Evolução da carteira
Composição da carteira por tipo de produto
Distribuição por vencimento
Evolução dos estágios IFRS 9
Sazonalidade de pagamentos
Histórico de inadimplência
Indicadores de alerta
Comparação com cônjuge
Análise de grupo econômico
Conversão de gráficos para base64 para inclusão em relatórios
Classe AnalisadorSCR
Método principal analisar_scr_associado(cpf_cnpj) que orquestra todo o processo
Extração de dados do SCR via SQL complexas
Análise de cônjuges quando aplicável
Análise de grupos econômicos quando aplicável
Formatação detalhada dos dados para o modelo de linguagem
Cálculo de estatísticas adicionais
Geração de visualizações gráficas
Geração de análises textuais utilizando modelos LLM
Consolidação de todas as análises em um resultado final
Integrações
OpenAI API para geração de análises textuais
Matplotlib e Seaborn para geração de gráficos
Logging detalhado de operações e erros
Tratamento de Erros e Resiliência
Mecanismos de retry para chamadas à API e consultas SQL
Tratamento de timeouts em análises secundárias
Cache para evitar consultas repetidas
Fallbacks para cenários de falha
Requisitos Específicos
O código deve manter todas as funcionalidades existentes, incluindo:
Análise de SCR principal
Análise de cônjuges
Análise de grupos econômicos
Geração de gráficos informativos
Geração de análises textuais via LLM
Consolidação de resultados
A estrutura de classes e métodos deve ser preservada para manter compatibilidade com sistemas existentes
O código deve incluir tratamento abrangente de erros e logging detalhado
Deve-se manter os mecanismos de otimização como cache e configurações Spark
As consultas SQL devem ser preservadas conforme implementação original
A geração de gráficos deve ser mantida com todas as características visuais
Considerações Adicionais
O código será executado em ambiente Databricks
É essencial manter a compatibilidade com as tabelas e estruturas de dados existentes
A performance é crítica, especialmente para análises em lote
O código deve ser bem documentado e seguir as melhores práticas de Python
A qualidade visual dos gráficos é importante para a interpretação dos dados
Por favor, reconstrua o código completo mantendo todas estas características e funcionalidades, garantindo que a nova implementação seja robusta, eficiente e bem estruturada.
Prompt Elaborado para Reconstrução de Código de Análise de Carteira e Histórico de Crédito
Contexto e Objetivo
Solicito a reconstrução completa e aprimoramento de um código Python existente destinado à análise de carteira e histórico de crédito de associados financeiros. O código atual implementa um sistema de análise que extrai dados históricos de crédito, processa estas informações e gera relatórios analíticos detalhados utilizando modelos de linguagem e visualizações gráficas.
Código Atual e Funcionalidades
O código atual é uma implementação robusta de um analisador de carteira de crédito que:
Utiliza a biblioteca PySpark para conexão e consulta a bancos de dados
Implementa um gerenciador de sessões Spark com mecanismos de retry e tratamento de erros
Monitora recursos do sistema e do Spark durante a execução
Extrai dados detalhados do histórico de crédito de associados de tabelas específicas
Realiza análises paralelas de cônjuges e grupos econômicos quando aplicável
Formata e estrutura os dados para análise
Calcula estatísticas adicionais para enriquecer a análise
Gera visualizações gráficas informativas sobre os dados de crédito
Utiliza a API da OpenAI para gerar análises textuais detalhadas
Implementa mecanismos de cache, timeout e retry para otimizar o desempenho
Especificações Técnicas Detalhadas
O código deve ser reconstruído mantendo as seguintes estruturas e funcionalidades:
Classes de Logging e Monitoramento
ColoredFormatter para formatação de logs com cores
ResourceMonitor para monitoramento de recursos do sistema e Spark
Classe SparkSessionManager
Gerenciamento singleton da sessão Spark
Mecanismos de recuperação automática em caso de falhas
Configurações otimizadas para consultas de dados
Método execute_with_retry para execução resiliente de consultas
Classe GeradorGraficos
Geração de múltiplos tipos de gráficos informativos:
Evolução da carteira
Composição da carteira por tipo de produto
Distribuição por vencimento
Evolução dos estágios IFRS 9
Sazonalidade de pagamentos
Histórico de inadimplência
Indicadores de alerta
Comparação com cônjuge
Análise de grupo econômico
Conversão de gráficos para base64 para inclusão em relatórios
Classe AnalisadorCredito
Método principal analisar_historico_credito_associado(cpf_cnpj) que orquestra todo o processo
Extração de dados do histórico de crédito via SQL complexas
Análise de cônjuges quando aplicável
Análise de grupos econômicos quando aplicável
Formatação detalhada dos dados para o modelo de linguagem
Cálculo de estatísticas adicionais
Geração de visualizações gráficas
Geração de análises textuais utilizando modelos LLM
Consolidação de todas as análises em um resultado final
Integrações
OpenAI API para geração de análises textuais
Matplotlib e Seaborn para geração de gráficos
Logging detalhado de operações e erros
Tratamento de Erros e Resiliência
Mecanismos de retry para chamadas à API e consultas SQL
Tratamento de timeouts em análises secundárias
Cache para evitar consultas repetidas
Fallbacks para cenários de falha
Requisitos Específicos
O código deve manter todas as funcionalidades existentes, incluindo:
Análise de histórico de crédito principal
Análise de cônjuges
Análise de grupos econômicos
Geração de gráficos informativos
Geração de análises textuais via LLM
Consolidação de resultados
A estrutura de classes e métodos deve ser preservada para manter compatibilidade com sistemas existentes
O código deve incluir tratamento abrangente de erros e logging detalhado
Deve-se manter os mecanismos de otimização como cache e configurações Spark
As consultas SQL devem ser preservadas conforme implementação original
A geração de gráficos deve ser mantida com todas as características visuais
Considerações Adicionais
O código será executado em ambiente Databricks
É essencial manter a compatibilidade com as tabelas e estruturas de dados existentes
A performance é crítica, especialmente para análises em lote
O código deve ser bem documentado e seguir as melhores práticas de Python
A qualidade visual dos gráficos é importante para a interpretação dos dados
Por favor, reconstrua o código completo mantendo todas estas características e funcionalidades, garantindo que a nova implementação seja robusta, eficiente e bem estruturada.
Prompt Elaborado para Desenvolvimento de um Sistema Avançado de Análise de Crédito
Visão Geral do Sistema
Solicito o desenvolvimento de um sistema completo e modular de análise de crédito que integre múltiplos componentes analíticos, aplique regras de negócio específicas por tipo de produto e pessoa, e gere relatórios profissionais detalhados. O sistema deve ser projetado para ambiente Databricks, utilizando Python e seguindo princípios de arquitetura modular, orientada a objetos e altamente extensível.
Arquitetura e Estrutura Proposta
1. Estrutura de Diretórios e Módulos
Exemplo
/analise_credito/
  ├── core/
  │   ├── __init__.py
  │   ├── base_analyzer.py          # Classe base para analisadores
  │   ├── spark_manager.py          # Gerenciador de sessões Spark
  │   ├── resource_monitor.py       # Monitoramento de recursos
  │   ├── logging_config.py         # Configuração de logging
  │   └── data_extractor.py         # Extração de dados comuns
  │
  ├── analyzers/
  │   ├── __init__.py
  │   ├── perfil_analyzer.py        # Análise de perfil do associado
  │   ├── carteira_analyzer.py      # Análise de carteira de crédito
  │   ├── scr_analyzer.py           # Análise de SCR
  │   └── avalista_analyzer.py      # Análise de avalistas
  │
  ├── rules/
  │   ├── __init__.py
  │   ├── rule_engine.py            # Motor de regras
  │   ├── product_rules.py          # Regras por produto
  │   ├── pf_rules.py               # Regras específicas para PF
  │   └── pj_rules.py               # Regras específicas para PJ
  │
  ├── reporting/
  │   ├── __init__.py
  │   ├── report_generator.py       # Gerador de relatórios
  │   ├── html_templates.py         # Templates HTML
  │   ├── pdf_converter.py          # Conversor HTML para PDF
  │   └── chart_generator.py        # Gerador de gráficos
  │
  ├── llm/
  │   ├── __init__.py
  │   ├── llm_client.py             # Cliente para modelos LLM
  │   ├── prompts.py                # Templates de prompts
  │   └── response_parser.py        # Parser de respostas
  │
  ├── database/
  │   ├── __init__.py
  │   ├── process_manager.py        # Gerenciador de processos
  │   ├── result_saver.py           # Salvamento de resultados
  │   └── log_manager.py            # Gerenciador de logs
  │
  ├── utils/
  │   ├── __init__.py
  │   ├── formatters.py             # Formatadores de dados
  │   ├── validators.py             # Validadores de entrada
  │   └── helpers.py                # Funções auxiliares
  │
  ├── config/
  │   ├── __init__.py
  │   ├── settings.py               # Configurações globais
  │   └── product_config.py         # Configurações de produtos
  │
  ├── __init__.py
  ├── main.py                       # Ponto de entrada principal
  ├── pipeline.py                   # Pipeline de análise
  └── api.py                        # API para integração externa
2. Fluxo de Processamento
Identificação e Extração de Dados:
Identificar associado proponente (PF ou PJ)
Verificar existência de avalistas
Extrair informações básicas (nome, agência, regional, gestor, risco, renda)
Identificar tipo de proposta/produto
Análise Paralela:
Executar análise de perfil do associado
Executar análise de carteira de crédito
Executar análise de SCR
Executar análises complementares (cônjuge, grupo econômico)
Executar análise de avalistas (quando aplicável)
Aplicação de Regras:
Aplicar regras específicas por tipo de produto
Aplicar regras específicas por tipo de pessoa (PF/PJ)
Calcular limites e capacidade de pagamento
Análise Consolidada:
Enviar dados estruturados para modelo LLM
Gerar análise técnica detalhada
Gerar parecer final com recomendação
Geração de Relatório:
Construir relatório HTML estruturado
Incorporar gráficos e visualizações
Converter para PDF (quando aplicável)
Salvar em local apropriado
Atualização de Status e Logging:
Atualizar status do processo na base de dados
Registrar logs detalhados para auditoria
Salvar métricas de desempenho
Requisitos Técnicos Detalhados
Componente Principal: Pipeline de Análise
ExemploPython
class CreditAnalysisPipeline:
    """
    Pipeline principal que orquestra todo o processo de análise de crédito.
    """
    
    def __init__(self, config=None):
        """
        Inicializa o pipeline com configurações personalizadas.
        
        Args:
            config: Configurações opcionais para sobrescrever padrões
        """
        # Inicialização de componentes
        
    def process_request(self, process_id, cpf_cnpj, proposal, avalistas=None):
        """
        Processa uma solicitação de análise de crédito.
        
        Args:
            process_id: ID do processo
            cpf_cnpj: CPF/CNPJ do proponente
            proposal: Descrição da proposta
            avalistas: Lista de CPFs de avalistas (opcional)
            
        Returns:
            Dict: Resultado da análise
        """
        # Implementação do fluxo completo
        
    def process_batch(self, max_processes=10):
        """
        Processa um lote de solicitações pendentes.
        
        Args:
            max_processes: Número máximo de processos a processar
            
        Returns:
            List: Resultados das análises
        """
        # Implementação do processamento em lote
Componentes Específicos
Extrator de Dados:
Extrair informações do associado e proposta
Identificar tipo de pessoa e produto
Carregar regras específicas para o produto
Motor de Regras:
Implementar regras por produto (cartão, cheque, empréstimo)
Implementar regras específicas por tipo de pessoa
Calcular limites e capacidade de pagamento
Cliente LLM:
Gerenciar conexão com API de modelos de linguagem
Implementar mecanismos de retry e fallback
Otimizar prompts para diferentes cenários
Gerador de Relatórios:
Criar templates HTML dinâmicos e responsivos
Incorporar gráficos e visualizações
Implementar conversão para PDF
Estruturar relatório em seções lógicas
Gerenciador de Processos:
Consultar processos pendentes
Atualizar status de processos
Salvar resultados e logs
Requisitos de Implementação
Modularidade e Extensibilidade:
Arquitetura orientada a objetos com interfaces bem definidas
Fácil adição de novos produtos e regras
Componentes desacoplados com responsabilidades claras
Robustez e Resiliência:
Tratamento abrangente de erros em todos os níveis
Mecanismos de retry para operações externas
Fallbacks para cenários de falha
Validação rigorosa de entradas e saídas
Logging e Auditoria:
Logging estruturado em múltiplos níveis
Registro de decisões e cálculos importantes
Rastreabilidade completa do processo
Métricas de desempenho e tempo de execução
Performance:
Execução paralela de análises independentes
Cache de resultados intermediários
Otimização de consultas SQL
Monitoramento de recursos
Segurança:
Sanitização de entradas
Proteção contra injeção SQL
Tratamento seguro de dados sensíveis
Especificações Adicionais
Relatório HTML/PDF:
Design responsivo e profissional
Estrutura de navegação intuitiva
Seções claramente demarcadas
Visualizações gráficas interativas
Resumo executivo destacado
Detalhamento técnico completo
Integração com Databricks:
Uso eficiente de recursos do cluster
Compatibilidade com widgets e notebooks
Armazenamento otimizado no DBFS
Integração com tabelas Delta
Configurabilidade:
Parâmetros ajustáveis via arquivos de configuração
Personalização de regras sem alteração de código
Ajuste de limiares e critérios de decisão
Por favor, desenvolva este sistema completo seguindo as melhores práticas de engenharia de software, com código limpo, bem documentado e testável. O sistema deve ser projetado para evolução contínua, permitindo a adição de novos produtos, regras e funcionalidades com o mínimo de alterações na arquitetura central.
